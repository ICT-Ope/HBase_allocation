diff -uNr hbase-0.90.2/hbase-webapps/master/changegroupconf.jsp hbase-0.90.2-local/hbase-webapps/master/changegroupconf.jsp
--- hbase-webapps/master/changegroupconf.jsp	1970-01-01 08:00:00.000000000 +0800
+++ hbase-webapps/master/changegroupconf.jsp	2011-07-27 11:00:08.000000000 +0800
@@ -0,0 +1,247 @@
+<%@ page language="java" import="java.io.*" import="java.util.*"
+	import="org.apache.hadoop.hbase.master.HMaster"
+	import="org.apache.hadoop.hbase.HTableDescriptor"
+	import="org.apache.hadoop.hbase.HRegionInfo"
+	import="org.apache.hadoop.hbase.HServerAddress"
+	import="org.apache.hadoop.hbase.HServerInfo"
+	import="org.apache.hadoop.hbase.ClusterStatus"
+	import="org.apache.hadoop.hbase.master.GroupAssignmentManager"
+	import="org.apache.hadoop.hbase.allocation.group.ServerWithGroup"
+	import="org.apache.hadoop.hbase.allocation.group.MoveConfImpl"
+	contentType="text/html; charset=GB18030" pageEncoding="GB18030"%>
+<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
+<html>
+<head>
+<meta http-equiv="Content-Type" content="text/html; charset=GB18030">
+<link rel="stylesheet" type="text/css" href="/static/hbase.css" />
+<title>Distribute Group hbase-site.xml</title>
+<script type="text/javascript">
+	function validate_distform() {
+
+		var result = confirm("Do you want to distribute group hbase-site.xml or restart group regionservers??");
+		if (result == true) {
+			return true;
+		} else {
+			return false;
+		}
+	}
+</script>
+</head>
+<body>
+	<a id="logo" href="http://wiki.apache.org/lucene-hadoop/Hbase"><img
+		src="/static/hbase_logo_med.gif" alt="HBase Logo" title="HBase Logo" />
+	</a>
+	<h1 id="page_title">Distribute and Restart Group</h1>
+	<p id="links_menu">
+		<a href="/master.jsp">Master</a>,<a href="/logs/">Local logs</a>, <a
+			href="/stacks">Thread Dump</a>, <a href="/logLevel">Log Level</a>,<a
+			href="showgroup.jsp">Group Information</a>
+	</p>
+	<hr id="head_rule" />
+	<%
+	  class Distribute implements Runnable {
+	    private HMaster master;
+	    private List<String> groupserverlist;
+	    private String currentdir;
+	    private String command;
+
+	    public Distribute(HMaster master, List<String> groupserverlist,
+	        String currentdir, String command) {
+	      this.master = master;
+	      this.groupserverlist = groupserverlist;
+	      this.currentdir = currentdir;
+	      this.command = command;
+	    }
+
+	    public void run() {
+	      if (command.equals("distconf")) {
+	        MoveConfImpl moveimpl = new MoveConfImpl(currentdir);
+	        for (String serveraddr : groupserverlist) {
+	          try {
+	            String addr = serveraddr.substring(0, serveraddr.indexOf(","));
+	            System.out.println("Before Distribute " + addr
+	                + " configuration");
+	            //distribute new configuration
+	            moveimpl.DistributeConf(addr, "distribute");
+	            System.out.println("After Distribute configuration");
+	          } catch (Exception e) {
+	            e.printStackTrace();
+	          }
+	        }
+	      } else if (command.equals("restart")) {
+	        synchronized (GroupAssignmentManager.class) {
+	          MoveConfImpl moveimpl = new MoveConfImpl(currentdir);
+	          for (String serveraddr : groupserverlist) {
+	            try {
+	              String addr = serveraddr
+	                  .substring(0, serveraddr.indexOf(","));
+	              System.out.println("Before Restart " + addr
+	                  + " configuration");
+	              moveimpl.ImplRegionServer(addr, "stop");
+	              moveimpl.ImplRegionServer(addr, "start");
+	              System.out.println("After Restart configuration");
+	            } catch (Exception e) {
+	              e.printStackTrace();
+	            }
+	          }
+
+	          while (true) {
+	            int onlinenum = 0;
+	            ClusterStatus status = master.getClusterStatus();
+	            Collection<HServerInfo> servers = status.getServerInfo();
+	            for (HServerInfo info : servers) {
+	              String onlineserver = info.getHostname() + ","
+	                  + info.getServerAddress().getPort();
+	              if (groupserverlist.contains(onlineserver)) {
+	                onlinenum++;
+	              }
+	            }
+	            if (groupserverlist.size() != onlinenum) {
+	              try {
+	                Thread.sleep(1000);
+	              } catch (InterruptedException ex) {
+	                ex.printStackTrace();
+	              }
+	              continue;
+	            } else {
+	              break;
+	            }
+	          }
+	        }
+	      }
+	      synchronized (ServerWithGroup.class) {
+	        ServerWithGroup.setIsprocess(false);
+	        ServerWithGroup.setDoMoveconf(false);
+	      }
+	    }
+	  }
+	%>
+	<%
+	  final String DEFAULT_GROUP = "0";
+	  final String groupinfofilename = "groupinformation.conf";
+	  HMaster master = (HMaster) getServletContext().getAttribute(
+	      HMaster.MASTER);
+	  String CURRENTDIR = request.getRealPath("/");
+
+	  Map<String, List<String>> groupmap = new HashMap<String, List<String>>();
+	  List<String> groupserverlist = new ArrayList<String>();
+	  String submit = request.getParameter("cfsubmit");
+	  boolean isprocess = ServerWithGroup.isIsprocess();
+
+	  if (!isprocess) {
+	    String line = "";
+	    try {
+	      line = ServerWithGroup.readGroupInfo(master, groupinfofilename);
+	    } catch (IOException ex) {
+	    }
+	    groupmap = ServerWithGroup.initGroupMap(master, line);
+	    String configuration = null;
+	    if (request.getParameter("configurename") != null) {
+	      configuration = request.getParameter("configurename");
+	      if (configuration.length() > 0) {
+	        configuration = configuration.replaceAll("[&]lt;", "<");
+	        configuration = configuration.replaceAll("[&]gt;", ">");
+	        configuration = configuration.replaceAll("[&]quot;", "\"");
+	        File xmlfile = new File(CURRENTDIR + "/hbase-site.xml");
+	        BufferedWriter bw = new BufferedWriter(new FileWriter(xmlfile));
+	        bw.write(configuration);
+	        bw.close();
+	      }
+	    }
+	    if (request.getParameter("groupname") != null) {
+	      String group = request.getParameter("groupname");
+	      if (group.equals("null")) {
+	        out.println("<script type=\"text/javascript\">");
+	        out.println("alert(\"Warning , please choose right group...\")");
+	        out.println("history.back(-1)");
+	        out.println("</script>");
+	        return;
+	      }
+
+	      groupserverlist = groupmap.get(group);
+	      if (groupserverlist == null || groupserverlist.size() <= 0) {
+	        out.println("<script type=\"text/javascript\">");
+	        out.println("alert(\"Warning , there is no regionserver in this group.\")");
+	        out.println("history.back(-1)");
+	        out.println("</script>");
+	      }
+	      if (submit != null && submit.length() > 0) {
+	        if (submit.equals("Distribute")) {
+	          if (configuration != null && configuration.length() > 0) {
+	            out.println("Distribute group " + group);
+	            synchronized (ServerWithGroup.class) {
+	              ServerWithGroup.setIsprocess(true);
+	              ServerWithGroup.setDoMoveconf(true);
+	            }
+	            Thread DistributeThread = new Thread(new Distribute(master,
+	                groupserverlist, CURRENTDIR, "distconf"));
+	            DistributeThread.setName("Distribute Thread");
+	            DistributeThread.start();
+	            out.println("<script type=\"text/javascript\">");
+	            out.println("alert(\"Ready to distribute hbase-site.xml ,please wait...\")");
+	            out.println("window.location.href='changegroupconf.jsp'");
+	            out.println("</script>");
+	            return;
+	          } else {
+	            out.println("<script type=\"text/javascript\">");
+	            out.println("alert(\"Hbase-site.xml is null ,please write it.\")");
+	            out.println("history.back(-1)");
+	            out.println("</script>");
+	            return;
+	          }
+	        } else if (submit.equals("Restart")) {
+	          out.println("Restart group " + group);
+	          synchronized (ServerWithGroup.class) {
+	            ServerWithGroup.setIsprocess(true);
+	            ServerWithGroup.setDoMoveconf(true);
+	          }
+	          Thread RestartThread = new Thread(new Distribute(master,
+	              groupserverlist, CURRENTDIR, "restart"));
+	          RestartThread.setName("Restart Thread");
+	          RestartThread.start();
+	          out.println("<script type=\"text/javascript\">");
+	          out.println("alert(\"Ready to restart group regionservers ,please wait...\")");
+	          out.println("window.location.href='changegroupconf.jsp'");
+	          out.println("</script>");
+	          return;
+	        }
+	      }
+
+	    }
+	  } else {
+	    boolean ismoving = ServerWithGroup.isDoMoveconf();
+	    if (ismoving) {
+	      out.println("<center>");
+	      out.println("<form name='flushform' action='#' method=post>");
+	      out.println("<input type=submit name=submit value=Refresh style=\"width:60%;height:30px\" >");
+	      out.println("</form>");
+	      out.println("</center>");
+	    } else {
+	      out.println("<script type=\"text/javascript\">");
+	      out.println("alert(\"System is busy ,do it later , back to home \")");
+	      out.println("window.location.href='showgroup.jsp'");
+	      out.println("</script>");
+
+	    }
+	  }
+	  out.println("<center>");
+	  out.println("<form name=distform action='#' method='post' onSubmit=\"return validate_distform()\">");
+	  out.println("<br><font size=16 >Choose Group:</font>");
+	  out.println("<select name=groupname size=1 style=\"width:160px\">");
+	  out.println("<option value=null > </option>");
+	  for (String gp : groupmap.keySet()) {
+	    if (!gp.equals(DEFAULT_GROUP)) {
+	      out.println("<option value=" + gp + " >" + gp + "</option>");
+	    }
+	  }
+	  out.println("</select><br>");
+
+	  out.println("<br>New hbase-site.xml:<br>");
+	  out.println("<textarea cols=60 rows=25 name=configurename></textarea>");
+	  out.println("<br><br>Distribute group configure:<input type=submit name=cfsubmit value=\"Distribute\" style=\"width:20%;height:30px\">");
+	  out.println("<br><br>Restart group regionserver:<input type=submit name=cfsubmit value=\"Restart\" style=\"width:20%;height:30px\">");
+	  out.println("</form>");
+	  out.println("</center>");
+	%>
+</body>
+</html>
\ No newline at end of file
diff -uNr hbase-0.90.2/hbase-webapps/master/changetablegroup.jsp hbase-0.90.2-local/hbase-webapps/master/changetablegroup.jsp
--- hbase-webapps/master/changetablegroup.jsp	1970-01-01 08:00:00.000000000 +0800
+++ hbase-webapps/master/changetablegroup.jsp	2011-07-27 15:20:13.000000000 +0800
@@ -0,0 +1,214 @@
+<%@ page language="java" import="java.util.*" import="java.io.*"
+	import="org.apache.hadoop.hbase.master.HMaster"
+	import="org.apache.hadoop.hbase.HTableDescriptor"
+	import="org.apache.hadoop.hbase.HRegionInfo"
+	import="org.apache.hadoop.hbase.HServerAddress"
+	import="org.apache.hadoop.hbase.HServerInfo"
+	import="org.apache.hadoop.hbase.util.Bytes"
+	import="org.apache.hadoop.hbase.allocation.group.ServerWithGroup"
+	import="org.apache.hadoop.hbase.ipc.ScheduleHBaseServer"
+	import="org.apache.hadoop.hbase.master.GroupAssignmentManager"
+	contentType="text/html; charset=GB18030" pageEncoding="GB18030"%>
+<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
+<html>
+<head>
+<meta http-equiv="Content-Type" content="text/html; charset=GB18030">
+<title>Change Table Group Info</title>
+</head>
+<body>
+	<a id="logo" href="http://wiki.apache.org/lucene-hadoop/Hbase"><img
+		src="/static/hbase_logo_med.gif" alt="HBase Logo" title="HBase Logo" />
+	</a>
+	<h1 id="page_title">Change Table</h1>
+	<p id="links_menu">
+		<a href="/master.jsp">Master</a>,<a href="/logs/">Local logs</a>, <a
+			href="/stacks">Thread Dump</a>, <a href="/logLevel">Log Level</a>,<a
+			href="showgroup.jsp">Group Information</a>
+	</p>
+
+	<hr id="head_rule" />
+	<%
+	  /**
+	   * Class used for change table priority or groups
+	   */
+	  class ChangeTableGP implements Runnable {
+	    private String[] groups;
+	    private String priporty;
+	    private String tablename;
+
+	    public ChangeTableGP(String[] groups, String priporty, String tablename) {
+	      this.groups = groups;
+	      this.priporty = priporty;
+	      this.tablename = tablename;
+	    }
+
+	    public void run() {
+	      synchronized (GroupAssignmentManager.class) {
+	        ServerWithGroup.setIserror(false);
+	        try {
+	          if (groups != null && groups.length > 0) {
+	            System.out.println("in a thread , before change table group");
+	            GroupAssignmentManager.setGroup(groups, tablename);
+	            System.out.println("in a thread , after change table group");
+	          }
+	          if (priporty != null && priporty.length() > 0) {
+	            System.out
+	                .println("in a thread , before change table priporty");
+	            GroupAssignmentManager.setPriority(priporty, tablename);
+	            System.out.println("in a thread , after change table priporty");
+	          }
+	        } catch (Exception ex) {
+	          ServerWithGroup.setIserror(true);
+	          ServerWithGroup
+	              .setErrormsg("Change table property error ,please check log...");
+	          ex.printStackTrace();
+	        } finally {
+	          synchronized (ServerWithGroup.class) {
+	            ServerWithGroup.setIsprocess(false);
+	            ServerWithGroup.setIschangetable(false);
+	          }
+	        }
+	      }
+	    }
+	  }
+
+	  final String groupinfofilename = "groupinformation.conf";
+	  HMaster master = (HMaster) getServletContext().getAttribute(
+	      HMaster.MASTER);
+	  Map<String, List<String>> groupmap = new HashMap<String, List<String>>();
+	  String line = "";
+	  boolean isprocess = ServerWithGroup.isIsprocess();
+	  if (isprocess) {
+	    out.println("<script type=\"text/javascript\">");
+	    out.println("alert(\"System busy ,you can't change table group or pripority!!!\")");
+	    out.println("history.back(-1)");
+	    out.println("</script>");
+	    return;
+	  }
+	  try {
+	    line = ServerWithGroup.readGroupInfo(master, groupinfofilename);
+	  } catch (IOException ex) {
+	  }
+	  groupmap = ServerWithGroup.initGroupMap(master, line);
+	  if (groupmap.size() <= 0) {
+	    out.println("No group Info ,error.......");
+	    return;
+	  }
+	  List<HTableDescriptor> tablelist = ServerWithGroup.listAllTables(master);
+	  HTableDescriptor targettable1 = null;
+	  HTableDescriptor targettable2 = null;
+	  String newgroups = null;
+	  String priority = null;
+	  boolean needchangegrp = false;
+	  boolean needchangepri = false;
+	  for (HTableDescriptor table : tablelist) {
+	    System.out.println("table name is " + table.getNameAsString());
+	    if (request.getParameter(table.getNameAsString() + ".grp") != null) {
+	      newgroups = request.getParameter(table.getNameAsString() + ".grp");
+	      if (newgroups.length() <= 0)
+	        continue;
+	      System.out.println("newgroups is " + newgroups);
+	      targettable1 = table;
+	      needchangegrp = true;
+	      break;
+	    }
+	  }
+	  for (HTableDescriptor table : tablelist) {
+	    if (request.getParameter(table.getNameAsString() + ".pri") != null) {
+	      priority = request.getParameter(table.getNameAsString() + ".pri");
+	      if (priority.length() <= 0)
+	        continue;
+	      System.out.println("priority is " + priority);
+	      targettable2 = table;
+	      needchangepri = true;
+	      break;
+	    }
+	  }
+	  if (targettable1 == null && targettable2 == null) {
+	    out.println("<script type=\"text/javascript\">");
+	    out.println("alert(\"Table don't exist !!!\")");
+	    out.println("history.back(-1)");
+	    out.println("</script>");
+	  }
+	  if (needchangegrp && needchangepri) {
+	    if (!targettable1.equals(targettable2)) {
+	      out.println("<script type=\"text/javascript\">");
+	      out.println("alert(\"Error Table  confuse to change  !!!\")");
+	      out.println("history.back(-1)");
+	      out.println("</script>");
+	      return;
+	    }
+	  }
+	  if (!needchangegrp && !needchangepri) {
+	    out.println("<script type=\"text/javascript\">");
+	    out.println("alert(\"No table to change  !!!\")");
+	    out.println("history.back(-1)");
+	    out.println("</script>");
+	    return;
+	  }
+	  String[] groups = null;
+	  String tablename = null;
+	  if (needchangegrp) {
+	    System.out.println("need change group!!");
+	    tablename = targettable1.getNameAsString();
+	    if (tablename.equals("-ROOT-") || tablename.equals(".META."))
+	      return;
+	    System.out.println("newgroup " + newgroups);
+	    groups = newgroups.split(GroupAssignmentManager.GROUP_SPLITER);
+	    for (String gp : groups) {
+	      System.out.println("group " + gp);
+	      if (!groupmap.keySet().contains(gp)) {
+	        out.println("<script type=\"text/javascript\">");
+	        out.println("alert(\"Error ,This group don't exist!!!\")");
+	        out.println("history.back(-1)");
+	        out.println("</script>");
+	        return;
+	      }
+	      List<String> serverlist = groupmap.get(gp);
+	      if (serverlist.size() <= 0) {
+	        out.println("<script type=\"text/javascript\">");
+	        out.println("alert(\"Error ,This group don't contain regionserver!!!\")");
+	        out.println("history.back(-1)");
+	        out.println("</script>");
+	        return;
+	      }
+	    }
+	  }
+	  if (needchangepri) {
+	    System.out.println("need change priority!!, and priority is "
+	        + priority);
+	    tablename = targettable2.getNameAsString();
+	    try {
+	      int i = Integer.valueOf(priority);
+	      if (i < 1 || i > 10) {
+	        out.println("<script type=\"text/javascript\">");
+	        out.println("alert(\"Error , priority must between 1 and 10 !!!\")");
+	        out.println("history.back(-1)");
+	        out.println("</script>");
+	        return;
+	      }
+	    } catch (Exception ex) {
+	      out.println("<script type=\"text/javascript\">");
+	      out.println("alert(\"Error , Wrong priority format, priority must be int!!!\")");
+	      out.println("history.back(-1)");
+	      out.println("</script>");
+	      return;
+	    }
+	  }
+	  synchronized (ServerWithGroup.class) {
+	    ServerWithGroup.setIsprocess(true);
+	    ServerWithGroup.setIschangetable(true);
+	  }
+	  System.out.println("start change group or priority....,group is "
+	      + groups + " and pripority is " + priority + " and table is "
+	      + tablename);
+	  Thread chtable = new Thread(
+	      new ChangeTableGP(groups, priority, tablename));
+	  chtable.start();
+	  out.println("<script type=\"text/javascript\">");
+	  out.println("alert(\"Process Change table  ,may cost lots of  time ,please wait...\")");
+	  out.println("history.back(-1)");
+	  out.println("</script>");
+	%>
+</body>
+</html>
\ No newline at end of file
diff -uNr hbase-0.90.2/hbase-webapps/master/dogroupbalacne.jsp hbase-0.90.2-local/hbase-webapps/master/dogroupbalacne.jsp
--- hbase-webapps/master/dogroupbalacne.jsp	1970-01-01 08:00:00.000000000 +0800
+++ hbase-webapps/master/dogroupbalacne.jsp	2011-07-27 11:16:54.000000000 +0800
@@ -0,0 +1,71 @@
+<%@ page language="java"
+	import="org.apache.hadoop.hbase.master.GroupAssignmentManager"
+	import="org.apache.hadoop.hbase.allocation.group.ServerWithGroup"
+	contentType="text/html; charset=GB18030" pageEncoding="GB18030"%>
+<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
+<html>
+<head>
+<meta http-equiv="Content-Type" content="text/html; charset=GB18030">
+<title>Balance group</title>
+</head>
+<body>
+	<%
+	/**
+	 * Class used for balance group regions
+	 */
+	class Balancegroup implements Runnable{
+		private String group;
+		public Balancegroup(String group){
+			this.group = group;
+		}
+		public void run(){
+			try {
+				ServerWithGroup.setIserror(false);
+				synchronized(GroupAssignmentManager.class){
+					GroupAssignmentManager.balanceGroup(group);
+				}
+			}catch(Exception ex){
+				ServerWithGroup.setIserror(true);
+				ServerWithGroup.setErrormsg("Group Balance error ,please check log...");
+				ex.printStackTrace();
+			}finally{
+				synchronized (ServerWithGroup.class) {
+					ServerWithGroup.setIsprocess(false);
+					ServerWithGroup.setIsbalance(false);
+				}
+			}
+		}
+	}
+%>
+	<%
+	boolean isprocess = ServerWithGroup.isIsprocess();
+	if (!isprocess) {
+		if (request.getParameter("groupname") != null) {
+			String group = request.getParameter("groupname");
+			
+			//start a thread
+			synchronized (ServerWithGroup.class) {
+				ServerWithGroup.setIsprocess(true);
+				ServerWithGroup.setIsbalance(true);
+			}
+			Thread balancethread = new Thread(new Balancegroup(group));
+			balancethread.start();
+			out.println("<script type=\"text/javascript\">");
+			out.println("alert(\"Balance group "+ group +" ............\")");
+			out.println("window.location.href='groupinfo.jsp?groupname="+group+"'");
+			out.println("</script>");
+		}else{
+			out.println("<script type=\"text/javascript\">");
+			out.println("alert(\"Error, Set groupname first ............\")");
+			out.println("history.back(-1)");
+			out.println("</script>");
+		}
+	}else{
+		out.println("<script type=\"text/javascript\">");
+		out.println("alert(\"Wait, System busy............\")");
+		out.println("history.back(-1)");
+		out.println("</script>");
+	}
+%>
+</body>
+</html>
\ No newline at end of file
diff -uNr hbase-0.90.2/hbase-webapps/master/dotablebalance.jsp hbase-0.90.2-local/hbase-webapps/master/dotablebalance.jsp
--- hbase-webapps/master/dotablebalance.jsp	1970-01-01 08:00:00.000000000 +0800
+++ hbase-webapps/master/dotablebalance.jsp	2011-07-27 11:16:58.000000000 +0800
@@ -0,0 +1,150 @@
+<%@ page language="java" import="java.util.*"
+	import="org.apache.hadoop.hbase.master.GroupAssignmentManager"
+	import="org.apache.hadoop.hbase.allocation.group.ServerWithGroup"
+	import="org.apache.hadoop.hbase.master.HMaster"
+	import="org.apache.hadoop.hbase.HRegionInfo"
+	import="org.apache.hadoop.hbase.HServerInfo"
+	import="org.apache.hadoop.hbase.util.Bytes"
+	import="org.apache.hadoop.hbase.UnknownRegionException"
+	import="org.apache.hadoop.hbase.MasterNotRunningException"
+	import="org.apache.hadoop.hbase.ZooKeeperConnectionException"
+	import="org.apache.hadoop.hbase.HTableDescriptor"
+	contentType="text/html; charset=GB18030" pageEncoding="GB18030"%>
+<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
+<html>
+<head>
+<meta http-equiv="Content-Type" content="text/html; charset=GB18030">
+<link rel="stylesheet" type="text/css" href="/static/hbase.css" />
+<title>Table balance</title>
+</head>
+<body>
+	<a id="logo" href="http://wiki.apache.org/lucene-hadoop/Hbase"><img
+		src="/static/hbase_logo_med.gif" alt="HBase Logo" title="HBase Logo" />
+	</a>
+	<h1 id="page_title">Table Balance</h1>
+	<p id="links_menu">
+		<a href="/master.jsp">Master</a>,<a href="/logs/">Local logs</a>, <a
+			href="/stacks">Thread Dump</a>, <a href="/logLevel">Log Level</a>,<a
+			href="showgroup.jsp">Group Information</a>
+	</p>
+
+	<hr id="head_rule" />
+	<%
+	  /**
+	   * Class used for balance table regions
+	   */
+	  class Balancetable implements Runnable {
+	    private String table;
+
+	    public Balancetable(String table) {
+	      this.table = table;
+	    }
+
+	    public void run() {
+	      try {
+	        ServerWithGroup.setIserror(false);
+	        synchronized (GroupAssignmentManager.class) {
+	          GroupAssignmentManager.balanceTable(table);
+	        }
+	      } catch (Exception ex) {
+	        ServerWithGroup.setIserror(true);
+	        ServerWithGroup.setErrormsg("Table " + table
+	            + " Balance error ,please check log...");
+	        ex.printStackTrace();
+	      } finally {
+	        synchronized (ServerWithGroup.class) {
+	          ServerWithGroup.setIsprocess(false);
+	          ServerWithGroup.setIsbalance(false);
+	        }
+	      }
+	    }
+	  }
+	%>
+	<%
+	  String table = "";
+	  if (request.getParameter("tablename") != null) {
+	    table = request.getParameter("tablename");
+	  } else {
+	    out.println("<script type=\"text/javascript\">");
+	    out.println("alert(\"Error, Set tablename first ............\")");
+	    out.println("window.location.href='showgroup.jsp'");
+	    out.println("</script>");
+	  }
+	  HMaster master = (HMaster) getServletContext().getAttribute(
+	      HMaster.MASTER);
+	  List<HServerInfo> availalbeserver = GroupAssignmentManager
+	      .getAvailableServer(table);
+	  Map<String, Integer> balancestate = new HashMap<String, Integer>();
+	  int totalregion = 0;
+	  int totalserver = 0;
+	  boolean finishedbalance = true;
+	  for (HServerInfo info : availalbeserver) {
+	    String servername = info.getHostname() + ","
+	        + info.getServerAddress().getPort();
+	    int size = ServerWithGroup
+	        .getRegionOfTableOnServer(master, table, info);
+	    balancestate.put(servername, size);
+	    totalregion += size;
+	    totalserver += 1;
+	  }
+	  if (totalregion == 0 || totalserver == 0) {
+	    out.println("<br>No region available in this table<br>");
+	  } else {
+	    int min = totalregion / totalserver;
+	    int max = min + GroupAssignmentManager.div;
+	    for (Map.Entry<String, Integer> entry : balancestate.entrySet()) {
+	      int size = entry.getValue();
+	      if (size < min || size > max) {
+	        finishedbalance = false;
+	        break;
+	      }
+	    }
+	  }
+	  boolean isprocess = ServerWithGroup.isIsprocess();
+	  if (!isprocess) {
+	    //start a thread
+	    if (finishedbalance == false) {
+	      synchronized (ServerWithGroup.class) {
+	        ServerWithGroup.setIsprocess(true);
+	        ServerWithGroup.setIsbalance(true);
+	      }
+	      Thread balancethread = new Thread(new Balancetable(table));
+	      balancethread.start();
+	    } else {
+	      out.println("<script type=\"text/javascript\">");
+	      out.println("alert(\"This table is balanced already.\")");
+	      out.println("</script>");
+	    }
+	  }
+	  if (ServerWithGroup.isIsbalance()) {
+	    if (finishedbalance == false) {
+	      out.println("<br>Warning, System is busy<br>");
+	      out.println("<form name='flushform' action='#' method=post>");
+	      out.println("<input type=submit name=submit value=Refresh style=\"width:200px;height:100px\" >");
+	      out.println("</form><br>");
+	    }
+	  }
+	  boolean haserror = ServerWithGroup.isIserror();
+	  if (haserror) {
+	    out.println("<br>" + ServerWithGroup.getErrormsg() + "<br>");
+	  }
+	  out.println("<h4>Table name :" + table + "</h4>");
+	  if (finishedbalance) {
+	    out.println("<br>Table is balanced already ,<a href=\"showgroup.jsp\">Back to Home</a> <br><br>");
+	  }
+	  out.println("<TABLE BORDER=1>");
+	  out.println("<TR><TD>Servername</TD>");
+	  out.println("<TD>region num</TD></TR>");
+
+	  for (HServerInfo info : availalbeserver) {
+	    String servername = info.getHostname() + ","
+	        + info.getServerAddress().getPort();
+	    int size = ServerWithGroup
+	        .getRegionOfTableOnServer(master, table, info);
+	    out.println("<TR><TD>" + servername + "</TD>");
+	    out.println("<TD>(" + size + ")</TD></TR>");
+	  }
+	  out.println("</TABLE>");
+	%>
+</body>
+</html>
\ No newline at end of file
diff -uNr hbase-0.90.2/hbase-webapps/master/groupinfo.jsp hbase-0.90.2-local/hbase-webapps/master/groupinfo.jsp
--- hbase-webapps/master/groupinfo.jsp	1970-01-01 08:00:00.000000000 +0800
+++ hbase-webapps/master/groupinfo.jsp	2011-07-27 11:17:03.000000000 +0800
@@ -0,0 +1,174 @@
+<%@ page language="java" import="java.util.*" import="java.io.*"
+	import="org.apache.hadoop.hbase.master.HMaster"
+	import="org.apache.hadoop.hbase.HTableDescriptor"
+	import="org.apache.hadoop.hbase.HRegionInfo"
+	import="org.apache.hadoop.hbase.HServerAddress"
+	import="org.apache.hadoop.hbase.HServerInfo"
+	import="org.apache.hadoop.hbase.util.Bytes"
+	import="org.apache.hadoop.hbase.allocation.group.ServerWithGroup"
+	import="org.apache.hadoop.hbase.ipc.ScheduleHBaseServer"
+	import="org.apache.hadoop.hbase.master.GroupAssignmentManager"
+	contentType="text/html; charset=GB18030" pageEncoding="GB18030"%>
+<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
+<html>
+<head>
+<meta http-equiv="Content-Type" content="text/html; charset=GB18030">
+<title>Group Information Detail</title>
+<link rel="stylesheet" type="text/css" href="/static/hbase.css" />
+</head>
+<body>
+	<a id="logo" href="http://wiki.apache.org/lucene-hadoop/Hbase"><img
+		src="/static/hbase_logo_med.gif" alt="HBase Logo" title="HBase Logo" />
+	</a>
+	<h1 id="page_title">Detail Group Info</h1>
+	<p id="links_menu">
+		<a href="/master.jsp">Master</a>,<a href="/logs/">Local logs</a>, <a
+			href="/stacks">Thread Dump</a>, <a href="/logLevel">Log Level</a>,<a
+			href="showgroup.jsp">Group Information</a>
+	</p>
+	<hr id="head_rule" />
+	<%
+	  final String defaultgroup = "0";
+	  final String groupinfofilename = "groupinformation.conf";
+	  boolean isprocess = ServerWithGroup.isIsprocess();
+	  if (isprocess) {
+	    if (ServerWithGroup.isIschangetable()) {
+	      out.println("<br>System is change table...........");
+	      out.println("<form name='flushform' action='#' method=post>");
+	      out.println("<input type=submit name=submit value=Refresh style=\"width:200px;height:80px\" >");
+	      out.println("</form>");
+	    }
+	  }
+	  if (request.getParameter("groupname") != null) {
+	    String group = request.getParameter("groupname");
+	    out.println("<br><h4>Group Detail Information</h4>");
+	    HMaster master = (HMaster) getServletContext().getAttribute(
+	        HMaster.MASTER);
+	    Map<String, List<String>> groupmap = new HashMap<String, List<String>>();
+	    String line = "";
+	    try {
+	      line = ServerWithGroup.readGroupInfo(master, groupinfofilename);
+	    } catch (IOException ex) {
+	    }
+	    groupmap = ServerWithGroup.initGroupMap(master, line);
+	    if (groupmap.size() <= 0) {
+	      out.println("No group Info ,error.......");
+	      return;
+	    }
+
+	    Collection<HServerInfo> servercollect = master.getClusterStatus()
+	        .getServerInfo();
+
+	    List<String> serverlist = groupmap.get(group);
+	    out.println("<h4>  group: " + group + " </h4>");
+	    out.println("Need balance ? <a href=\"dogroupbalacne.jsp?groupname="
+	        + group + "\">balance</a>");
+	    out.println("<br>Server num :" + serverlist.size() + "<br><br>");
+	    String spliter = GroupAssignmentManager.GROUP_SPLITER;
+	    out.println("<TABLE BORDER=1>");
+	    out.println("<TR><TD>Server name</TD>");
+	    out.println("<TD>Server detail</TD>");
+	    out.println("<TD>Table num</TD>");
+	    out.println("<TD>Region num</TD></TR>");
+	    List<HTableDescriptor> tablelist = new ArrayList<HTableDescriptor>();
+	    List<HRegionInfo> regionlist = new ArrayList<HRegionInfo>();
+	    for (String server : serverlist) {
+	      out.println("<TR><TD>Server" + server + "</TD>");
+	      List<HTableDescriptor> tables = ServerWithGroup
+	          .listTableOnRegionServer(master, server);
+	      for (HTableDescriptor table : tables) {
+	        if (!tablelist.contains(table)) {
+	          tablelist.add(table);
+	        }
+	      }
+	      List<HRegionInfo> regions = ServerWithGroup.listRegionOnRegionServer(
+	          master, server);
+	      for (HRegionInfo region : regions) {
+	        if (!regionlist.contains(region)) {
+	          regionlist.add(region);
+	        }
+	      }
+	      HServerInfo regionserver = null;
+	      for (HServerInfo info : servercollect) {
+	        String name = info.getHostname() + ","
+	            + info.getServerAddress().getPort();
+	        if (name.equals(server)) {
+	          regionserver = info;
+	        }
+	      }
+	      out.println("<TD><a href=\"http://" + regionserver.getHostname()
+	          + ":" + regionserver.getInfoPort() + "/regionserver.jsp\">"
+	          + server + "</a></TD>");
+	      out.println("<TD>table num:" + tables.size() + "</TD>");
+	      out.println("<TD>region num:" + regions.size() + "</TD></TR>");
+	    }
+	    out.println("</TABLE>");
+	    out.println("<br><br>Table detail info in this group</br>");
+	    out.println("<br>Total  Table num:" + tablelist.size());
+	    out.println("<br>Total Region num:" + regionlist.size());
+	    out.println("<br>If you want change table group ,new groups must be int ,and must be split with \""
+	        + spliter + "\"<br>");
+	    out.println("<br>The priority of table you want to change must between 1 and 10 ,and small num means high priority.<br>");
+	    if (regionlist.size() <= 0)
+	      return;
+	    out.println("<TABLE BORDER=1>");
+	    out.println("<TR><TD>Table name</TD>");
+	    out.println("<TD>Region num</TD>");
+	    out.println("<TD>Table Priority</TD>");
+	    out.println("<TD>Belong Groups</TD>");
+	    out.println("<TD>Change Groups</TD>");
+	    out.println("<TD>Change Priority</TD>");
+	    out.println("<TD>Submit</TD>");
+	    out.println("<TD>Table Balance</TD></TR>");
+	    out.println("<FORM name=\"tableform\" action=\"changetablegroup.jsp\" method=post >");
+	    for (HTableDescriptor table : tablelist) {
+	      String tableaddress = "http://"
+	          + master.getMasterAddress().getHostname() + ":"
+	          + master.getInfoServer().getPort() + "/table.jsp?name="
+	          + table.getNameAsString();
+	      out.println("<TR><TD><a href=" + tableaddress + ">"
+	          + table.getNameAsString() + "</a></TD>");
+	      int regionnum = 0;
+	      for (HRegionInfo region : regionlist) {
+	        HTableDescriptor regiontable = region.getTableDesc();
+	        if (regiontable.equals(table)) {
+	          regionnum++;
+	        }
+	      }
+	      out.println("<TD>" + regionnum + "</TD>");
+	      byte[] pvalue = table.getValue(Bytes.toBytes("priority"));
+	      if (pvalue == null || pvalue.length <= 0) {
+	        String tablename = table.getNameAsString();
+	        if (tablename.equals("-ROOT-") || tablename.equals(".META.")) {
+	          out.println("<TD>" + ScheduleHBaseServer.highestPri + "</TD>");
+	        } else {
+	          out.println("<TD>" + ScheduleHBaseServer.defaultPri + "</TD>");
+	        }
+	      } else {
+	        out.println("<TD>" + Bytes.toString(pvalue) + "</TD>");
+	      }
+	      byte[] gvalue = table.getValue(GroupAssignmentManager.GROUP_KEY);
+
+	      if (gvalue != null) {
+	        out.println("<TD>" + Bytes.toString(gvalue) + "</TD>");
+	      } else {
+	        out.println("<TD>null</TD>");
+	      }
+	      String tablename = table.getNameAsString();
+	      if (!tablename.equals("-ROOT-") && !tablename.equals(".META.")) {
+	        out.println("<TD><input type=text name=" + table.getNameAsString()
+	            + ".grp size=5 style=\"width:80%\"></TD>");
+	        out.println("<TD><input type=text name=" + table.getNameAsString()
+	            + ".pri size=5 style=\"width:80%\"></TD>");
+	        out.println("<TD><input type=submit name='changetable' value='ChangeTable'></TD>");
+	        out.println("<TD><a href=dotablebalance.jsp?tablename="
+	            + table.getNameAsString() + ">balacne</a></TD>");
+	      }
+	      out.println("</TR>");
+	    }
+	    out.println("</FORM>");
+	    out.println("</TABLE>");
+	  }
+	%>
+</body>
+</html>
\ No newline at end of file
diff -uNr hbase-0.90.2/hbase-webapps/master/moveremoteconf.sh hbase-0.90.2-local/hbase-webapps/master/moveremoteconf.sh
--- hbase-webapps/master/moveremoteconf.sh	1970-01-01 08:00:00.000000000 +0800
+++ hbase-webapps/master/moveremoteconf.sh	2011-07-27 11:23:08.000000000 +0800
@@ -0,0 +1,38 @@
+#!/bin/bash
+#Filename: moveremoteconf.sh
+
+server=$1
+confdir=$2
+hbasedir=$3
+command=$4
+filename=`basename $confdir`
+libdir="$hbasedir/lib"
+dirname=`dirname $confdir`
+
+if [ "$command" = "get" ]
+then
+	#clean hbase-conf hbase lib
+	rm -fr $filename
+	rm -fr lib
+	rm -f  hbase-*.jar
+	#get hbase-conf
+	scp -r $server:$confdir $filename
+	scp -r $server:$libdir lib
+	scp -r $server:$hbasedir/hbase-*.jar .
+elif [ "$command" = "put" ]
+then
+	#put hbase-conf,hbase lib 
+	ssh $server "cd $dirname; mv $filename $filename.back; cd $hbasedir; mv lib lib.back; rm -f hbase-*.jar"
+	scp -r $filename $server:${dirname}/
+	scp -r lib $server:${hbasedir}/
+	scp -r hbase-*.jar $server:${hbasedir}/
+	rm -fr $filename
+        rm -fr lib
+        rm -f  hbase-*.jar
+elif [ "$command" = "distribute" ]
+then
+	#distribute hbase-site.xml to server
+	filename="hbase-site.xml"
+	scp -r $filename $server:$confdir/
+	rm -f $filename
+fi
diff -uNr hbase-0.90.2/hbase-webapps/master/processgroup.jsp hbase-0.90.2-local/hbase-webapps/master/processgroup.jsp
--- hbase-webapps/master/processgroup.jsp	1970-01-01 08:00:00.000000000 +0800
+++ hbase-webapps/master/processgroup.jsp	2011-07-27 11:17:13.000000000 +0800
@@ -0,0 +1,256 @@
+<%@ page language="java" import="java.util.*" import="java.io.*"
+	import="org.apache.hadoop.hbase.master.HMaster"
+	import="org.apache.hadoop.hbase.HRegionInfo"
+	import="org.apache.hadoop.hbase.HServerInfo"
+	import="org.apache.hadoop.hbase.util.Bytes"
+	import="org.apache.hadoop.hbase.UnknownRegionException"
+	import="org.apache.hadoop.hbase.MasterNotRunningException"
+	import="org.apache.hadoop.hbase.ZooKeeperConnectionException"
+	import="org.apache.hadoop.hbase.HTableDescriptor"
+	import="org.apache.hadoop.hbase.master.GroupAssignmentManager"
+	import="org.apache.hadoop.hbase.allocation.group.ServerWithGroup"
+	import="org.apache.hadoop.hbase.allocation.group.MoveGroupPlan"
+	import="org.apache.hadoop.hbase.allocation.group.MoveConfImpl"
+	import="org.apache.hadoop.hbase.allocation.group.ProcessMove"
+	contentType="text/html; charset=GB18030" pageEncoding="GB18030"%>
+<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
+<html>
+<head>
+<meta http-equiv="Content-Type" content="text/html; charset=GB18030">
+<title>Process Group</title>
+</head>
+<body>
+	<%
+	  final String DEFAULT_GROUP = "0";
+	  final String groupinfofilename = "groupinformation.conf";
+	  HMaster master = (HMaster) getServletContext().getAttribute(
+	      HMaster.MASTER);
+	  Map<String, List<String>> groupmap = new HashMap<String, List<String>>();
+	  Map<String, Boolean> grouppropertymap = new HashMap<String, Boolean>();
+	  boolean isprocess = ServerWithGroup.isIsprocess();
+	  //out.println("Is moving regionservers ??? "+isprocess);
+	  if (!isprocess) {
+	    //get groupmap from hdfs
+	    String line = "";
+	    try {
+	      line = ServerWithGroup.readGroupInfo(master, groupinfofilename);
+	    } catch (IOException ex) {
+	    }
+	    groupmap = ServerWithGroup.initGroupMap(master, line);
+	    grouppropertymap = ServerWithGroup.initGroupPropertyMap(master, line);
+	    if (!grouppropertymap.keySet().contains(DEFAULT_GROUP)) {
+	      grouppropertymap.put(DEFAULT_GROUP, false);
+	    }
+	    if (groupmap.size() <= 0) {
+	      out.println("No group Info ,error.......");
+	      return;
+	    }
+	    boolean modifygroup = false;
+	    //add group
+	    if (request.getParameter("addnewgroup") != null) {
+	      String newgroup = request.getParameter("addnewgroup");
+	      Set<String> grouplist = groupmap.keySet();
+	      if (!grouplist.contains(newgroup)) {
+	        if (newgroup.length() > 0) {
+	          modifygroup = true;
+	          groupmap.put(newgroup, new ArrayList<String>());
+	          if (request.getParameter("setgroupproperty") != null) {
+	            grouppropertymap.put(newgroup, true);
+	          } else {
+	            grouppropertymap.put(newgroup, false);
+	          }
+	          out.println("<br>Add group " + newgroup
+	              + " information successfully !!");
+	        }
+	      } else {
+	        out.println("<script type=\"text/javascript\">");
+	        out.println("alert(\"Error , Groupname must be unique , use another groupname!\")");
+	        out.println("window.location.href='showgroup.jsp'");
+	        out.println("</script>");
+	        return;
+	      }
+	    }
+	    //del group
+	    Set<String> grouplist = new HashSet<String>();
+	    for (String group : groupmap.keySet()) {
+	      grouplist.add(group);
+	    }
+	    for (String group : grouplist) {
+	      if (request.getParameter(group + ".del") != null) {
+	        List<String> rgplist = groupmap.get(group);
+	        if (rgplist != null && rgplist.size() > 0) {
+	          out.println("<script type=\"text/javascript\">");
+	          out.println("alert(\"Error , This group is not null ,move regionservers to other group first!!\")");
+	          out.println("window.location.href='showgroup.jsp'");
+	          out.println("</script>");
+	          return;
+	        } else {
+	          modifygroup = true;
+	          groupmap.remove(group);
+	          out.println("<br>Remove  group " + group
+	              + " information successfully !!");
+	        }
+	      }
+	    }
+	    if (modifygroup) {
+	      //write back
+	      ServerWithGroup.writeGroupInfo(master, groupinfofilename, groupmap,
+	          grouppropertymap);
+	      // tell someone else
+	      Thread initthread = new Thread(new Runnable() {
+	        public void run() {
+	          GroupAssignmentManager.initValue(false);
+	        }
+	      });
+	      initthread.start();
+	      out.println("<script type=\"text/javascript\">");
+	      out.println("window.location.href='showgroup.jsp'");
+	      out.println("</script>");
+	      return;
+	    }
+	    // move regionserver group
+	    Set<MoveGroupPlan> movegroupPlanset = new HashSet<MoveGroupPlan>();
+	    for (Map.Entry<String, List<String>> gp : groupmap.entrySet()) {
+	      String originalgroup = gp.getKey();
+	      for (String servername : gp.getValue()) {
+	        if (request.getParameter(servername + ".select") != null) {
+	          String newgroup = request.getParameter(servername + ".select");
+	          if (!newgroup.equals("null")) {
+	            if (originalgroup.equals(DEFAULT_GROUP)) {
+	              if (groupmap.get(originalgroup).size() <= 1) {
+	                out.println("<script type=\"text/javascript\">");
+	                out.println("alert(\"Error , Default group 0 must have at least one regionserver, can't change !!\")");
+	                out.println("window.location.href='showgroup.jsp'");
+	                out.println("</script>");
+	                return;
+	              }
+	            }
+	            MoveGroupPlan newplan = new MoveGroupPlan(servername,
+	                originalgroup, newgroup);
+	            movegroupPlanset.add(newplan);
+	          }
+	        }
+	      }
+	    }
+
+	    //do move
+	    if (movegroupPlanset.size() <= 0) {
+	      return;
+	    } else {
+	      if (movegroupPlanset.size() >= 5) {
+	        out.println("<script type=\"text/javascript\">");
+	        out.println("alert(\"Error , At most change 5 regionserver once,please check carefully!!!\")");
+	        out.println("window.location.href='showgroup.jsp'");
+	        out.println("</script>");
+	        return;
+	      }
+	      boolean haveunmoveableregion = false;
+	      for (MoveGroupPlan plan : movegroupPlanset) {
+	        String servername = plan.getServername();
+	        List<HRegionInfo> regionlist = new ArrayList<HRegionInfo>();
+	        try {
+	          regionlist = ServerWithGroup.listRegionOnRegionServer(master,
+	              servername);
+	          for (HRegionInfo info : regionlist) {
+	            if (info.isMetaRegion() || info.isRootRegion()) {
+	              haveunmoveableregion = true;
+	              break;
+	            }
+	          }
+	        } catch (MasterNotRunningException e1) {
+	          e1.printStackTrace();
+	        } catch (ZooKeeperConnectionException e1) {
+	          e1.printStackTrace();
+	        }
+	        if (haveunmoveableregion)
+	          break;
+	      }
+	      if (haveunmoveableregion) {
+	        out.println("<script type=\"text/javascript\">");
+	        out.println("alert(\"Failure  warning , because theas server has -ROOT- or .META. region, they can not be moved.!!!\")");
+	        out.println("window.location.href='showgroup.jsp'");
+	        out.println("</script>");
+	        return;
+	      }
+	      List<String> willmoveservers = new ArrayList<String>();
+	      for (MoveGroupPlan plan : movegroupPlanset) {
+	        String servername = plan.getServername();
+	        willmoveservers.add(servername);
+	      }
+	      boolean noserverfotable = false;
+	      HTableDescriptor lonetable = null;
+	      for (MoveGroupPlan plan : movegroupPlanset) {
+	        String servername = plan.getServername();
+	        String originalgp = plan.getOriginalgroup();
+	        String targetgp = plan.getTargetgroup();
+	        if (originalgp.equals(targetgp)) {
+	          willmoveservers.remove(servername);
+	          continue;
+	        }
+	        List<HRegionInfo> regionlist = new ArrayList<HRegionInfo>();
+	        try {
+	          regionlist = ServerWithGroup.listRegionOnRegionServer(master,
+	              servername);
+	        } catch (MasterNotRunningException e1) {
+	          e1.printStackTrace();
+	        } catch (ZooKeeperConnectionException e1) {
+	          e1.printStackTrace();
+	        }
+	        if (regionlist == null)
+	          continue;
+	        //find absolate table 
+	        for (HRegionInfo hri : regionlist) {
+	          String tablename = hri.getTableDesc().getNameAsString();
+	          List<HServerInfo> availalbeserver = GroupAssignmentManager
+	              .getAvailableServer(tablename);
+	          List<String> availservernames = new ArrayList<String>();
+	          for (HServerInfo hsr : availalbeserver) {
+	            String name = hsr.getHostname() + ","
+	                + hsr.getServerAddress().getPort();
+	            //cancel will delete server
+	            if (!willmoveservers.contains(name)) {
+	              availservernames.add(name);
+	            }
+	          }
+	          if (availservernames.size() <= 0) {
+	            noserverfotable = true;
+	            lonetable = hri.getTableDesc();
+	            break;
+	          }
+	        }
+	        if (noserverfotable) {
+	          break;
+	        }
+	      }
+	      if (noserverfotable) {
+	        out.println("<script type=\"text/javascript\">");
+	        out.println("alert(\"Failure  warning , because the table "
+	            + lonetable.getNameAsString()
+	            + " has no available regionserver, you can change its group property first ,and then change this regionserver's group!!!\")");
+	        out.println("window.location.href='showgroup.jsp'");
+	        out.println("</script>");
+	        return;
+	      }
+	      //start a thread
+	      synchronized (ServerWithGroup.class) {
+	        ServerWithGroup.setIsprocess(true);
+	        ServerWithGroup.setIsmoveregion(true);
+	      }
+	      String currentdir = request.getRealPath("/");
+	      ProcessMove pgromove = new ProcessMove(movegroupPlanset, groupmap,
+	          grouppropertymap, master, currentdir);
+	      Thread movethread = new Thread(pgromove);
+	      movethread.start();
+	      out.println("<script type=\"text/javascript\">");
+	      out.println("alert(\"System is processing move group,please wait...\")");
+	      out.println("window.location.href='showgroup.jsp'");
+	      out.println("</script>");
+	    }
+	  }
+	  out.println("<script type=\"text/javascript\">");
+	  out.println("alert(\"System busy ,wait move group process over !!!\")");
+	  out.println("history.back(-1)");
+	  out.println("</script>");
+	%>
+</body>
+</html>
\ No newline at end of file
diff -uNr hbase-0.90.2/hbase-webapps/master/restartserver.sh hbase-0.90.2-local/hbase-webapps/master/restartserver.sh
--- hbase-webapps/master/restartserver.sh	1970-01-01 08:00:00.000000000 +0800
+++ hbase-webapps/master/restartserver.sh	2011-07-27 11:23:08.000000000 +0800
@@ -0,0 +1,16 @@
+#!/bin/bash
+#Filename: restartserver.sh
+
+server=$1
+hbasedir=$2
+command=$3
+
+if [ "$command" = "start" ]
+then	
+	START="$hbasedir/bin/hbase-daemon.sh start regionserver"
+	ssh $server $START
+elif [ "$command" = "stop" ]
+then
+	STOP="$hbasedir/bin/hbase-daemon.sh stop regionserver"
+	ssh $server $STOP
+fi
diff -uNr hbase-0.90.2/hbase-webapps/master/showgroup.jsp hbase-0.90.2-local/hbase-webapps/master/showgroup.jsp
--- hbase-webapps/master/showgroup.jsp	1970-01-01 08:00:00.000000000 +0800
+++ hbase-webapps/master/showgroup.jsp	2011-07-27 11:18:07.000000000 +0800
@@ -0,0 +1,229 @@
+<%@ page language="java" import="java.util.*" import="java.io.*"
+	import="org.apache.hadoop.hbase.master.HMaster"
+	import="org.apache.hadoop.hbase.HTableDescriptor"
+	import="org.apache.hadoop.hbase.HRegionInfo"
+	import="org.apache.hadoop.hbase.HServerAddress"
+	import="org.apache.hadoop.hbase.HServerInfo"
+	import="org.apache.hadoop.hbase.allocation.group.ServerWithGroup"
+	import="org.apache.hadoop.hbase.allocation.group.MoveGroupPlan"
+	contentType="text/html; charset=GB18030" pageEncoding="GB18030"%>
+<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
+<html>
+<head>
+<meta http-equiv="Content-Type" content="text/html; charset=GB18030">
+<title>Show Regionserver With Group</title>
+<link rel="stylesheet" type="text/css" href="/static/hbase.css" />
+<script type="text/javascript">
+	function validate_moveform() {
+		var result = confirm("Do you want to change regionserver's group information??");
+		if (result == true) {
+			return true;
+		} else {
+			return false;
+		}
+	}
+</script>
+</head>
+<body>
+	<a id="logo" href="http://wiki.apache.org/lucene-hadoop/Hbase"><img
+		src="/static/hbase_logo_med.gif" alt="HBase Logo" title="HBase Logo" />
+	</a>
+	<h1 id="page_title">Show Regionserver Group Information</h1>
+	<p id="links_menu">
+		<a href="/master.jsp">Master</a>,<a href="/logs/">Local logs</a>, <a
+			href="/stacks">Thread Dump</a>, <a href="/logLevel">Log Level</a>,<a
+			href="showgroup.jsp">Group Information</a>
+	</p>
+	<hr id="head_rule" />
+	<%
+	  final String DEFAULT_GROUP = "0";
+	  final String groupinfofilename = "groupinformation.conf";
+	  HMaster master = (HMaster) getServletContext().getAttribute(
+	      HMaster.MASTER);
+	  Collection<HServerInfo> servercollect = master.getClusterStatus()
+	      .getServerInfo();
+	  Map<String, List<String>> groupmap = new HashMap<String, List<String>>();
+	  Map<String, Boolean> grouppropertymap = new HashMap<String, Boolean>();
+
+	  if (ServerWithGroup.isIserror()) {
+	    out.println("<script type=\"text/javascript\">");
+	    out.println("alert(\"Failure  warning , "
+	        + ServerWithGroup.getErrormsg() + "!!!\")");
+	    out.println("window.location.href='showgroup.jsp'");
+	    out.println("</script>");
+	    ServerWithGroup.setIserror(false);
+	    return;
+	  }
+	  boolean isprocess = ServerWithGroup.isIsprocess();
+	  if (isprocess) {
+	    out.println("<TABLE BORDER=1 ALIGN=\"center\" WIDTH=\"60%\">");
+	    out.println("<TR><TD>System is busy , you can't do any other operations.</TD></TR>");
+	    if (ServerWithGroup.isIsmoveregion()) {
+	      Set<MoveGroupPlan> movegroupPlanset = ServerWithGroup
+	          .getMovegroupPlanset();
+	      String currentserver = ServerWithGroup.getCurrentserver();
+	      boolean doMoveconf = ServerWithGroup.isDoMoveconf();
+	      out.println("<TR><TD>Change Regionserver Plan</TD></TR>");
+
+	      for (MoveGroupPlan plan : movegroupPlanset) {
+	        String servername = plan.getServername();
+	        String originalgp = plan.getOriginalgroup();
+	        String targetgp = plan.getTargetgroup();
+	        ServerWithGroup.setCurrentserver(servername);
+	        out.println("<TR><TD>Move " + servername + " form " + originalgp
+	            + " to " + targetgp + "</TD>");
+
+	        int remainsize = 0;
+	        if (!plan.getStatus()) {
+	          List<HRegionInfo> regionlist = ServerWithGroup
+	              .listRegionOnRegionServer(master, servername);
+	          remainsize = regionlist.size();
+	        }
+	        out.println("<TD>Remaining Region num :" + remainsize
+	            + "</TD></TR>");
+	        if (servername.equals(currentserver) && doMoveconf) {
+	          out.println("<TR><TD>Update configuration</TD></TR>");
+	        }
+	      }
+	    } else if (ServerWithGroup.isIsbalance()) {
+	      out.println("<TR><TD>Waiting ,system is balance group or table</TD></TR>");
+	    } else if (ServerWithGroup.isIschangetable()) {
+	      out.println("<TR><TD>Waiting ,system is change table group or table priority</TD></TR>");
+	    }
+	    out.println("<TR><TD><form name='flushform' action='#' method=post>");
+	    out.println("<input type=submit name=submit value=Refresh style=\"width:60%;height:30px\" >");
+	    out.println("</form></TD></TR></TABLE>");
+	  }
+	  String line = "";
+	  try {
+	    line = ServerWithGroup.readGroupInfo(master, groupinfofilename);
+	  } catch (IOException ex) {
+	  }
+	  groupmap = ServerWithGroup.initGroupMap(master, line);
+	  grouppropertymap = ServerWithGroup.initGroupPropertyMap(master, line);
+	  if (!grouppropertymap.keySet().contains(DEFAULT_GROUP)) {
+	    grouppropertymap.put(DEFAULT_GROUP, false);
+	  }
+	  if (groupmap.size() <= 0) {
+	    out.println("No group Info ,error.......");
+	    out.println("alert(\"No group Info ,error.......!!!\")");
+	    return;
+	  }
+	  //show groups
+	  //show group list
+	  out.println("<form name=groupform action=\"processgroup.jsp\" method=post>");
+	  out.println("<TABLE BORDER=1 ALIGN=\"center\" WIDTH=\"60%\">");
+	  out.println("<CAPTION><h2>List Group</h2></CAPTION>");
+	  out.println("<TR>");
+	  out.println("<TD>Group name</TD>");
+	  out.println("<TD>Special Configuration</TD>");
+	  out.println("<TD>Server num</TD>");
+	  out.println("<TD>Region num</TD>");
+	  out.println("<TD>Action</TD>");
+	  out.println("<TD>Change Group Configuration Or Restart Group</TD>");
+	  out.println("</TR>");
+	  out.println("<TR>");
+	  Map<String, Integer> servermap = new HashMap<String, Integer>();
+	  for (String gp : groupmap.keySet()) {
+	    int servernum = groupmap.get(gp).size();
+	    if (!servermap.keySet().contains(gp)) {
+	      servermap.put(gp, servernum);
+	    } else {
+	      Integer orinum = servermap.get(gp);
+	      servermap.put(gp, servernum + orinum);
+	    }
+	  }
+	  //out.println("Group size :"+groupmap.keySet().size());
+	  for (String gp : groupmap.keySet()) {
+	    boolean isspecial = grouppropertymap.get(gp);
+	    out.println("<TR>");
+	    out.println("<TD><a href=\"groupinfo.jsp?groupname=" + gp
+	        + "\">group:   " + gp + "</a></TD>");
+	    out.println("<TD>" + isspecial + "</TD>");
+	    int servernum = servermap.get(gp);
+	    out.println("<TD ><font color=blue>(" + servernum + ")</font></TD> ");
+	    int regionsize = ServerWithGroup.getRegionNumOnGroup(master, gp,
+	        groupmap);
+	    out.println("<TD ><font color=black>(" + regionsize + ")</font></TD> ");
+	    if (!gp.equals(DEFAULT_GROUP)) {
+	      out.println("<TD><input type=submit name=" + gp
+	          + ".del value=Delete ></TD>");
+	      out.println("<TD><a href='changegroupconf.jsp'>Change</a></TD>");
+	    } else {
+	      out.println("<TD>default group</TD>");
+	      out.println("<TD></TD>");
+	    }
+
+	    out.println("</TR>");
+	  }
+	  out.println("<TR>");
+	  out.println("<TD>Add Group:</TD>");
+	  out.println("<TD><input type=text name=addnewgroup></TD>");
+	  out.println("<TD>Special ?<input type=checkbox name=setgroupproperty ></TD>");
+	  out.println("<TD></TD>");
+	  out.println("<TD><input type=submit name=groupchange value=AddNew></TD>");
+	  out.println("</TR>");
+	  out.println("</form>");
+	  out.println("<br><br>");
+	  //show regionserver groups
+	  out.println("<form name=serverform action=\"processgroup.jsp\" method=post onSubmit=\"return validate_moveform()\">");
+
+	  out.println("<TABLE BORDER=1 ALIGN=\"center\" WIDTH=\"60%\">");
+	  out.println("<CAPTION><h2>RegionServer Group</h2></CAPTION>");
+	  out.println("<TR>");
+	  out.println("<TD>Region Server name</TD>");
+	  out.println("<TD>Request num</TD>");
+	  out.println("<TD>Region num</TD>");
+	  out.println("<TD>Original Group</TD>");
+	  out.println("<TD>Update to New Group</TD>");
+	  out.println("</TR>");
+	  for (Map.Entry<String, List<String>> entry : groupmap.entrySet()) {
+	    String group = entry.getKey();
+	    List<String> gplist = entry.getValue();
+	    if (gplist.size() <= 0)
+	      continue;
+	    String[] gparray = gplist.toArray(new String[gplist.size()]);
+	    Arrays.sort(gparray, new Comparator<String>() {
+	      public int compare(String left, String right) {
+	        return left.compareTo(right);
+	      }
+	    });
+	    for (String server : gplist) {
+	      out.println("<TR>");
+	      HServerInfo regionserver = null;
+	      for (HServerInfo info : servercollect) {
+	        String name = info.getHostname() + ","
+	            + info.getServerAddress().getPort();
+	        if (name.equals(server)) {
+	          regionserver = info;
+	        }
+	      }
+	      out.println("<TD><a href=\"http://" + regionserver.getHostname()
+	          + ":" + regionserver.getInfoPort() + "/regionserver.jsp\">"
+	          + server + "</a></TD>");
+	      out.println("<TD>" + regionserver.getLoad().getNumberOfRequests()
+	          + "</TD>");
+	      out.println("<TD>" + regionserver.getLoad().getNumberOfRegions()
+	          + "</TD>");
+	      out.println("<TD>" + group + "</TD>");
+	      out.println("<TD><select name=" + server
+	          + ".select size=1 style=\"width:80%\">");
+	      out.println("<option value=null> </option>");
+	      for (String gp : groupmap.keySet()) {
+	        if (!gp.equals(group)) {
+	          out.println("<option value=" + gp + " >" + gp + "</option>");
+	        }
+	      }
+	      out.println("</select></TD>");
+	      out.println("</TR>");
+	    }
+	  }
+	  out.println("<TR>");
+	  out.println("<TD></TD><TD></TD><TD></TD><TD></TD>");
+	  out.println("<TD><input type=submit name=regionserverupdate value=UpdateRegionserverGroup style=\"width:80%;height:30px\"></TD>");
+	  out.println("</TR>");
+	  out.println("</TABLE>");
+	  out.println("</form>");
+	%>
+</body>
+</html>
\ No newline at end of file
Binary files hbase-0.90.2/lib/hbase-0.90.2.jar and hbase-0.90.2-local/lib/hbase-0.90.2.jar differ
diff -uNr hbase-0.90.2/src/main/java/org/apache/hadoop/hbase/allocation/CheckMeta.java hbase-0.90.2-local/src/main/java/org/apache/hadoop/hbase/allocation/CheckMeta.java
--- src/main/java/org/apache/hadoop/hbase/allocation/CheckMeta.java	1970-01-01 08:00:00.000000000 +0800
+++ src/main/java/org/apache/hadoop/hbase/allocation/CheckMeta.java	2011-07-20 11:41:12.000000000 +0800
@@ -0,0 +1,284 @@
+/**
+ * Copyright 2010 The Apache Software Foundation
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.hbase.allocation;
+import java.io.IOException;
+import java.util.HashMap;
+import java.util.TreeSet;
+import java.util.WeakHashMap;
+import java.util.Map.Entry;
+
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.hbase.HConstants;
+import org.apache.hadoop.hbase.HRegionInfo;
+import org.apache.hadoop.hbase.HServerAddress;
+import org.apache.hadoop.hbase.HServerInfo;
+import org.apache.hadoop.hbase.HTableDescriptor;
+import org.apache.hadoop.hbase.client.HTable;
+import org.apache.hadoop.hbase.client.Result;
+import org.apache.hadoop.hbase.client.ResultScanner;
+import org.apache.hadoop.hbase.client.Scan;
+import org.apache.hadoop.hbase.util.Bytes;
+import org.apache.hadoop.hbase.util.Writables;
+/**
+ * Get region info in meta table
+ * 
+ *
+ */
+public class CheckMeta {
+	private static final Log LOG = LogFactory.getLog(CheckMeta.class);
+	static HTable t=null;
+	
+	
+	/**
+	 * get table descriptors.
+	 * @return table descriptors.
+	 */
+	public static HTableDescriptor[] getTables()
+	{	
+		HTableDescriptor[] ret=null;		
+		try {
+			Scan s=new Scan();
+			if(t==null)
+				t=new HTable(".META.");
+			t.setScannerCaching(1000);
+			s.setCaching(1000);
+			ResultScanner sn=t.getScanner(s);
+			Result r=null;
+			final TreeSet<HTableDescriptor> uniqueTables = new TreeSet<HTableDescriptor>();
+			while((r=sn.next()) != null)
+			{
+				byte[] value = r.getValue(HConstants.CATALOG_FAMILY,
+						HConstants.REGIONINFO_QUALIFIER);
+				HRegionInfo info = null;
+				if (value != null) {
+					info = Writables.getHRegionInfo(value);
+				}
+				// Only examine the rows where the startKey is zero length
+				if (info != null && info.getStartKey().length == 0) {
+					uniqueTables.add(info.getTableDesc());
+				}
+			}
+			try {
+				sn.close();
+			} catch (Exception e) {
+				e.printStackTrace();
+			}
+			ret=uniqueTables.toArray(new HTableDescriptor[uniqueTables.size()]);
+			return ret;
+		} catch (IOException e) {
+			e.printStackTrace();
+		}
+		return null;
+	}
+	/**
+	 * test if the server and address  are equal.
+	 * @param server
+	 * @param address
+	 * @return
+	 */
+	public static boolean isThisAddress(HServerInfo server,HServerAddress address)
+	{
+		return server.getServerAddress().getHostname().equals(address.getHostname())&&(server.getServerAddress().getPort()==address.getPort());
+	}
+	/**
+	 * Get region and server infos according to the server informations use sent in
+	 * @param infos method will return the regions which assigned to these servers.
+	 * @param filterOffline need to check if region online.
+	 * @return the region info and the server info which region assigned to 
+	 */
+	public static HashMap<HRegionInfo,HServerInfo> getServerRegions(HServerInfo[] infos,boolean filterOffline)
+	{
+		try {
+			HashMap<HRegionInfo,HServerInfo> ret=new HashMap<HRegionInfo,HServerInfo>();
+			HashMap<HRegionInfo,HServerAddress> regionInfo=getAllRegionInfo();
+			for(HRegionInfo rinfo:regionInfo.keySet())
+			{
+				
+				for(int i=0;i<infos.length;i++)
+				{
+					if(isThisAddress(infos[i],regionInfo.get(rinfo)))
+					{
+						if(filterOffline)
+						{
+							if(rinfo!=null&&!rinfo.isOffline())
+								ret.put(rinfo, infos[i]);
+						}
+						else
+						{
+							ret.put(rinfo, infos[i]);
+						}
+						
+					}
+				}
+			}
+			return ret;
+		} catch (IOException e) {
+			e.printStackTrace();
+		} catch (InterruptedException e) {
+			e.printStackTrace();
+		}
+		
+		return null;
+		
+	}
+//	/**
+//	 * 
+//	 * @param filter
+//	 * @return
+//	 * @throws IOException
+//	 */
+//	public static HashMap<HRegionInfo,HServerAddress> getAllRegionInfo(boolean filter) throws IOException
+//	{
+//		Scan s=new Scan();
+//		if(t==null)
+//			t=new HTable(".META.");
+//		ResultScanner sn=t.getScanner(s);
+//		Result r=null;
+//		HashMap<HRegionInfo, HServerAddress> m=new HashMap<HRegionInfo, HServerAddress>();
+//		while((r=sn.next()) != null)
+//		{
+//			
+//			HRegionInfo info=null;
+//			try {
+//			
+//				info = Writables.getHRegionInfo(
+//				    r.getValue(HConstants.CATALOG_FAMILY,
+//				            HConstants.REGIONINFO_QUALIFIER));
+//				//System.out.println(info);
+//			} catch (Exception e) {
+//				// TODO Auto-generated catch block
+//				//System.out.println(e.getMessage());
+//				//System.out.println(Bytes.toString(r.getRow()));
+//				//t.delete(new Delete(r.getRow()));
+//				//e.printStackTrace();
+//			}
+//			if(info==null)
+//				continue;
+//			HServerAddress server = new HServerAddress();
+//	        byte [] value = r.getValue(HConstants.CATALOG_FAMILY,
+//	            HConstants.SERVER_QUALIFIER);
+//	        if (value != null && value.length > 0) {
+//	          String address = Bytes.toString(value);
+//	          server = new HServerAddress(address);
+//	        }
+// 
+//	        if (!(info.isOffline() || !info.isSplit())) {
+//	          m.put(info, server);
+//	        }
+//		}
+//		try {
+//			sn.close();
+//		} catch (Exception e) {
+//			e.printStackTrace();
+//		}
+//		return m;
+//	}
+
+	/**
+	 * Get all region and server informations from meta table
+	 * @return the region infos
+	 */
+	public static HashMap<HRegionInfo,HServerAddress> getAllRegionInfo() throws IOException, InterruptedException
+	{
+		Scan s=new Scan();
+		if(t==null)
+			t=new HTable(".META.");
+		ResultScanner sn=t.getScanner(s);
+		Result r=null;
+		HashMap<HRegionInfo, HServerAddress> m=new HashMap<HRegionInfo, HServerAddress>();
+		while((r=sn.next()) != null)
+		{
+			
+			HRegionInfo info=null;
+			try {
+			
+				info = Writables.getHRegionInfo(
+				    r.getValue(HConstants.CATALOG_FAMILY,
+				            HConstants.REGIONINFO_QUALIFIER));
+			} catch (Exception e) {
+				LOG.error("There are error rows in meta table:"+r);
+				//TODO: we should fix meta table here.
+			}
+			if(info==null)
+				continue;
+			HServerAddress server = new HServerAddress();
+	        byte [] value = r.getValue(HConstants.CATALOG_FAMILY,
+	            HConstants.SERVER_QUALIFIER);
+	        if (value != null && value.length > 0) {
+	          String address = Bytes.toString(value);
+	          server = new HServerAddress(address);
+	        }
+ 
+	        if ((!(info.isOffline() )&&( !info.isSplit()))) {
+	          m.put(info, server);
+	        }
+		}
+		try {
+			sn.close();
+		} catch (Exception e) {
+			e.printStackTrace();
+		}
+		return m;
+	}
+	/**
+	 * get HRegionInfo and HServerAddress pairs according to the table name 
+	 * @param table table the returned Region belong to.
+	 * @return HRegionInfo and HServerAddress pairs
+	 */
+	public static HashMap<HRegionInfo,HServerAddress> getRegionAddress(String table)
+	{
+		try {
+			return getRegionAddress(table,getAllRegionInfo());
+		} catch (IOException e) {
+			e.printStackTrace();
+		} catch (InterruptedException e) {
+			e.printStackTrace();
+		}
+		return null;
+		
+	}
+	/**
+	 * main test
+	 * @param args
+	 */
+	public static void main(String args[])
+	{
+		System.out.println(getRegionAddress("testPri10"));
+	}
+	/**
+	 * filter region and address pairs according to the table name you send in.
+	 * @param table the returned regions belong to this table
+	 * @param maps the region and address pairs you want to filter
+	 * @return
+	 */
+	public static HashMap<HRegionInfo,HServerAddress> getRegionAddress(String table,HashMap<HRegionInfo,HServerAddress> maps)
+	{
+		HashMap<HRegionInfo, HServerAddress> m=new HashMap<HRegionInfo, HServerAddress>();
+		for(Entry<HRegionInfo, HServerAddress> e:maps.entrySet())
+		{
+			if(e.getKey().getTableDesc().getNameAsString().equals(table))
+				m.put(e.getKey(), e.getValue());
+		}
+		return m;
+	}
+
+
+}
\ No newline at end of file
diff -uNr hbase-0.90.2/src/main/java/org/apache/hadoop/hbase/allocation/ScheduleQueue.java hbase-0.90.2-local/src/main/java/org/apache/hadoop/hbase/allocation/ScheduleQueue.java
--- src/main/java/org/apache/hadoop/hbase/allocation/ScheduleQueue.java	1970-01-01 08:00:00.000000000 +0800
+++ src/main/java/org/apache/hadoop/hbase/allocation/ScheduleQueue.java	2011-07-20 11:41:12.000000000 +0800
@@ -0,0 +1,449 @@
+/**
+ * Copyright 2010 The Apache Software Foundation
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.hbase.allocation;
+
+import java.util.Calendar;
+import java.util.Random;
+import java.util.concurrent.PriorityBlockingQueue;
+import java.util.concurrent.TimeUnit;
+import java.util.concurrent.locks.Condition;
+import java.util.concurrent.locks.ReentrantLock;
+
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.hbase.UnknownScannerException;
+import org.apache.hadoop.hbase.ipc.HBaseRPC.Invocation;
+
+/**
+ * 
+ * this queue is used by {@link ScheduleHBaseServer}
+ * 
+ * @param <T>
+ *            the class contained by the queue
+ * 
+ */
+public class ScheduleQueue<T> {
+	private static final Log LOG = LogFactory.getLog(ScheduleQueue.class);
+	private final PriorityBlockingQueue<Job<T>> queue = new PriorityBlockingQueue<Job<T>>();
+	private int size = 0;
+	private int capacity = 100;
+	private int maxWait = 1000;
+	private boolean running = true;
+	ReentrantLock readLock = new ReentrantLock();
+	Condition[] lockList = new Condition[10];
+	ReentrantLock addLock = new ReentrantLock();
+	Condition queueFull = addLock.newCondition();
+	int lowestThreadPir = 10;
+	boolean verbose = false;
+
+	private void setSize(int size) {
+		this.addLock.lock();
+		this.size = size;
+		if (this.size < this.capacity) {
+			this.queueFull.signalAll();
+		}
+		this.addLock.unlock();
+	}
+
+	private void addSize() {
+		this.addLock.lock();
+		this.size++;
+		this.addLock.unlock();
+	}
+
+	private void decreaseSize() {
+		this.addLock.lock();
+		this.size--;
+		if (this.size < this.capacity) {
+			this.queueFull.signalAll();
+		}
+		this.addLock.unlock();
+	}
+
+	private void testAdd(Job<T> j) {
+		int wait = 0;
+		while (this.size >= this.capacity) {
+			try {
+				addLock.lock();
+				this.queueFull.await(10, TimeUnit.MILLISECONDS);
+				// this.queueFull.await();
+				addLock.unlock();
+				wait++;
+				if (wait > this.maxWait)
+					break;
+			} catch (InterruptedException e) {
+				// TODO Auto-generated catch block
+				e.printStackTrace();
+			}
+		}
+		// readLock.lock();
+		this.queue.add(j);
+		// readLock.unlock();
+		this.addSize();
+
+	}
+
+	private int getSize() {
+		return this.size;
+	}
+
+	private Thread refresher = new Thread() {
+		public void run() {
+			while (running) {
+				refreshIner();
+				try {
+					sleep(1000);
+				} catch (Exception e) {
+
+					// e.printStackTrace();
+				}
+			}
+		}
+	};
+
+	public void stop() {
+		this.running = false;
+	}
+
+	/**
+	 * Init a queue
+	 * 
+	 * @param size
+	 *            the capacity of the queue,not a precision value,if queue size
+	 *            exceed this value, workers which add jobs should wait
+	 * @param lowestPrid
+	 *            the lowest priority which worker thread hold,the default
+	 *            priority is range from 1 to 10,reverse from java thread
+	 *            priority
+	 */
+	public ScheduleQueue(int size, int lowestPrid) {
+
+		this.capacity = size;
+		this.refresher.start();
+		for (int i = 0; i < 10; i++) {
+			lockList[i] = readLock.newCondition();
+		}
+		this.lowestThreadPir = lowestPrid;
+
+	}
+
+	/**
+	 * add a job to this queue
+	 * 
+	 * @param call
+	 *            the job instance
+	 * @param pri
+	 *            the job's priority
+	 */
+	public void add(T call, int pri) {
+		this.testAdd(new Job<T>(pri, call));
+		testHead();
+
+	}
+
+	/**
+	 * get the size of the queue,maintain a integer to indicate the size for
+	 * performance.
+	 * 
+	 * @return the size of the queue
+	 */
+	public int size() {
+		return this.size;
+	}
+
+	/**
+	 * get the size of the queue
+	 * 
+	 * @return the size of the queue
+	 */
+	public int queueSize() {
+		return queue.size();
+	}
+
+	private int getCondition(int pri) {
+		if (pri <= 10 && pri >= 1) {
+			return pri - 1;
+		} else if (pri > 10) {
+			return 9;
+		} else {
+			return 0;
+		}
+	}
+
+	private void testHead() {
+		readLock.lock();
+		Job<T> jobt = queue.peek();
+		if (jobt != null) {
+			if (verbose)
+				System.out.println(Thread.currentThread().getName() + " "
+						+ "begain testHead " + getCondition(jobt.orgPri));
+			if (verbose) {
+				System.out.println(this.queue);
+			}
+			this.lockList[getCondition(jobt.orgPri)].signal();
+			if (verbose)
+				System.out.println(Thread.currentThread().getName() + " "
+						+ "over testHead " + getCondition(jobt.orgPri));
+		}
+		readLock.unlock();
+
+	}
+
+	/**
+	 * if handler's priority lower than job's priority, then this handler can't
+	 * get this job.
+	 * 
+	 * @param job
+	 *            the job which worker want to get
+	 * @param pri
+	 *            the worker thread's priority
+	 * @return should the worker get this job
+	 */
+	public boolean shouldWork(Job<T> job, int pri) {
+		if (job == null)
+			return false;
+		return (pri >= job.orgPri)
+		|| (job.orgPri < 1 && pri == 1)
+		|| (job.orgPri > this.lowestThreadPir && pri == this.lowestThreadPir);
+	}
+
+	/**
+	 *get a job from the queue ,will test whether the thread can get this job
+	 * 
+	 * @param pri
+	 *            the worker thread's priority
+	 * @return the job
+	 * @throws InterruptedException
+	 */
+	public T get(int pri) throws InterruptedException {
+		Job<T> job = null;
+
+		job = queue.peek();
+		while (!shouldWork(job, pri)) {
+			if (verbose)
+				System.out.println(Thread.currentThread().getName() + " "
+						+ "begain wait " + getCondition(pri));
+			readLock.lock();
+			this.lockList[getCondition(pri)].await(100, TimeUnit.MILLISECONDS);
+			readLock.unlock();
+			if (verbose)
+				System.out.println(Thread.currentThread().getName() + " "
+						+ "over wait " + getCondition(pri));
+			job = queue.peek();
+
+		}
+		Job<T> ret = queue.take();
+		if (ret.orgPri > pri && pri != this.lowestThreadPir) {
+
+			System.err.println("error");
+		}
+		this.testHead();
+		if (ret == null) {
+			this.setSize(0);
+			return null;
+		} else {
+			this.decreaseSize();
+			return ret.getCall();
+		}
+	}
+
+	/**
+	 * refresh the priorities of the jobs in queue,simply -1
+	 */
+	public void refresh() {
+		this.refresher.interrupt();
+	}
+
+	static int outputIndicator = 0;
+
+	private void refreshIner() {
+		try {
+			if ((outputIndicator << 58) >>> 58 == 0)
+				LOG.debug(Calendar.getInstance().getTime() + ":" + this.queue);
+			outputIndicator++;
+			for (Job<T> job : queue) {
+				if (job != null) {
+					job.add();
+				}
+			}
+			testHead();
+		} catch (Exception e) {
+			e.printStackTrace();
+		}
+	}
+
+	private void refreshIner(int n) {
+		try {
+			for (Job<T> job : queue) {
+				if (job != null) {
+					job.add(n);
+				}
+			}
+			testHead();
+		} catch (Exception e) {
+			e.printStackTrace();
+		}
+	}
+
+	/**
+	 * 
+	 * The Job hold by queue
+	 * 
+	 * @param <T>
+	 */
+	public static class Job<T> implements Comparable<Job<T>> {
+		int orgPri = 0;
+		int priority = 0;
+		long initTime = 0;
+		T call;
+
+		/**
+		 * increase job's priority
+		 */
+		public void add() {
+			this.priority--;
+		}
+
+		/**
+		 * increase job's priority by n
+		 * 
+		 * @param n
+		 */
+		public void add(int n) {
+
+			this.priority = this.priority - n;
+
+		}
+
+		/**
+		 * get the instance hold by the job
+		 * 
+		 * @return the call instance
+		 */
+		public T getCall() {
+			return call;
+		}
+
+		/**
+		 * set the instance hold byt the job
+		 * 
+		 * @param call
+		 *            the call instance
+		 */
+		public void setCall(T call) {
+			this.call = call;
+		}
+
+		/**
+		 * Initiate a job
+		 * 
+		 * @param pri
+		 *            the job priority
+		 * @param call
+		 *            the instance hold by the job
+		 */
+		public Job(int pri, T call) {
+			this.orgPri = pri;
+			this.priority = pri;
+			this.initTime = System.currentTimeMillis();
+			this.call = call;
+		}
+
+		/**
+		 * print the job
+		 */
+		public String toString() {
+
+			return "orgPri:" + this.orgPri + ", lastPri:" + this.priority
+			+ ", wait time:"
+			+ ((System.currentTimeMillis() - this.initTime)) + ",ino:";
+		}
+
+		@Override
+		public int compareTo(Job<T> arg0) {
+			// TODO Auto-generated method stub
+			return this.priority - arg0.priority;
+		}
+
+	}
+
+	/**
+	 * test the queue's function
+	 * 
+	 * @param args
+	 */
+	public static void main(String args[]) {
+		final Random r = new Random();
+		final ScheduleQueue<String> queue = new ScheduleQueue<String>(100, 10);
+		Thread tt[] = new Thread[50];
+		int pri = 1;
+		for (int i = 0; i < tt.length; i++, pri++) {
+			tt[i] = new Thread(i + "") {
+				public void run() {
+					while (true) {
+						String j = null;
+						try {
+							j = queue
+							.get(Math.abs(this.getPriority() - 10) + 1);
+						} catch (InterruptedException e) {
+							// TODO Auto-generated catch block
+							e.printStackTrace();
+						}
+						System.out.println("thread pri: "
+								+ (Math.abs(this.getPriority() - 10) + 1)
+								+ "  job:" + j + " ,thread real pri is:"
+								+ this.getPriority());
+					}
+				}
+			};
+			if (pri >= 11)
+				pri = 1;
+			tt[i].setPriority(pri);
+			tt[i].start();
+		}
+
+		Thread tt2[] = new Thread[10];
+		for (int i = 0; i < tt2.length; i++) {
+			tt2[i] = new Thread(i + "") {
+				@SuppressWarnings("static-access")
+				public void run() {
+					for (int i = 0; i < 10000000; i++) {
+						System.out.println("add ten jobs...............");
+						for (int j = 0; j < 100000; j++) {
+							int jobpri = (r.nextInt(19) - 4);
+							queue.add("" + jobpri, jobpri);
+
+						}
+						System.out.println(queue.size());
+						try {
+							Thread.currentThread().sleep(r.nextInt(10000));
+						} catch (InterruptedException e) {
+							// TODO Auto-generated catch block
+							e.printStackTrace();
+						}
+					}
+				}
+			};
+			tt2[i].start();
+		}
+
+	}
+
+}
diff -uNr hbase-0.90.2/src/main/java/org/apache/hadoop/hbase/allocation/group/AutoBalance.java hbase-0.90.2-local/src/main/java/org/apache/hadoop/hbase/allocation/group/AutoBalance.java
--- src/main/java/org/apache/hadoop/hbase/allocation/group/AutoBalance.java	1970-01-01 08:00:00.000000000 +0800
+++ src/main/java/org/apache/hadoop/hbase/allocation/group/AutoBalance.java	2011-07-01 13:00:14.000000000 +0800
@@ -0,0 +1,195 @@
+/**
+ * Copyright 2010 The Apache Software Foundation
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.hbase.allocation.group;
+
+import java.io.IOException;
+
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.hbase.Abortable;
+import org.apache.hadoop.hbase.HBaseConfiguration;
+import org.apache.hadoop.hbase.HTableDescriptor;
+import org.apache.hadoop.hbase.MasterNotRunningException;
+import org.apache.hadoop.hbase.ZooKeeperConnectionException;
+import org.apache.hadoop.hbase.client.HBaseAdmin;
+import org.apache.hadoop.hbase.master.GroupAssignmentManager;
+import org.apache.hadoop.hbase.util.Bytes;
+import org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher;
+import org.apache.zookeeper.KeeperException;
+
+/**
+ * Class user for auto balance all tables in hbase start with hbase
+ * 
+ */
+public class AutoBalance {
+	private static Log LOG = LogFactory.getLog(AutoBalance.class);
+	private long period ; 
+	/**
+	 * Construct method
+	 * @param period  , auto balance period , ms
+	 */
+	public AutoBalance( long period) {
+		super();
+		this.period = period;
+	}
+	/**
+	 * Start balance
+	 */
+	public void startBalance(){
+		Thread balancethread = new Thread(new Balance(period));
+		balancethread.start();
+	}
+	/**
+	 * Inner Class for balance all table
+	 * 
+	 */
+	class Balance implements Runnable ,Abortable{
+		private long period;
+		private ZooKeeperWatcher zkw ;
+		Configuration conf = HBaseConfiguration.create();
+		public Balance(long period) {
+			this.period = period;
+			try {
+				zkw = new ZooKeeperWatcher(conf, "BalanceTracker", (Abortable) this);
+				LOG.info("init a new zookeeper watcher !");
+			} catch (ZooKeeperConnectionException e) {
+				e.printStackTrace();
+			} catch (IOException e) {
+				e.printStackTrace();
+			} 
+		}
+		/**
+		 * Check if cluster is running 
+		 * <p>
+		 * if cluster is running ,then read all table from zookeeper , then balance them
+		 */
+		public synchronized void run() {
+			while(!checkClusterIsRunning()){
+				try {
+					Thread.sleep(1000);
+				} catch (InterruptedException e) {
+					e.printStackTrace();
+				}
+			}
+			try {
+				final long SLEEP_WHENSTART = 600000; // 10 minutes
+				Thread.sleep(SLEEP_WHENSTART);
+			} catch (InterruptedException e) {
+				e.printStackTrace();
+			}
+			while (true) {
+				// auto balance all table
+				try {
+					LOG.info("Before Balance table...");
+					balanceAllTable();
+					LOG.info("After Balance table...");
+				} catch (KeeperException e) {
+					e.printStackTrace();
+				} catch (InterruptedException e) {
+					e.printStackTrace();
+				}
+				try {
+					LOG.info("Before Balance sleep...");
+					int numbers = (int) (period/1000)+1;
+					for (int i = 0; i< numbers; i++){
+						// check if cluster  is down
+						Thread.sleep(1000);
+						boolean status = checkClusterIsRunning();
+						if (!status) break;
+					}
+					LOG.info("After  Balance sleep...");
+				} catch (InterruptedException e) {
+					e.printStackTrace();
+				}
+			}
+		}
+		
+		private void balanceAllTable() throws KeeperException, InterruptedException {
+			HBaseAdmin admin = null;
+			try {
+				admin = new HBaseAdmin(conf);
+			} catch (MasterNotRunningException e) {
+				e.printStackTrace();
+				return;
+			} catch (ZooKeeperConnectionException e) {
+				e.printStackTrace();
+				return;
+			}
+			HTableDescriptor[] tablelist = null;
+			try {
+				tablelist = admin.listTables();
+			} catch (IOException e) {
+				e.printStackTrace();
+			}
+			LOG.info("Get all table from client ,and table size is "+tablelist.length);
+			for (HTableDescriptor tabledesc : tablelist){
+				String table = tabledesc.getNameAsString();
+				LOG.info("table name is :"+table);
+				boolean isprocess = ServerWithGroup.isIsprocess();
+				System.out.println("Is  Processing ? " + isprocess);
+				if (!isprocess){
+					LOG.info("Ready to balance table "+ table);
+					synchronized (ServerWithGroup.class) {
+						ServerWithGroup.setIsprocess(true);
+						ServerWithGroup.setIsbalance(true);
+					}
+					synchronized (GroupAssignmentManager.class) {
+						GroupAssignmentManager.balanceTable(table);
+					}
+					synchronized (ServerWithGroup.class) {
+						ServerWithGroup.setIsprocess(false);
+						ServerWithGroup.setIsbalance(false);
+					}
+				LOG.info("After balance table "+ table);
+				}
+			}
+		}
+
+		private boolean checkClusterIsRunning(){
+			String clusterStateZNode =  zkw.clusterStateZNode;
+			byte[] data;
+			try {
+				data = zkw.getZooKeeper().getData(clusterStateZNode, false, null);
+			} catch (KeeperException e) {
+				LOG.debug("when get clusterstate form zookeeper "+e.getMessage());
+				return false;
+			} catch (InterruptedException e) {
+				LOG.debug("when get clusterstate form zookeeper "+e.getMessage());
+				return false;
+			}
+			//LOG.debug("data is "+Bytes.toString(data));
+			if (data!= null){
+				return true;
+			}else {
+				return false;
+			}
+		}
+		@Override
+		public void abort(String arg0, Throwable arg1) {
+			LOG.info("Get exceptuion when auto balance , abort.......");
+		}
+	}
+	
+	public static void main(String[] args){
+		AutoBalance autobalance = new AutoBalance(100000);
+		autobalance.startBalance();
+	}
+}
diff -uNr hbase-0.90.2/src/main/java/org/apache/hadoop/hbase/allocation/group/MoveConfImpl.java hbase-0.90.2-local/src/main/java/org/apache/hadoop/hbase/allocation/group/MoveConfImpl.java
--- src/main/java/org/apache/hadoop/hbase/allocation/group/MoveConfImpl.java	1970-01-01 08:00:00.000000000 +0800
+++ src/main/java/org/apache/hadoop/hbase/allocation/group/MoveConfImpl.java	2011-07-01 14:41:43.000000000 +0800
@@ -0,0 +1,179 @@
+/**
+ * Copyright 2010 The Apache Software Foundation
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.hbase.allocation.group;
+
+import java.io.File;
+import java.io.IOException;
+
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+
+/**
+ * This class is used for update regionserver configuration and library
+ * <p>
+ * It use two shell script in ${hbase_home}/hbase-webapps/master/ ,
+ * moveremoteconf.sh and restartserver.sh , make sure you have permission
+ */
+public class MoveConfImpl {
+	static final Log LOG = LogFactory.getLog(MoveConfImpl.class);
+	final String CONFPATHNAME = "HBASE_CONF_DIR";
+	final String HBASEPATHNAME = "HBASE_HOME";
+	public String ConfDIR;
+	public String HbaseDIR;
+	public String currentdir;
+
+	/**
+	 * Construct method
+	 * 
+	 * @param path
+	 *            Path name of ${master_home}/hbase-webapp/master
+	 */
+	public MoveConfImpl(String path) {
+		ConfDIR = System.getenv(CONFPATHNAME);
+		HbaseDIR = System.getenv(HBASEPATHNAME);
+		currentdir = path;
+		LOG.info("current  path  is   " + currentdir);
+		if (HbaseDIR == null || HbaseDIR.length() <= 0) {
+			String line = currentdir.substring(0, currentdir.lastIndexOf("/"));
+			HbaseDIR = line.substring(0, line.lastIndexOf("/"));
+		}
+		if (ConfDIR == null || ConfDIR.length() <= 0) {
+			ConfDIR = HbaseDIR + "/conf";
+		}
+		LOG.info("hbase   path  is   " + HbaseDIR);
+		LOG.info("configuration   path  is   " + ConfDIR);
+	}
+
+	/**
+	 * Scp configuration between regionservers
+	 * 
+	 * @param server
+	 *            regionserver name ,example "dw83.kgb.sqa.cm4,60020"
+	 * @param command
+	 *            if command is "get" ,it will get remote regionserver
+	 *            configuration and library to local temp file ; if command is
+	 *            "put", it will put temp configuration and library to remote
+	 *            regionserver.
+	 * @return true if success ,else false
+	 */
+	public boolean ScpConf(String server, String command) {
+		Process process = null;
+		if (!command.equals("get") && !command.equals("put")) {
+			LOG.info("This shell script only support get and put command.");
+			return false;
+		}
+		String[] getcommand = new String[5];
+		getcommand[0] = currentdir + "/moveremoteconf.sh";
+		getcommand[1] = server;
+		getcommand[2] = ConfDIR;
+		getcommand[3] = HbaseDIR;
+		getcommand[4] = command;
+		try {
+			process = Runtime.getRuntime().exec(getcommand, null,
+					new File(currentdir));
+		} catch (IOException e) {
+			e.printStackTrace();
+			return false;
+		}
+		try {
+			process.waitFor();
+		} catch (InterruptedException e) {
+			e.printStackTrace();
+			return false;
+		}
+		process.destroy();
+		return true;
+	}
+
+	/**
+	 * Start or stop regionserver from master use shell script
+	 * 
+	 * @param server
+	 *            regionserver name ,example "dw83.kgb.sqa.cm4,60020"
+	 * @param command
+	 *            "start" or "stop" ,means start or stop regionserver
+	 * @return true if success ,else false
+	 */
+	public boolean ImplRegionServer(String server, String command) {
+		Process process = null;
+		if (!command.equals("start") && !command.equals("stop")) {
+			LOG.info("This shell script only support start and stop command.");
+			return false;
+		}
+		String[] cmd = new String[4];
+		cmd[0] = currentdir + "/restartserver.sh";
+		cmd[1] = server;
+		cmd[2] = HbaseDIR;
+		cmd[3] = command;
+		try {
+			process = Runtime.getRuntime()
+					.exec(cmd, null, new File(currentdir));
+		} catch (IOException e) {
+			e.printStackTrace();
+			return false;
+		}
+		try {
+			process.waitFor();
+		} catch (InterruptedException e) {
+			e.printStackTrace();
+			return false;
+		}
+		process.destroy();
+		return true;
+	}
+	
+	/**
+	 * DistributeConf configuration to regionserver
+	 * 
+	 * @param server
+	 *            regionserver name ,example "dw83.kgb.sqa.cm4,60020"
+	 * @param command
+	 *            if command is "distribute " ,it will distribute hbase-site,xml to remote regionservwer
+	 * @return true if success ,else false
+	 */
+	public boolean DistributeConf(String server, String command) {
+		Process process = null;
+		if (!command.equals("distribute")) {
+			LOG.info("This shell script only support distribute  command.");
+			return false;
+		}
+		String[] distributecommand = new String[5];
+		distributecommand[0] = currentdir + "/moveremoteconf.sh";
+		distributecommand[1] = server;
+		distributecommand[2] = ConfDIR;
+		distributecommand[3] = HbaseDIR;
+		distributecommand[4] = command;
+		try {
+			process = Runtime.getRuntime().exec(distributecommand, null,
+					new File(currentdir));
+		} catch (IOException e) {
+			e.printStackTrace();
+			return false;
+		}
+		try {
+			process.waitFor();
+		} catch (InterruptedException e) {
+			e.printStackTrace();
+			return false;
+		}
+		process.destroy();
+		return true;
+	}
+}
diff -uNr hbase-0.90.2/src/main/java/org/apache/hadoop/hbase/allocation/group/MoveGroupPlan.java hbase-0.90.2-local/src/main/java/org/apache/hadoop/hbase/allocation/group/MoveGroupPlan.java
--- src/main/java/org/apache/hadoop/hbase/allocation/group/MoveGroupPlan.java	1970-01-01 08:00:00.000000000 +0800
+++ src/main/java/org/apache/hadoop/hbase/allocation/group/MoveGroupPlan.java	2011-06-29 15:08:25.000000000 +0800
@@ -0,0 +1,104 @@
+/**
+ * Copyright 2010 The Apache Software Foundation
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.hbase.allocation.group;
+
+/**
+ * Used for change regionserver groups
+ * <p>
+ * Include move regions between regionservers and update configuration fold and
+ * library fold
+ * 
+ */
+public class MoveGroupPlan {
+	private String servername;
+	private String originalgroup;
+	private String targetgroup;
+	private boolean status;
+
+	/**
+	 * Default Construct Method
+	 */
+	public MoveGroupPlan() {
+	}
+
+	/**
+	 * Construct Method
+	 * 
+	 * @param servername
+	 *            regionserver name ,for example "dw83.kgb.sqa.cm4,60020"
+	 * @param originalgroup
+	 *            origninal groupname ,for example "0"
+	 * @param targetgroup
+	 *            target group name ,for example ''1"
+	 */
+	public MoveGroupPlan(String servername, String originalgroup,
+			String targetgroup) {
+		this.servername = servername;
+		this.originalgroup = originalgroup;
+		this.targetgroup = targetgroup;
+		this.status = false;
+	}
+
+	/**
+	 * Get servername
+	 * 
+	 * @return regionserver name
+	 */
+	public String getServername() {
+		return servername;
+	}
+
+	/**
+	 * get origina group name
+	 * 
+	 * @return original group name
+	 */
+	public String getOriginalgroup() {
+		return originalgroup;
+	}
+
+	/**
+	 * get target group name
+	 * 
+	 * @return target groupname
+	 */
+	public String getTargetgroup() {
+		return targetgroup;
+	}
+
+	/**
+	 * Get change group status
+	 * 
+	 * @return status if regionserver is changed group
+	 */
+	public boolean getStatus() {
+		return status;
+	}
+
+	/**
+	 * Set change group status
+	 * 
+	 * @param status
+	 *            if regionserver is changed group
+	 */
+	public void setStatus(boolean status) {
+		this.status = status;
+	}
+}
diff -uNr hbase-0.90.2/src/main/java/org/apache/hadoop/hbase/allocation/group/ProcessMove.java hbase-0.90.2-local/src/main/java/org/apache/hadoop/hbase/allocation/group/ProcessMove.java
--- src/main/java/org/apache/hadoop/hbase/allocation/group/ProcessMove.java	1970-01-01 08:00:00.000000000 +0800
+++ src/main/java/org/apache/hadoop/hbase/allocation/group/ProcessMove.java	2011-06-29 15:13:12.000000000 +0800
@@ -0,0 +1,290 @@
+/**
+ * Copyright 2010 The Apache Software Foundation
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.hbase.allocation.group;
+
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Map;
+import java.util.Random;
+import java.util.Set;
+
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.hbase.HRegionInfo;
+import org.apache.hadoop.hbase.HServerInfo;
+import org.apache.hadoop.hbase.MasterNotRunningException;
+import org.apache.hadoop.hbase.UnknownRegionException;
+import org.apache.hadoop.hbase.ZooKeeperConnectionException;
+import org.apache.hadoop.hbase.master.HMaster;
+import org.apache.hadoop.hbase.util.Bytes;
+import org.apache.hadoop.hbase.master.GroupAssignmentManager;
+
+/**
+ * This class is used for change regionserver group property
+ * <p>
+ * It will move all regions off a regionserver ,and then move into other
+ * regionserver left on this group.
+ */
+public class ProcessMove implements Runnable {
+	static final Log LOG = LogFactory.getLog(ProcessMove.class);
+	final static String DEFAULT_GROUP = "0";
+	final String GROUP_INFORMATION = "groupinformation.conf";
+
+	private Set<MoveGroupPlan> movegroupPlanset = new HashSet<MoveGroupPlan>();
+	private Map<String, List<String>> groupmap = new HashMap<String, List<String>>();
+	private Map<String, Boolean> grouppropertymap = new HashMap<String, Boolean>();
+	private HMaster master = null;
+	private String currentdir = null;
+
+	/**
+	 * Construct method for thread
+	 * 
+	 * @param movegroupPlanset
+	 *            Set<{@link MoveGroupPlan}> , Will change regionserver plan set
+	 * @param groupmap
+	 * 			  Map < String, List< String >> , key:groupname , value: regionserver name list 
+	 * @param grouppropertymap
+	 * 			  Map< String, Boolean > , key : groupname ,value : isSpecialConfiguration
+	 * @param master 
+	 * 			 Master Interface 
+	 * @param currentdir
+	 * 			 current context dir path
+	 */
+	public ProcessMove(Set<MoveGroupPlan> movegroupPlanset,
+			Map<String, List<String>> groupmap,
+			Map<String, Boolean> grouppropertymap, HMaster master,
+			String currentdir) {
+		super();
+		this.movegroupPlanset = movegroupPlanset;
+		this.groupmap = groupmap;
+		this.grouppropertymap = grouppropertymap;
+		this.master = master;
+		this.currentdir = currentdir;
+	}
+
+	/**
+	 * Move all regions and update configuration and librarys
+	 * 
+	 */
+	public void run() {
+		List<String> willmoveservers = new ArrayList<String>();
+		ServerWithGroup.setMovegroupPlanset(movegroupPlanset);
+		ServerWithGroup.setIserror(false);
+
+		for (MoveGroupPlan plan : movegroupPlanset) {
+			String servername = plan.getServername();
+			willmoveservers.add(servername);
+		}
+
+		for (MoveGroupPlan plan : movegroupPlanset) {
+			String servername = plan.getServername();
+			String originalgp = plan.getOriginalgroup();
+			String targetgp = plan.getTargetgroup();
+			ServerWithGroup.setCurrentserver(servername);
+			LOG.info("Move " + servername + " form group " + originalgp
+					+ " to group " + targetgp);
+			if (originalgp.equals(targetgp)) {
+				willmoveservers.remove(servername);
+				continue;
+			}
+			List<HRegionInfo> regionlist = new ArrayList<HRegionInfo>();
+			try {
+				regionlist = ServerWithGroup.listRegionOnRegionServer(master,
+						servername);
+			} catch (MasterNotRunningException e) {
+				e.printStackTrace();
+			} catch (ZooKeeperConnectionException e) {
+				e.printStackTrace();
+			}
+			if (regionlist != null) {
+				LOG.info("We have " + regionlist.size()
+						+ " regions to move ...");
+				// move region
+				while (true) {
+					// assign regions on this server this region's table other
+					// servers
+					if (regionlist == null || regionlist.size() <= 0)
+						break;
+					for (HRegionInfo hri : regionlist) {
+						String tablename = hri.getTableDesc().getNameAsString();
+						List<HServerInfo> availalbeserver = GroupAssignmentManager
+								.getAvailableServer(tablename);
+						List<String> availservernames = new ArrayList<String>();
+						for (HServerInfo hsr : availalbeserver) {
+							String name = hsr.getHostname() + ","
+									+ hsr.getServerAddress().getPort();
+							// cancel will delete server
+							if (!willmoveservers.contains(name)) {
+								availservernames.add(name);
+								LOG.info("Available server " + name
+										+ "for table " + tablename);
+							}
+						}
+						LOG.info("Available server  length "
+								+ availservernames.size());
+						if (availservernames.size() <= 0) {
+							LOG.info("No available regionservers left for  table"
+									+ tablename
+									+ " to assign,and it will be changed to group 0 !!");
+							continue;
+							// think carefully
+						}
+
+						Random r = new Random();
+						int index = r.nextInt(availservernames.size());
+						String targertservername = availservernames.get(index);
+						HServerInfo targetserver = null;
+						LOG.info("Choose Server  targert" + servername
+								+ "to moved this region to...");
+						Collection<HServerInfo> serverInfo = master
+								.getClusterStatus().getServerInfo();
+						for (HServerInfo sinfo : serverInfo) {
+							String thisservername = sinfo.getHostname() + ","
+									+ sinfo.getServerAddress().getPort();
+							if (thisservername.equals(targertservername)) {
+								targetserver = sinfo;
+								break;
+							}
+						}
+						LOG.info("Choose Server " + targertservername);
+						if (targetserver == null) {
+							LOG.info("RegionServer Missing ...");
+							ServerWithGroup.setIserror(true);
+							ServerWithGroup
+									.setErrormsg("Region server missing when move servergroup");
+							synchronized (ServerWithGroup.class) {
+								ServerWithGroup.setIsprocess(false);
+							}
+							return;
+						}
+						String regionName = Bytes.toStringBinary(hri
+								.getRegionName());
+						String encodeRegionName = regionName.substring(
+								(regionName.lastIndexOf(".",
+										regionName.length() - 2)) + 1,
+								regionName.length() - 1);
+						try {
+							if (!hri.isOffline() && !hri.isSplit()) {
+								synchronized (GroupAssignmentManager.class) {
+									master.move(
+											Bytes.toBytes(encodeRegionName),
+											Bytes.toBytes(targetserver
+													.getServerName()));
+								}
+								LOG.info("Move region " + encodeRegionName
+										+ " from server " + servername
+										+ " to server "
+										+ targetserver.getServerName());
+							}
+						} catch (UnknownRegionException e) {
+							e.printStackTrace();
+						}
+					}
+					try {
+						regionlist = ServerWithGroup.listRegionOnRegionServer(
+								master, servername);
+					} catch (MasterNotRunningException e) {
+						e.printStackTrace();
+					} catch (ZooKeeperConnectionException e) {
+						e.printStackTrace();
+					}
+					if (regionlist.size() > 0) {
+						LOG.info("Can't move all regions once ,do it again!");
+						try {
+							Thread.sleep(500);
+						} catch (InterruptedException e) {
+							e.printStackTrace();
+						}
+					}
+				}
+			}
+			if (grouppropertymap.get(targetgp)
+					|| grouppropertymap.get(originalgp)) {
+				// update configuration and library
+				List<String> rglist = groupmap.get(targetgp);
+				if (rglist == null || rglist.size() <= 0) {
+					LOG.info("Don't Need to Update Conf");
+				} else {
+					String sourceserver = rglist.get(0);
+					String sourceaddress = sourceserver.substring(0,
+							sourceserver.indexOf(","));
+					String targetaddress = servername.substring(0,
+							servername.indexOf(","));
+					try {
+						boolean result = true;
+						ServerWithGroup.setDoMoveconf(true);
+						LOG.info("before move conf ");
+						MoveConfImpl moveimpl = new MoveConfImpl(currentdir);
+						LOG.info("after move conf ");
+						result = moveimpl.ScpConf(sourceaddress, "get");
+						if (!result)
+							throw new Exception("get conf exception");
+						result = moveimpl.ImplRegionServer(targetaddress,
+								"stop");
+						if (!result)
+							throw new Exception("stop server exception");
+						result = moveimpl.ScpConf(targetaddress, "put");
+						if (!result)
+							throw new Exception("put conf exception");
+						result = moveimpl.ImplRegionServer(targetaddress,
+								"start");
+						if (!result)
+							throw new Exception("start server exception");
+						ServerWithGroup.setDoMoveconf(false);
+					} catch (Exception e) {
+						e.printStackTrace();
+						ServerWithGroup.setIserror(true);
+						ServerWithGroup
+								.setErrormsg("Error occured when update regionserver configuration and jars ...");
+						synchronized (ServerWithGroup.class) {
+							ServerWithGroup.setIsprocess(false);
+						}
+						return;
+					}
+				}
+			}
+			willmoveservers.remove(servername);
+			groupmap.get(originalgp).remove(servername);
+			groupmap.get(targetgp).add(servername);
+			LOG.info("update groupmap successfully");
+			try {
+				ServerWithGroup.writeGroupInfo(master, GROUP_INFORMATION,
+						groupmap, grouppropertymap);
+				LOG.info("Write conf back ");
+				GroupAssignmentManager.initValue(false);
+				LOG.info("GroupAssignmentManager initValue ");
+			} catch (IOException e) {
+				LOG.info(ProcessMove.class, e);
+			}
+			plan.setStatus(true);
+			ServerWithGroup.setMovegroupPlanset(movegroupPlanset);
+		}
+		synchronized (ServerWithGroup.class) {
+			ServerWithGroup.setIsprocess(false);
+			ServerWithGroup.setIsmoveregion(false);
+		}
+		LOG.info("Finished update group information!");
+	}
+
+}
diff -uNr hbase-0.90.2/src/main/java/org/apache/hadoop/hbase/allocation/group/ServerWithGroup.java hbase-0.90.2-local/src/main/java/org/apache/hadoop/hbase/allocation/group/ServerWithGroup.java
--- src/main/java/org/apache/hadoop/hbase/allocation/group/ServerWithGroup.java	1970-01-01 08:00:00.000000000 +0800
+++ src/main/java/org/apache/hadoop/hbase/allocation/group/ServerWithGroup.java	2011-07-01 19:26:07.000000000 +0800
@@ -0,0 +1,673 @@
+/**
+ * Copyright 2010 The Apache Software Foundation
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.hbase.allocation.group;
+
+import java.io.IOException;
+import java.net.URI;
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.fs.FSDataInputStream;
+import org.apache.hadoop.fs.FSDataOutputStream;
+import org.apache.hadoop.fs.FileSystem;
+import org.apache.hadoop.fs.Path;
+import org.apache.hadoop.hbase.ClusterStatus;
+import org.apache.hadoop.hbase.HConstants;
+import org.apache.hadoop.hbase.HRegionInfo;
+import org.apache.hadoop.hbase.HServerAddress;
+import org.apache.hadoop.hbase.HServerInfo;
+import org.apache.hadoop.hbase.HTableDescriptor;
+import org.apache.hadoop.hbase.MasterNotRunningException;
+import org.apache.hadoop.hbase.ZooKeeperConnectionException;
+import org.apache.hadoop.hbase.client.HBaseAdmin;
+import org.apache.hadoop.hbase.client.HConnection;
+import org.apache.hadoop.hbase.client.HTable;
+import org.apache.hadoop.hbase.client.Result;
+import org.apache.hadoop.hbase.client.ResultScanner;
+import org.apache.hadoop.hbase.client.Scan;
+import org.apache.hadoop.hbase.ipc.HRegionInterface;
+import org.apache.hadoop.hbase.master.HMaster;
+import org.apache.hadoop.hbase.util.Bytes;
+import org.apache.hadoop.hbase.util.Writables;
+
+/**
+ * Read group configuration from hdfs and write back to hdfs
+ * <p>
+ * Also provide region and table information on regionserver
+ */
+public class ServerWithGroup {
+	static final Log LOG = LogFactory.getLog(ServerWithGroup.class);
+
+	final static String DEFAULT_GROUP = "0";
+
+	private static boolean isprocess = false;
+	private static boolean ismoveregion = false;
+	private static boolean isbalance = false;
+	private static boolean ischangetable = false;
+	private static String currentserver = "";
+	private static boolean doMoveconf = false;
+	private static boolean iserror = false;
+	private static String errormsg = "";
+
+	private static Set<MoveGroupPlan> movegroupPlanset = new HashSet<MoveGroupPlan>();
+
+	/**
+	 * Used for prevent other task when there is an task processing in system
+	 * 
+	 * This method is used for identify different tasks.
+	 * 
+	 * @return true if task is processing , false if not.
+	 */
+	public static boolean isIsprocess() {
+		return isprocess;
+	}
+
+	/**
+	 * Set process flag
+	 * 
+	 * @param current
+	 *            process flag
+	 */
+	public static void setIsprocess(boolean isprocess) {
+		ServerWithGroup.isprocess = isprocess;
+	}
+
+	/**
+	 * Used for get current processing regionserver when change regionserver
+	 * group
+	 * 
+	 * @return current processing regionserver name
+	 */
+	public static String getCurrentserver() {
+		return currentserver;
+	}
+
+	/**
+	 * Set current processing regionserver name
+	 * 
+	 * @param currentserver
+	 *            regionserver name
+	 */
+	public static void setCurrentserver(String currentserver) {
+		ServerWithGroup.currentserver = currentserver;
+	}
+
+	/**
+	 * Used for identify whether regionserver is updating configuration and jars
+	 * 
+	 * @return true if system is move regionserver configuration ,else false
+	 */
+	public static boolean isDoMoveconf() {
+		return doMoveconf;
+	}
+
+	/**
+	 * Set regionserver is move configuration and lib flag
+	 * 
+	 * @param doMoveconf
+	 *            if system is updating regionserver configuration and library
+	 */
+	public static void setDoMoveconf(boolean doMoveconf) {
+		ServerWithGroup.doMoveconf = doMoveconf;
+	}
+
+	/**
+	 * Used for identify whether regionserver is moving regions
+	 * 
+	 * @return true if system is moving regions between regionservers , else
+	 *         false
+	 */
+	public static boolean isIsmoveregion() {
+		return ismoveregion;
+	}
+
+	/**
+	 * Set regionserver is move region flag
+	 * 
+	 * @param ismoveregion
+	 *            if system is moving regions
+	 */
+	public static void setIsmoveregion(boolean ismoveregion) {
+		ServerWithGroup.ismoveregion = ismoveregion;
+	}
+
+	/**
+	 * Used for identify whether system is balancing group or table
+	 * 
+	 * @return true if system is balancing , false if not.
+	 */
+	public static boolean isIsbalance() {
+		return isbalance;
+	}
+
+	/**
+	 * Set system is balance group or table
+	 * 
+	 * @param isbalance
+	 *            if system is balancing table or group
+	 */
+	public static void setIsbalance(boolean isbalance) {
+		ServerWithGroup.isbalance = isbalance;
+	}
+
+	/**
+	 * Used for identify whether system is change table priority or groups
+	 * 
+	 * @return true if system is changing talbe, false if not.
+	 */
+	public static boolean isIschangetable() {
+		return ischangetable;
+	}
+
+	/**
+	 * Set system is changing table group or priority
+	 * 
+	 * @param ischangetable
+	 *            if system is change table priority or groups
+	 */
+	public static void setIschangetable(boolean ischangetable) {
+		ServerWithGroup.ischangetable = ischangetable;
+	}
+
+	/**
+	 * Used for identify whether system is has an error, this will shown in
+	 * front-end
+	 * 
+	 * @return true if there is error occured ,else fasle
+	 */
+	public static boolean isIserror() {
+		return iserror;
+	}
+
+	/**
+	 * Set system is encount an error when processing
+	 * 
+	 * @param iserror
+	 *            if system occured error
+	 */
+	public static void setIserror(boolean iserror) {
+		ServerWithGroup.iserror = iserror;
+	}
+
+	/**
+	 * Used for show error message content , this will shown in front-end
+	 * 
+	 * @return msg , error message content
+	 */
+	public static String getErrormsg() {
+		return errormsg;
+	}
+
+	/**
+	 * Set error message content
+	 * 
+	 * @param errormsg
+	 *            set error message
+	 */
+	public static void setErrormsg(String errormsg) {
+		ServerWithGroup.errormsg = errormsg;
+	}
+
+	/**
+	 * Used for change regionserver group , {@link MoveGroupPlan} will be done
+	 * by a thread {@link ProcessMove} , it will be used in front-end
+	 * 
+	 * @return current processing regionserver plans movegroupPlanset
+	 */
+	public static Set<MoveGroupPlan> getMovegroupPlanset() {
+		return movegroupPlanset;
+	}
+
+	/**
+	 * Set current moveplan {@link MoveGroupPlan}
+	 * 
+	 * @param movegroupPlanset
+	 *            current will moved regionservers
+	 */
+	public static void setMovegroupPlanset(Set<MoveGroupPlan> movegroupPlanset) {
+		ServerWithGroup.movegroupPlanset = movegroupPlanset;
+	}
+
+	/**
+	 * Read regionserver information form hdfs to a String line
+	 * <p>
+	 * Configuration file is stored in
+	 * hdfs://${hbase.rootdir}/groupinformation.conf Format :
+	 * groupname1;isSpecial;regionservername1;regionservername2:
+	 * groupname2;isSpecial;regionservername3
+	 * 
+	 * @param master
+	 *            HMaster interface
+	 * @param confpath
+	 *            groupinformation file Path in hdfs
+	 * @return line Configuration File content
+	 * @throws IOException
+	 *             IOException ocurred in hdfs
+	 */
+	public static String readGroupInfo(HMaster master, final String confpath)
+			throws IOException {
+		FileSystem fs = master.getMasterFileSystem().getFileSystem();
+		URI hdfsuri = master.getMasterFileSystem().getRootDir().toUri();
+		Path inputpath = new Path(hdfsuri.toString() + "/" + confpath);
+		String outline = "";
+		boolean isexist;
+		try {
+			isexist = fs.exists(inputpath);
+		} catch (IOException e) {
+			return outline;
+		}
+		if (isexist) {
+			FSDataInputStream hdfsInStream = fs.open(inputpath);
+			byte[] ioBuffer = new byte[1024];
+			int readLen = hdfsInStream.read(ioBuffer);
+			while (-1 != readLen) {
+				String line = Bytes.toStringBinary(ioBuffer, 0, readLen);
+				outline += line;
+				readLen = hdfsInStream.read(ioBuffer);
+			}
+			hdfsInStream.close();
+		}
+		LOG.info("Read groupinformation.conf from  hdfs://${hbase.rootdir}/groupinformation.conf");
+		return outline;
+	}
+
+	/**
+	 * Initialize groupmap for regionserver
+	 * <p>
+	 * System will delete offline regionserver from configuration file and add
+	 * new online regionserver into DEFAULT_GROUP
+	 * 
+	 * @param master
+	 *            HMaster interface
+	 * @param confline
+	 *            Configuration content
+	 * @return groupmap Map< String, List< String >> key:groupname , value:
+	 *         regionserver name list
+	 */
+	public static Map<String, List<String>> initGroupMap(HMaster master,
+			String confline) {
+
+		ClusterStatus status = master.getClusterStatus();
+		Collection<HServerInfo> serverInfo = status.getServerInfo();
+		Set<String> onlineserver = new HashSet<String>();
+		for (HServerInfo info : serverInfo) {
+			String servername = info.getHostname() + ","
+					+ info.getServerAddress().getPort();
+			onlineserver.add(servername);
+		}
+
+		Map<String, List<String>> groupmap = new HashMap<String, List<String>>();
+		Set<String> finalserverset = new HashSet<String>();
+		if (confline.length() > 0) {
+			String[] grouplines = confline.split(":");
+			for (String line : grouplines) {
+				if (line == null || line.length() <= 0)
+					continue;
+				String[] serverlines = line.split(";");
+				if (serverlines.length <= 1)
+					continue;
+				String groupname = serverlines[0];
+				// add servers of this group
+				List<String> rglist = new ArrayList<String>();
+				for (int i = 2; i < serverlines.length; i++) {
+					if (onlineserver.contains(serverlines[i])) {
+						rglist.add(serverlines[i]);
+						finalserverset.add(serverlines[i]);
+					}
+				}
+				groupmap.put(groupname, rglist);
+			}
+		}
+		// add new online server
+		for (HServerInfo info : serverInfo) {
+			String servername = info.getHostname() + ","
+					+ info.getServerAddress().getPort();
+			if (!finalserverset.contains(servername)) {
+				// add to default group
+				if (!groupmap.containsKey(DEFAULT_GROUP)) {
+					groupmap.put(DEFAULT_GROUP, new ArrayList<String>());
+				}
+				groupmap.get(DEFAULT_GROUP).add(servername);
+			}
+		}
+		return groupmap;
+	}
+
+	/**
+	 * Get group property grouppropertymap from configuration line ,if this
+	 * group is special ,it will be set true , and when move regionserver groups
+	 * ,it will force update new configuration and jars
+	 * 
+	 * @param master
+	 *            HMaster interface
+	 * @param confline
+	 *            Configuration content
+	 * @return grouppropertymap Map< String, Boolean > , key : groupname ,value:
+	 *         isSpecialConfiguration
+	 */
+	public static Map<String, Boolean> initGroupPropertyMap(HMaster master,
+			String confline) {
+		Map<String, Boolean> grouppropertymap = new HashMap<String, Boolean>();
+		if (confline.length() > 0) {
+			String[] grouplines = confline.split(":");
+			for (String line : grouplines) {
+				if (line == null || line.length() <= 0)
+					continue;
+				String[] serverlines = line.split(";");
+				if (serverlines.length <= 1)
+					continue;
+				String groupname = serverlines[0];
+				String groupproperty = serverlines[1];
+				grouppropertymap.put(groupname, Boolean.valueOf(groupproperty));
+			}
+		}
+		if (!grouppropertymap.keySet().contains(DEFAULT_GROUP)) {
+			grouppropertymap.put(DEFAULT_GROUP, false);
+		} else {
+			if (grouppropertymap.get(DEFAULT_GROUP) == true) {
+				grouppropertymap.remove(DEFAULT_GROUP);
+				grouppropertymap.put(DEFAULT_GROUP, false);
+			}
+		}
+		return grouppropertymap;
+	}
+
+	/**
+	 * Write regionserver groupinformation back to hdfs
+	 * 
+	 * @param master
+	 *            HMaster interface
+	 * @param confpath
+	 *            Configuration file Path in hdfs
+	 * @param groupmap
+	 *            Map< String, List< String >> key:groupname , value:
+	 *            regionserver name list
+	 * @param grouppropertymap
+	 *            Map< String, Boolean > , key : groupname ,value:
+	 *            isSpecialConfiguration
+	 * @throws IOException
+	 *             IOException occured in hdfs
+	 */
+	public static void writeGroupInfo(HMaster master, final String confpath,
+			Map<String, List<String>> groupmap,
+			Map<String, Boolean> grouppropertymap) throws IOException {
+		// write back to hdfs
+		FileSystem fs = master.getMasterFileSystem().getFileSystem();
+		URI hdfsuri = master.getMasterFileSystem().getRootDir().toUri();
+		Path outputpath = new Path(hdfsuri.toString() + "/" + confpath);
+		FSDataOutputStream outputStream = fs.create(outputpath);
+		for (Map.Entry<String, List<String>> entry : groupmap.entrySet()) {
+			String group = entry.getKey();
+			outputStream.write(Bytes.toBytes(group + ";"));
+			String isspecial = grouppropertymap.get(group).toString();
+			outputStream.write(Bytes.toBytes(isspecial + ";"));
+			List<String> serverlist = entry.getValue();
+			for (String server : serverlist) {
+				outputStream.write(Bytes.toBytes(server + ";"));
+			}
+			outputStream.write(Bytes.toBytes(":"));
+		}
+		outputStream.close();
+		LOG.info("Write groupinformation back to  hdfs://${hbase.rootdir}/groupinformation.conf");
+	}
+
+	/**
+	 * Read region information of regionserver from .META. region
+	 * 
+	 * @param hmaster
+	 *            HMaster interface
+	 * @param servername
+	 *            regionserver name
+	 * @return regionlist List< HRegionInfo > , List of regions this
+	 *         regionserver hold
+	 */
+	public static List<HRegionInfo> listRegionsInServerFromMeta(
+			HMaster hmaster, String servername) {
+		List<HRegionInfo> regionlist = new ArrayList<HRegionInfo>();
+		try {
+			HTable metatable = new HTable(hmaster.getConfiguration(),
+					HConstants.META_TABLE_NAME);
+			Scan scan = new Scan();
+			scan.addColumn(HConstants.CATALOG_FAMILY,
+					HConstants.REGIONINFO_QUALIFIER);
+			scan.addColumn(HConstants.CATALOG_FAMILY,
+					HConstants.SERVER_QUALIFIER);
+			ResultScanner rs = metatable.getScanner(scan);
+			Result rt = null;
+			while ((rt = rs.next()) != null) {
+				byte[] value = rt.getValue(HConstants.CATALOG_FAMILY,
+						HConstants.REGIONINFO_QUALIFIER);
+				if (value == null || value.length == 0)
+					continue;
+				HRegionInfo region = null;
+				try {
+					region = Writables.getHRegionInfo(value);
+				} catch (Exception e) {
+					e.printStackTrace();
+					continue;
+				}
+				byte[] address = rt.getValue(HConstants.CATALOG_FAMILY,
+						HConstants.SERVER_QUALIFIER);
+				if (address == null || address.length == 0)
+					continue;
+				if (region.isOffline() || region.isSplit())
+					continue;
+				if (!regionlist.contains(region)) {
+					HServerAddress addr = new HServerAddress(
+							Bytes.toString(address));
+					String name = addr.getHostname() + "," + addr.getPort();
+					if (name.equals(servername)) {
+						regionlist.add(region);
+					}
+				}
+			}
+		} catch (IOException ex) {
+			ex.printStackTrace();
+		}
+		return regionlist;
+	}
+
+	/**
+	 * Read region information stored in regionserver , we get this information
+	 * directly from {@link HRegionInterface}
+	 * 
+	 * @param hmaster
+	 *            HMaster interface
+	 * @param servername
+	 *            regionserver name
+	 * @return regionlist List< HRegionInfo > , List of regions this
+	 *         regionserver hold
+	 * @throws MasterNotRunningException
+	 *             master not running
+	 * @throws ZooKeeperConnectionException
+	 *             zookeeper connection exception
+	 */
+	public static List<HRegionInfo> listRegionOnRegionServer(HMaster master,
+			String servername) throws MasterNotRunningException,
+			ZooKeeperConnectionException {
+		List<HRegionInfo> regionlist = new ArrayList<HRegionInfo>();
+		HBaseAdmin admin = new HBaseAdmin(master.getConfiguration());
+		HConnection coon = admin.getConnection();
+		Collection<HServerInfo> servercollect = master.getClusterStatus()
+				.getServerInfo();
+		HServerAddress addr = null;
+		for (HServerInfo info : servercollect) {
+			String name = info.getHostname() + ","
+					+ info.getServerAddress().getPort();
+			if (name.equals(servername)) {
+				addr = info.getServerAddress();
+				break;
+			}
+		}
+		if (addr == null)
+			return regionlist;
+		HRegionInterface hri = null;
+		try {
+			hri = coon.getHRegionConnection(addr);
+			regionlist = hri.getOnlineRegions();
+		} catch (Throwable  e) {
+			e.printStackTrace();
+		}
+		return regionlist;
+	}
+
+	/**
+	 * List all online tables stored on regionserver
+	 * 
+	 * @param master
+	 *            HMaster interface
+	 * @param servername
+	 *            regionserver name
+	 * @return tablelist List< HTableDescriptor > , all tables hold on this
+	 *         regionserver
+	 * @throws MasterNotRunningException
+	 *             master not running
+	 * @throws ZooKeeperConnectionException
+	 *             zookeeper connection exception
+	 */
+	public static List<HTableDescriptor> listTableOnRegionServer(
+			HMaster master, String servername)
+			throws MasterNotRunningException, ZooKeeperConnectionException {
+		List<HRegionInfo> regionlist = listRegionOnRegionServer(master,
+				servername);
+		List<HTableDescriptor> tablelist = new ArrayList<HTableDescriptor>();
+		for (HRegionInfo info : regionlist) {
+			HTableDescriptor htabledesc = info.getTableDesc();
+			if (!tablelist.contains(htabledesc)) {
+				tablelist.add(htabledesc);
+			}
+		}
+		return tablelist;
+	}
+
+	/**
+	 * List all tables in hbase system
+	 * 
+	 * @param hmaster
+	 *            HMaster interface
+	 * @return tablelist List< HTableDescriptor > , all tables hold on this
+	 *         regionserver
+	 */
+	public static List<HTableDescriptor> listAllTables(HMaster hmaster) {
+		List<HTableDescriptor> tablelist = new ArrayList<HTableDescriptor>();
+		try {
+			HTable metatable = new HTable(hmaster.getConfiguration(),
+					HConstants.META_TABLE_NAME);
+			Scan scan = new Scan();
+			scan.addColumn(HConstants.CATALOG_FAMILY,
+					HConstants.REGIONINFO_QUALIFIER);
+			ResultScanner rs = metatable.getScanner(scan);
+			Result rt = null;
+			while ((rt = rs.next()) != null) {
+				byte[] value = rt.getValue(HConstants.CATALOG_FAMILY,
+						HConstants.REGIONINFO_QUALIFIER);
+				if (value == null || value.length == 0)
+					continue;
+				HRegionInfo region = Writables.getHRegionInfo(value);
+				if (region.isOffline() || region.isSplit())
+					continue;
+				HTableDescriptor table = region.getTableDesc();
+				if (!tablelist.contains(table)) {
+					tablelist.add(table);
+				}
+			}
+		} catch (IOException e) {
+			e.printStackTrace();
+		}
+		return tablelist;
+	}
+
+	/**
+	 * Get region number of a group
+	 * 
+	 * @param hmaster
+	 *            HMaster interface
+	 * @param groupname
+	 *            groupname
+	 * @param groupmap
+	 *            Map< String, List< String >> ,key:groupname ,value
+	 *            regionserver list
+	 * @return totalregions , total region number hold on this group
+	 */
+	public static int getRegionNumOnGroup(HMaster hmaster, String groupname,
+			Map<String, List<String>> groupmap) {
+		int totalregions = 0;
+		if (groupmap == null || groupmap.size() <= 0)
+			return totalregions;
+		if (!groupmap.keySet().contains(groupname))
+			return totalregions;
+		List<String> serverlist = groupmap.get(groupname);
+		if (serverlist.size() <= 0)
+			return totalregions;
+		for (String server : serverlist) {
+			try {
+				List<HRegionInfo> regions = listRegionOnRegionServer(hmaster,
+						server);
+				totalregions += regions.size();
+			} catch (MasterNotRunningException e) {
+				e.printStackTrace();
+			} catch (ZooKeeperConnectionException e) {
+				e.printStackTrace();
+			}
+		}
+		return totalregions;
+	}
+
+	/**
+	 * Get region number of a table on a regionserver
+	 * 
+	 * @param hmaster
+	 *            HMaster interface
+	 * @param table
+	 *            tablename
+	 * @param server
+	 *            regionserver
+	 * @return totalregions , total region number hold on this table of this
+	 *         regionserver
+	 */
+	public static int getRegionOfTableOnServer(HMaster hmaster, String table,
+			HServerInfo server) {
+		int size = 0;
+		String servername = server.getHostname() + ","
+				+ server.getServerAddress().getPort();
+		try {
+			List<HRegionInfo> regionlist = listRegionOnRegionServer(hmaster,
+					servername);
+			for (HRegionInfo info : regionlist) {
+				String tablename = info.getTableDesc().getNameAsString();
+				if (table.equals(tablename)) {
+					size++;
+				}
+			}
+		} catch (MasterNotRunningException e) {
+			e.printStackTrace();
+		} catch (ZooKeeperConnectionException e) {
+			e.printStackTrace();
+		}
+		return size;
+	}
+}
\ No newline at end of file
diff -uNr hbase-0.90.2/src/main/java/org/apache/hadoop/hbase/allocation/test/BalanceRegionByTable.java hbase-0.90.2-local/src/main/java/org/apache/hadoop/hbase/allocation/test/BalanceRegionByTable.java
--- src/main/java/org/apache/hadoop/hbase/allocation/test/BalanceRegionByTable.java	1970-01-01 08:00:00.000000000 +0800
+++ src/main/java/org/apache/hadoop/hbase/allocation/test/BalanceRegionByTable.java	2011-06-28 10:00:41.000000000 +0800
@@ -0,0 +1,213 @@
+package org.apache.hadoop.hbase.allocation.test;
+
+
+
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Map;
+
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.hbase.HBaseConfiguration;
+import org.apache.hadoop.hbase.HColumnDescriptor;
+import org.apache.hadoop.hbase.HRegionInfo;
+import org.apache.hadoop.hbase.HServerAddress;
+import org.apache.hadoop.hbase.HServerInfo;
+import org.apache.hadoop.hbase.allocation.CheckMeta;
+import org.apache.hadoop.hbase.client.HBaseAdmin;
+import org.apache.hadoop.hbase.client.HTable;
+import org.apache.hadoop.hbase.util.Bytes;
+
+
+public class BalanceRegionByTable {
+	static final Configuration conf = HBaseConfiguration.create();
+	public static String table = "testPri";
+ 
+
+
+	public static void main(String args[]) {
+		try {
+			while(true)
+			{
+					balanceRegion(true);
+			}
+		} catch (IOException e) {
+			// TODO Auto-generated catch block
+			e.printStackTrace();
+		}
+	}
+
+	public static void balanceRegion(boolean auto) throws IOException {
+		String regionPre="23";
+		HBaseAdmin admin = new HBaseAdmin(conf);
+		Collection<HServerInfo> serverInfo = admin.getClusterStatus()
+				.getServerInfo();
+		HashSet<String> regionPreList=new HashSet();
+		HashMap<HServerAddress, String> serverCode = new HashMap<HServerAddress, String>();
+
+		for (HServerInfo hinfo : serverInfo) {
+			if (!serverCode.containsKey(hinfo)) {
+				serverCode.put(
+						hinfo.getServerAddress(),
+						hinfo.getHostnamePort().replace(":", ",") + ","
+								+ hinfo.getStartCode());
+				// Map<HServerAddress,String>
+			}
+		}
+		HTable ret = new HTable(conf, table);
+		
+		Map<HRegionInfo, HServerAddress> info = null;
+		HashMap<HServerAddress, List<HRegionInfo>> serverR ;
+		int div = 99999;
+		
+		int maxLoadN = 0;
+		int minLoadN = 9999999;
+		int flag=1;
+		while (true) {
+			try {
+				//ret.close();
+				//ret = new HTable(conf, table);
+				
+				div = 99999;
+				
+				maxLoadN = 0;
+				minLoadN = 9999999;
+				serverInfo = admin.getClusterStatus()
+				.getServerInfo();
+				
+				serverCode = new HashMap<HServerAddress, String>();
+				
+				for (HServerInfo hinfo : serverInfo) {
+					if (!serverCode.containsKey(hinfo)) {
+						serverCode.put(
+								hinfo.getServerAddress(),
+								hinfo.getHostnamePort().replace(":", ",") + ","
+										+ hinfo.getStartCode());
+						// Map<HServerAddress,String>
+					}
+				}
+				
+				try {
+					info = CheckMeta.getRegionAddress(ret.getTableDescriptor().getNameAsString());
+					//info = ret.getRegionsInfo();
+				} catch (Exception e) {
+					// TODO Auto-generated catch block
+					try {
+						Thread.currentThread().sleep(1000);
+					} catch (InterruptedException e1) {
+						// TODO Auto-generated catch block
+						e1.printStackTrace();
+					}
+					continue;
+					//e.printStackTrace();
+				}
+				
+				
+				
+				serverR = new HashMap<HServerAddress, List<HRegionInfo>>();
+				for (HServerInfo hinfo : serverInfo) {
+					serverR.put(hinfo.getServerAddress(), new ArrayList<HRegionInfo>());
+				
+				}
+
+				for (HRegionInfo rinfo : info.keySet()) {
+					if(Bytes.toString(rinfo.getStartKey()).length()<3)
+						continue;
+					if(!regionPreList.contains(Bytes.toString(rinfo.getStartKey()).subSequence(0, 3)))
+					{
+							regionPreList.add((String) Bytes.toString(rinfo.getStartKey()).subSequence(0, 3));
+					}
+				}
+				flag++;
+				if(flag>=regionPreList.size())
+				{
+					flag=0;
+				}
+				String []pres=new String[regionPreList.size()];
+				if(pres.length==0)
+				{
+					Thread.currentThread().sleep(20000);
+					continue;
+				}
+				regionPreList.toArray(pres);
+				
+				regionPre=pres[flag];
+		
+				for (HRegionInfo rinfo : info.keySet()) {
+					if (serverR.get(info.get(rinfo)) == null) {
+							serverR.put(info.get(rinfo), new ArrayList<HRegionInfo>());
+
+					}
+					
+					serverR.get(info.get(rinfo)).add(rinfo);
+						//serverR.put(info.get(rinfo), new ArrayList<HRegionInfo>());
+				
+					//serverR.get(info.get(rinfo)).add(rinfo);
+				}
+				HServerAddress maxLoad = null;
+				HServerAddress minLoad = null;
+
+				for (HServerAddress add : serverR.keySet()) {
+					if (serverR.get(add).size() > maxLoadN) {
+						maxLoadN = serverR.get(add).size();
+						maxLoad = add;
+					}
+					if (serverR.get(add).size() < minLoadN) {
+						minLoadN = serverR.get(add).size();
+						minLoad = add;
+					}
+				}
+				div = maxLoadN - minLoadN;
+				System.out.println("max load:" + maxLoad.getHostname() + " maxN:"
+						+ maxLoadN);
+				System.out.println("min load:" + minLoad.getHostname() + " minN:"
+						+ minLoadN);
+				if(div<2)
+				{
+					try {
+						Thread.currentThread().sleep(1000);
+					} catch (InterruptedException e) {
+						// TODO Auto-generated catch block
+						e.printStackTrace();
+					}
+					continue;
+				}
+				
+
+				HRegionInfo rtom = serverR.get(maxLoad).get(serverR.get(maxLoad).size()-1);
+				serverR.get(maxLoad).remove(0);
+				serverR.get(minLoad).add(rtom);
+				byte[] rn = rtom.getEncodedNameAsBytes();
+				// byte[] sern=maxLoad.;
+				// admin.move(null, null);
+				if (!auto) {
+					System.out.println("move  region ? : [Yes|No]");
+					java.util.Scanner scanner = new java.util.Scanner(System.in);
+					String sret = scanner.nextLine();
+					if (!sret.equals("Yes")) {
+						System.out.println("Your anwser is not Yes,now exit.");
+						System.exit(0);
+					}
+				}
+				try {
+					System.out.println("move " + rtom);
+					System.out.println("move to " + serverCode.get(minLoad));
+					Thread.currentThread().sleep(1000);
+					admin.move(rtom.getEncodedNameAsBytes(),
+							Bytes.toBytes(serverCode.get(minLoad)));
+				
+				} catch (Exception e) {
+					// TODO Auto-generated catch block
+					//e.printStackTrace();
+				}
+			} catch (Exception e) {
+				// TODO Auto-generated catch block
+				e.printStackTrace();
+			}
+		}
+
+	}
+}
diff -uNr hbase-0.90.2/src/main/java/org/apache/hadoop/hbase/allocation/test/GroupTest.java hbase-0.90.2-local/src/main/java/org/apache/hadoop/hbase/allocation/test/GroupTest.java
--- src/main/java/org/apache/hadoop/hbase/allocation/test/GroupTest.java	1970-01-01 08:00:00.000000000 +0800
+++ src/main/java/org/apache/hadoop/hbase/allocation/test/GroupTest.java	2011-06-28 10:01:13.000000000 +0800
@@ -0,0 +1,105 @@
+package org.apache.hadoop.hbase.allocation.test;
+
+import java.io.BufferedInputStream;
+import java.io.File;
+import java.io.FileInputStream;
+import java.io.FileOutputStream;
+import java.io.IOException;
+import java.io.InputStream;
+import java.io.OutputStream;
+import java.util.ArrayList;
+import java.util.HashMap;
+import java.util.List;
+import java.util.TreeSet;
+import java.util.Map.Entry;
+
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.fs.FileSystem;
+import org.apache.hadoop.fs.Path;
+import org.apache.hadoop.hbase.HBaseConfiguration;
+import org.apache.hadoop.hbase.HConstants;
+import org.apache.hadoop.hbase.HRegionInfo;
+import org.apache.hadoop.hbase.HServerAddress;
+import org.apache.hadoop.hbase.HServerInfo;
+import org.apache.hadoop.hbase.HTableDescriptor;
+import org.apache.hadoop.hbase.MasterNotRunningException;
+import org.apache.hadoop.hbase.ZooKeeperConnectionException;
+import org.apache.hadoop.hbase.allocation.CheckMeta;
+import org.apache.hadoop.hbase.client.HBaseAdmin;
+import org.apache.hadoop.hbase.client.HTable;
+import org.apache.hadoop.hbase.client.MetaScanner;
+import org.apache.hadoop.hbase.client.Result;
+import org.apache.hadoop.hbase.client.MetaScanner.MetaScannerVisitor;
+import org.apache.hadoop.hbase.util.Bytes;
+import org.apache.hadoop.hbase.util.FSUtils;
+import org.apache.hadoop.hbase.util.Writables;
+import org.apache.hadoop.io.IOUtils;
+
+
+public class GroupTest {
+	private static HTableDescriptor[] listTables() throws IOException {
+		final TreeSet<HTableDescriptor> uniqueTables = new TreeSet<HTableDescriptor>();
+		MetaScannerVisitor visitor = new MetaScannerVisitor() {
+			public boolean processRow(Result result) throws IOException {
+				try {
+					byte[] value = result.getValue(HConstants.CATALOG_FAMILY,
+							HConstants.REGIONINFO_QUALIFIER);
+					HRegionInfo info = null;
+					if (value != null) {
+						info = Writables.getHRegionInfo(value);
+					}
+					// Only examine the rows where the startKey is zero length
+					if (info != null && info.getStartKey().length == 0) {
+						uniqueTables.add(info.getTableDesc());
+					}
+					return true;
+				} catch (RuntimeException e) {
+					throw e;
+				}
+			}
+		};
+		MetaScanner.metaScan(HBaseConfiguration.create(), visitor);
+
+		return uniqueTables.toArray(new HTableDescriptor[uniqueTables.size()]);
+	}
+	final static Configuration c = HBaseConfiguration.create();
+	public static void main(String args[]) throws IOException {
+		Configuration c = HBaseConfiguration.create();
+		HBaseAdmin d = new HBaseAdmin(c);
+		// d.disableTable("testPri");
+		// d.deleteTable("testPri");
+		HServerInfo s = null;
+		for (HServerInfo server : d.getClusterStatus().getServerInfo()) {
+			s = server;
+			System.out.println(server);
+		}
+		HTableDescriptor[] tables = listTables();
+		for (HTableDescriptor des : tables) {
+			
+				HashMap<HRegionInfo, HServerAddress> map = CheckMeta
+						.getRegionAddress(des.getNameAsString());
+				for (Entry<HRegionInfo, HServerAddress> e : map.entrySet())
+					System.out.println(e.getKey().getRegionNameAsString()+ ":"
+							+ e.getValue());
+		}
+		String conffile = "/home/liujia_l.pt/test.group";
+		FileOutputStream fwriter = new FileOutputStream(new File(conffile));
+		String ss = "0;dw79.kgb.sqa.cm4,60027;:1;dw79.kgb.sqa.cm4,60033;dw79.kgb.sqa.cm4,60024:";
+		fwriter.write(Bytes.toBytes(ss));
+		fwriter.close();
+		File localfile = new File(conffile);
+		FileSystem fs = FileSystem.get(c);
+
+		long localsize = localfile.length();
+		Path p=new Path(FSUtils.getRootDir(c)+ "groupinformation.conf");
+		Path inputpath= new Path("/disk1/hbasedata2/groupinformation.conf");
+		if (localsize > 0) {
+			InputStream inst = new BufferedInputStream(new FileInputStream(
+					conffile));		
+			OutputStream outst = fs.create(inputpath);
+			IOUtils.copyBytes(inst, outst, (int) localsize, true);
+		}
+
+	}
+
+}
diff -uNr hbase-0.90.2/src/main/java/org/apache/hadoop/hbase/allocation/test/TestForSchedule.java hbase-0.90.2-local/src/main/java/org/apache/hadoop/hbase/allocation/test/TestForSchedule.java
--- src/main/java/org/apache/hadoop/hbase/allocation/test/TestForSchedule.java	1970-01-01 08:00:00.000000000 +0800
+++ src/main/java/org/apache/hadoop/hbase/allocation/test/TestForSchedule.java	2011-06-24 15:05:52.000000000 +0800
@@ -0,0 +1,253 @@
+package org.apache.hadoop.hbase.allocation.test;
+
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.List;
+import java.util.Random;
+
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.hbase.HBaseConfiguration;
+import org.apache.hadoop.hbase.HColumnDescriptor;
+import org.apache.hadoop.hbase.HTableDescriptor;
+import org.apache.hadoop.hbase.MasterNotRunningException;
+import org.apache.hadoop.hbase.ZooKeeperConnectionException;
+import org.apache.hadoop.hbase.client.HBaseAdmin;
+import org.apache.hadoop.hbase.client.HTable;
+import org.apache.hadoop.hbase.client.Put;
+import org.apache.hadoop.hbase.client.Result;
+import org.apache.hadoop.hbase.client.ResultScanner;
+import org.apache.hadoop.hbase.client.Scan;
+import org.apache.hadoop.hbase.util.Bytes;
+/**
+ * Test for priority server
+ * @author liujia_l.pt
+ *
+ */
+public class TestForSchedule {
+	static final Configuration conf=HBaseConfiguration.create();
+	static final Random r=new Random();
+	public static void main(String args[])
+	{
+		HBaseAdmin admin = null;
+		try {
+			admin = new HBaseAdmin(conf);
+		} catch (MasterNotRunningException e2) {
+			e2.printStackTrace();
+		} catch (ZooKeeperConnectionException e2) {
+			// TODO Auto-generated catch block
+			e2.printStackTrace();
+		}
+		HTableDescriptor des;
+	try{
+			//HBaseAdmin admin=new HBaseAdmin(conf);
+			des=new HTableDescriptor ("testPri8");
+			des.addFamily(new HColumnDescriptor ("ff"));
+			des.setValue(Bytes.toBytes("priority"), Bytes.toBytes(1+""));
+			admin.createTable(des);
+	} catch (MasterNotRunningException e) {
+		// TODO Auto-generated catch block
+		e.printStackTrace();
+	} catch (ZooKeeperConnectionException e) {
+		// TODO Auto-generated catch block
+		e.printStackTrace();
+	} catch (IOException e) {
+		// TODO Auto-generated catch block
+		e.printStackTrace();
+	}
+	try{
+			des=new HTableDescriptor ("testPri7");
+			des.addFamily(new HColumnDescriptor ("ff"));
+			des.setValue(Bytes.toBytes("priority"), Bytes.toBytes(5+""));
+			admin.createTable(des);
+	} catch (MasterNotRunningException e) {
+		// TODO Auto-generated catch block
+		e.printStackTrace();
+	} catch (ZooKeeperConnectionException e) {
+		// TODO Auto-generated catch block
+		e.printStackTrace();
+	} catch (IOException e) {
+		// TODO Auto-generated catch block
+		e.printStackTrace();
+	}
+	try
+	{
+			des=new HTableDescriptor ("testPri6");
+			des.addFamily(new HColumnDescriptor ("ff"));
+			des.setValue(Bytes.toBytes("priority"), Bytes.toBytes(10+""));
+			admin.createTable(des);
+			//HTable t=new HTable("");
+	
+	} catch (MasterNotRunningException e) {
+		// TODO Auto-generated catch block
+		e.printStackTrace();
+	} catch (ZooKeeperConnectionException e) {
+		// TODO Auto-generated catch block
+		e.printStackTrace();
+	} catch (IOException e) {
+		// TODO Auto-generated catch block
+		e.printStackTrace();
+	}try{
+			des=new HTableDescriptor ("testPri5");
+			des.addFamily(new HColumnDescriptor ("ff"));
+			des.setValue(Bytes.toBytes("priority"), Bytes.toBytes(20+""));
+			admin.createTable(des);
+	} catch (MasterNotRunningException e) {
+		// TODO Auto-generated catch block
+		e.printStackTrace();
+	} catch (ZooKeeperConnectionException e) {
+		// TODO Auto-generated catch block
+		e.printStackTrace();
+	} catch (IOException e) {
+		// TODO Auto-generated catch block
+		e.printStackTrace();
+	}
+		
+		for(int i=0;i<10;i++)
+		{
+		
+			new Thread()
+			{
+				public void run()
+				{
+					HTable t = null;
+					try {
+						t = new HTable(conf,"testPri8");
+						t.setAutoFlush(false);
+						t.setWriteBufferSize(1024*1024);
+					} catch (IOException e) {
+						// TODO Auto-generated catch block
+						e.printStackTrace();
+					}
+					try {
+						TestForSchedule.testT(t);
+					} catch (IOException e) {
+						// TODO Auto-generated catch block
+						e.printStackTrace();
+					}
+				}
+			}.start();
+		
+			new Thread()
+			{
+				public void run()
+				{
+					HTable t = null;
+					try {
+						t = new HTable(conf,"testPri7");
+						t.setAutoFlush(false);
+						t.setWriteBufferSize(1024*1024);
+					} catch (IOException e) {
+						// TODO Auto-generated catch block
+						e.printStackTrace();
+					}
+	
+					try {
+						TestForSchedule.testT(t);
+					} catch (IOException e) {
+						// TODO Auto-generated catch block
+						e.printStackTrace();
+					}
+
+				}
+			}.start();
+			
+			new Thread()
+			{
+				public void run()
+				{
+					HTable t = null;
+					try {
+						t = new HTable(conf,"testPri6");
+						t.setAutoFlush(false);
+						t.setWriteBufferSize(1024*1024);
+					} catch (IOException e) {
+						// TODO Auto-generated catch block
+						e.printStackTrace();
+					}
+					try {
+						TestForSchedule.testT(t);
+					} catch (IOException e) {
+						// TODO Auto-generated catch block
+						e.printStackTrace();
+					}
+					
+				}
+			}.start();
+			new Thread()
+			{
+				public void run()
+				{
+					HTable t = null;
+					try {
+						t = new HTable(conf,"testPri5");		t.setAutoFlush(false);
+						t.setWriteBufferSize(1024*1024);
+					} catch (IOException e) {
+						// TODO Auto-generated catch block
+						e.printStackTrace();
+					}
+					try {
+						TestForSchedule.testT(t);
+					} catch (IOException e) {
+						// TODO Auto-generated catch block
+						e.printStackTrace();
+					}
+				}
+			}.start();
+		}
+			
+	
+	}
+	public static void putTest(HTable t,int i)
+	{
+		Put p=new Put(Bytes.toBytes(""+r.nextInt(1000000000)+(i)+r.nextInt(1000000000)));
+		
+		p.add(Bytes.toBytes("ff"), Bytes.toBytes("ff"), Bytes.toBytes("ff"+i+r.nextInt(1000000000)+r.nextInt(1000000000)+"fffffffffffffffffffffffffffffffffffffffffffffffffffff"+i));
+		try {
+			t.put(p);
+		} catch (IOException e1) {
+			// TODO Auto-generated catch block
+			e1.printStackTrace();
+		}
+	}
+	public static Result scanTest(ResultScanner sn)
+	
+	{
+		try {
+			return sn.next();
+		} catch (IOException e) {
+			// TODO Auto-generated catch block
+			e.printStackTrace();
+		}
+		return null;
+
+	}
+	static int inter=0;
+	public static void  testT(HTable t) throws IOException
+	{
+		int i=0;
+		long start=System.currentTimeMillis();
+		long end =System.currentTimeMillis();
+		int pri=
+			Integer.parseInt(Bytes.toString(t.getTableDescriptor().getValue(Bytes.toBytes("priority"))));
+		Scan s=new Scan();
+		s.setStartRow(Bytes.toBytes(r.nextInt(10)));
+		t.setScannerCaching(1000);
+		t.setAutoFlush(false);
+		t.setWriteBufferSize(1000*6000);
+		ResultScanner sn=t.getScanner(s);
+		while(true)
+		{
+			if(i%10000==0)
+			{
+				end=System.currentTimeMillis();
+				System.out.println("table"+t.getTableDescriptor().getNameAsString()+" pri :"+pri+" time:"+ (end-start));
+				start=end;
+			}
+			//scanTest(sn);
+			putTest(t,i);
+			i++;
+
+		}
+	}
+
+}
diff -uNr hbase-0.90.2/src/main/java/org/apache/hadoop/hbase/ipc/ScheduleHBaseServer.java hbase-0.90.2-local/src/main/java/org/apache/hadoop/hbase/ipc/ScheduleHBaseServer.java
--- src/main/java/org/apache/hadoop/hbase/ipc/ScheduleHBaseServer.java	1970-01-01 08:00:00.000000000 +0800
+++ src/main/java/org/apache/hadoop/hbase/ipc/ScheduleHBaseServer.java	2011-07-20 11:41:12.000000000 +0800
@@ -0,0 +1,1806 @@
+package org.apache.hadoop.hbase.ipc;
+
+/**
+ * Copyright 2010 The Apache Software Foundation
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.ByteArrayInputStream;
+import java.io.DataInputStream;
+import java.io.DataOutputStream;
+import java.io.IOException;
+import java.lang.reflect.Field;
+import java.lang.reflect.InvocationTargetException;
+import java.lang.reflect.Method;
+import java.net.BindException;
+import java.net.InetAddress;
+import java.net.InetSocketAddress;
+import java.net.ServerSocket;
+import java.net.Socket;
+import java.net.SocketException;
+import java.net.UnknownHostException;
+import java.nio.ByteBuffer;
+import java.nio.channels.CancelledKeyException;
+import java.nio.channels.ClosedChannelException;
+import java.nio.channels.SelectionKey;
+import java.nio.channels.Selector;
+import java.nio.channels.ServerSocketChannel;
+import java.nio.channels.SocketChannel;
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.Iterator;
+import java.util.LinkedList;
+import java.util.List;
+import java.util.Map;
+import java.util.Random;
+import java.util.concurrent.BlockingQueue;
+import java.util.concurrent.ConcurrentHashMap;
+import java.util.concurrent.ExecutorService;
+import java.util.concurrent.Executors;
+import java.util.concurrent.LinkedBlockingQueue;
+
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.hbase.HTableDescriptor;
+import org.apache.hadoop.hbase.MasterNotRunningException;
+import org.apache.hadoop.hbase.ZooKeeperConnectionException;
+import org.apache.hadoop.hbase.allocation.CheckMeta;
+import org.apache.hadoop.hbase.allocation.ScheduleQueue;
+import org.apache.hadoop.hbase.client.Action;
+import org.apache.hadoop.hbase.client.HBaseAdmin;
+import org.apache.hadoop.hbase.client.MultiAction;
+import org.apache.hadoop.hbase.io.HbaseObjectWritable;
+import org.apache.hadoop.hbase.io.WritableWithSize;
+import org.apache.hadoop.hbase.ipc.ByteBufferOutputStream;
+import org.apache.hadoop.hbase.ipc.HBaseRPCErrorHandler;
+import org.apache.hadoop.hbase.ipc.HBaseRpcMetrics;
+import org.apache.hadoop.hbase.ipc.HBaseServer;
+import org.apache.hadoop.hbase.ipc.ServerNotRunningException;
+import org.apache.hadoop.hbase.ipc.HBaseRPC.Invocation;
+import org.apache.hadoop.hbase.regionserver.HRegion;
+import org.apache.hadoop.hbase.regionserver.HRegionServer;
+import org.apache.hadoop.hbase.regionserver.InternalScanner;
+import org.apache.hadoop.hbase.util.Bytes;
+import org.apache.hadoop.io.ObjectWritable;
+import org.apache.hadoop.io.Writable;
+import org.apache.hadoop.io.WritableUtils;
+import org.apache.hadoop.security.UserGroupInformation;
+import org.apache.hadoop.util.ReflectionUtils;
+import org.apache.hadoop.util.StringUtils;
+import com.google.common.util.concurrent.ThreadFactoryBuilder;
+
+/**
+ * An abstract IPC service. IPC calls take a single {@link Writable} as a
+ * parameter, and return a {@link Writable} as their value. A service runs on a
+ * port and is defined by a parameter class and a value class.
+ * 
+ * Extends HBaseServer,and add schedule function to make table priority take
+ * effect.
+ */
+public class ScheduleHBaseServer extends HBaseServer {
+
+	public final static String pri_string = "priority";
+
+	final static int PING_CALL_ID = -1;
+
+	/**
+	 * priority refresh interval
+	 */
+	private final static int initInter = 120000;
+
+	/**
+	 * the priority map,cache the region table and scanner's priority in memory.
+	 */
+	private static Map<String, InternalScanner> scannersMap = new ConcurrentHashMap<String, InternalScanner>();
+	private final static ConcurrentHashMap<String, Integer> regionPriMap = new ConcurrentHashMap<String, Integer>();
+	private final static ConcurrentHashMap<String, Integer> tablePriMap = new ConcurrentHashMap<String, Integer>();
+	private final static ConcurrentHashMap<Long, String> scannerPriMap = new ConcurrentHashMap<Long, String>();
+	private final static ConcurrentHashMap<Long, Integer> scannerPriMapInteger = new ConcurrentHashMap<Long, Integer>();
+
+	// 1 : Introduce ping and server does not throw away RPCs
+	// 3 : RPC was refactored in 0.19
+
+	/**
+	 * How many calls/handler are allowed in the queue.
+	 */
+	private static final int MAX_QUEUE_SIZE_PER_HANDLER = 100;
+
+	private static final String WARN_RESPONSE_SIZE = "hbase.ipc.warn.response.size";
+
+	/** Default value for above param */
+	private static final int DEFAULT_WARN_RESPONSE_SIZE = 100 * 1024 * 1024;
+
+	private final int warnResponseSize;
+
+	public static final Log LOG = LogFactory
+	.getLog("org.apache.hadoop.ipc.ScheduleHBaseServer");
+
+	protected static final ThreadLocal<ScheduleHBaseServer> SERVER = new ThreadLocal<ScheduleHBaseServer>();
+	private volatile boolean started = false;
+
+	/**
+	 * Returns the server instance called under or null. May be called under
+	 * {@link #call(Writable, long)} implementations, and under {@link Writable}
+	 * methods of paramters and return values. Permits applications to access
+	 * the server context. copied from HBaseServer
+	 * 
+	 * @return HBaseServer
+	 */
+	public static ScheduleHBaseServer get() {
+		return SERVER.get();
+	}
+
+	/**
+	 * This is set to Call object before Handler invokes an RPC and reset after
+	 * the call returns.
+	 */
+	protected static final ThreadLocal<Call> CurCall = new ThreadLocal<Call>();
+
+	/**
+	 * Returns the remote side ip address when invoked inside an RPC Returns
+	 * null incase of an error.
+	 * 
+	 * @return InetAddress
+	 */
+	public static InetAddress getRemoteIp() {
+		Call call = CurCall.get();
+		if (call != null) {
+			return call.connection.socket.getInetAddress();
+		}
+		return null;
+	}
+
+	/**
+	 * Returns remote address as a string when invoked inside an RPC. Returns
+	 * null in case of an error. copied from HBaseServer
+	 * 
+	 * @return String
+	 */
+	public static String getRemoteAddress() {
+		InetAddress addr = getRemoteIp();
+		return (addr == null) ? null : addr.getHostAddress();
+	}
+
+	protected String bindAddress;
+	protected int port; // port we listen on
+	private int handlerCount; // number of handler threads
+	private int priorityHandlerCount;
+	private int readThreads; // number of read threads
+	protected Class<? extends Writable> paramClass; // class of call parameters
+	protected int maxIdleTime; // the maximum idle time after
+	// which a client may be
+	// disconnected
+	protected int thresholdIdleConnections; // the number of idle
+	// connections after which we
+	// will start cleaning up idle
+	// connections
+	int maxConnectionsToNuke; // the max number of
+	// connections to nuke
+	// during a cleanup
+
+	protected HBaseRpcMetrics rpcMetrics;
+
+	protected Configuration conf;
+
+	private int maxQueueSize;
+	protected int socketSendBufferSize;
+	protected final boolean tcpNoDelay; // if T then disable Nagle's Algorithm
+	protected final boolean tcpKeepAlive; // if T then use keepalives
+
+	volatile protected boolean running = true; // true while server runs
+	// protected BlockingQueue<Call> callQueue; // queued calls
+	protected BlockingQueue<Call> priorityCallQueue;
+
+	private int highPriorityLevel; // what level a high priority call is at
+
+	protected final List<Connection> connectionList = Collections
+	.synchronizedList(new LinkedList<Connection>());
+	// maintain a list
+	// of client connections
+	private Listener listener = null;
+	protected Responder responder = null;
+	protected int numConnections = 0;
+	private Handler[] handlers = null;
+	private Handler[] priorityHandlers = null;
+	protected HBaseRPCErrorHandler errorHandler = null;
+	private static int queueCapacity = 300;
+	private static final ScheduleQueue<Call> queue = new ScheduleQueue<Call>(
+			queueCapacity, 10);
+
+	private Object instance;
+	private HRegionServer regionserver;
+	private Class<?> implementation;
+	private Class<?> ifaces[];
+	private boolean verbose;
+
+	private static String classNameBase(String className) {
+		String[] names = className.split("\\.", -1);
+		if (names == null || names.length == 0) {
+			return className;
+		}
+		return names[names.length - 1];
+	}
+
+	/**
+	 * Construct an RPC server.
+	 * 
+	 * @param instance
+	 *            the instance whose methods will be called
+	 * @param conf
+	 *            the configuration to use
+	 * @param bindAddress
+	 *            the address to bind on to listen for connection
+	 * @param port
+	 *            the port to listen for connections on
+	 * @param numHandlers
+	 *            the number of method handler threads to run
+	 * @param verbose
+	 *            whether each call should be logged
+	 * @throws IOException
+	 *             e
+	 */
+	@SuppressWarnings({ "unchecked"})
+	public ScheduleHBaseServer(Object instance, final Class<?>[] ifaces,
+			Configuration conf, String bindAddress, int port, int numHandlers,
+			int metaHandlerCount, boolean verbose, int highPriorityLevel)
+	throws IOException {
+
+		this(bindAddress, port, Invocation.class, numHandlers,
+				metaHandlerCount, conf, classNameBase(instance.getClass()
+						.getName()), highPriorityLevel);
+		this.instance = instance;
+		this.regionserver = (HRegionServer) instance;
+		this.implementation = instance.getClass();
+		this.verbose = verbose;
+		this.ifaces = ifaces;
+		Field f;
+		try {
+			f = HRegionServer.class.getDeclaredField("scanners");
+			f.setAccessible(true);
+			Map<String, InternalScanner> scanMap = (Map<String, InternalScanner>) f
+			.get(instance);
+			scannersMap = scanMap;
+		} catch (Exception e) {
+
+		}
+		// create metrics for the advertised interfaces this server implements.
+		// this.rpcMetrics.createMetrics(this.ifaces);
+	}
+
+	/**
+	 * Initiate the region priority
+	 * 
+	 * @param regions
+	 *            the region want to get priority
+	 * @param force
+	 *            force refresh priority,if true will get priority from table
+	 *            descriptor.
+	 * @return the region priority
+	 */
+
+	@SuppressWarnings("unused")
+	private int initRegionPri(byte[] regions, boolean force) {
+		String region = Bytes.toString(regions);
+		return this.initRegionPri(region, force);
+
+	}
+
+	/**
+	 * Initiate the region priority
+	 * 
+	 * @param regions
+	 *            the region want to get priority
+	 * @param force
+	 *            force refresh priority,if true will get priority from table
+	 *            descriptor.
+	 * @return the region priority
+	 */
+	private int initRegionPri(String region, boolean force) {
+		if (!force) {
+			Integer ret = regionPriMap.get(region);
+			if (ret != null)
+				return ret;
+		}
+		Integer prii;
+		int pri = defaultPri;
+		HRegion hr = ((HRegionServer) this.instance).getOnlineRegion(Bytes
+				.toBytes(region));
+
+		if (hr != null) {
+			if (hr.getRegionInfo().isMetaRegion()
+					|| hr.getRegionInfo().isRootRegion()) {
+				pri = highestPri;
+				System.out.println("int init region" + region + ",pri:" + pri);
+				regionPriMap.put(region, pri);
+				return pri;
+			}
+			String tableName = hr.getTableDesc().getNameAsString();
+
+			prii = tablePriMap.get(tableName);
+			if (prii == null) {
+				if (hr.getTableDesc().getValue(Bytes.toBytes(pri_string)) != null) {
+					try {
+						pri = Integer.parseInt(Bytes.toString(hr.getTableDesc()
+								.getValue(Bytes.toBytes(pri_string))));
+					} catch (Exception e) {
+						e.printStackTrace();
+					}
+				}
+				tablePriMap.put(tableName, pri);
+			} else {
+				pri = prii;
+			}
+
+		}
+		regionPriMap.put(region, pri);
+		return pri;
+	}
+
+	/**
+	 * Initiate the scanner's priority,invoked by openscanner
+	 * 
+	 * @param call
+	 * @param value
+	 *            scanner id
+	 */
+	public void initScannerPri(Invocation call, Object value) {
+		Long id = (Long) value;
+		byte[] region = (byte[]) call.getParameters()[0];
+		String regionN = Bytes.toString(region);
+		Integer prii = regionPriMap.get(regionN);
+		if (prii == null) {
+			this.initRegionPri(regionN, false);
+		} 
+		scannerPriMap.put(id, regionN);
+	}
+
+	@Override
+	public Writable call(Writable param, long receivedTime) throws IOException {
+		try {
+			Invocation call = (Invocation) param;
+			if (call.getMethodName() == null) {
+				throw new IOException(
+						"Could not find requested method, the usual "
+						+ "cause is a version mismatch between client and server.");
+			}
+
+			Method method = implementation.getMethod(call.getMethodName(), call
+					.getParameterClasses());
+
+			long startTime = System.currentTimeMillis();
+
+			Object value = method.invoke(instance, call.getParameters());
+			/**
+			 * do with openScanner option, added by ScheduleHBaseServer
+			 */
+			if (call.getMethodName().endsWith("openScanner")) {
+				this.initScannerPri(call, value);
+			}
+
+			int processingTime = (int) (System.currentTimeMillis() - startTime);
+			int qTime = (int) (startTime - receivedTime);
+			if (LOG.isDebugEnabled()) {
+				LOG.debug("Served: " + call.getMethodName() + " queueTime= "
+						+ qTime + " procesingTime= " + processingTime);
+			}
+			rpcMetrics.rpcQueueTime.inc(qTime);
+			rpcMetrics.rpcProcessingTime.inc(processingTime);
+			rpcMetrics.inc(call.getMethodName(), processingTime);
+
+			return new HbaseObjectWritable(method.getReturnType(), value);
+
+		} catch (InvocationTargetException e) {
+			Throwable target = e.getTargetException();
+			if (target instanceof IOException) {
+				throw (IOException) target;
+			}
+			IOException ioe = new IOException(target.toString());
+			ioe.setStackTrace(target.getStackTrace());
+			throw ioe;
+		} catch (Throwable e) {
+			IOException ioe = new IOException(e.toString());
+			ioe.setStackTrace(e.getStackTrace());
+			throw ioe;
+		}
+	}
+
+	public static final int lowestPri = 10;
+	public static final int defaultPri = 5;
+	public static final int highestPri = -10;
+	public static final int highPri = 0;
+
+	public static int handleFreshInter = 6;
+	public static int move = Integer.SIZE - handleFreshInter;
+	private Thread priorityIniter = new Thread() {
+		public void run() {
+			while (running) {
+				initPriority();
+				try {
+
+					sleep(initInter);
+				} catch (InterruptedException e) {
+					e.printStackTrace();
+				}
+			}
+
+		}
+	};
+
+	@Override
+	public void start() {
+		this.started = true;
+		startThreads();
+		openServer();
+		this.priorityIniter.start();
+	}
+
+	/**
+	 * Initiate the table priorities.
+	 */
+	private void initPriority() {
+		try {
+			handleFreshInter = conf.getInt("hbase.schedule.refreshinter", 7);
+			move = Integer.SIZE - handleFreshInter;
+			HTableDescriptor[] tableDs = CheckMeta.getTables();
+			int pri = defaultPri;
+			for (HTableDescriptor des : tableDs) {
+				byte[] prib = des.getValue(Bytes.toBytes(pri_string));
+				if (prib != null) {
+					try {
+						pri = Integer.parseInt(Bytes.toString((prib)));
+					} catch (Exception e) {
+						LOG.error("table priority error :"
+								+ Bytes.toString(prib) + " table name:"
+								+ des.getNameAsString());
+					}
+				}
+				tablePriMap.put(des.getNameAsString(), pri);
+			}
+		} catch (Exception e) {
+			e.printStackTrace();
+		}
+
+
+		for (Long id : scannerPriMap.keySet()) {
+			if (scannersMap.get(String.valueOf(id)) == null) {
+				scannerPriMap.remove(id);
+			}
+		}
+		for (Long id : scannerPriMapInteger.keySet()) {
+			if (scannersMap.get(String.valueOf(id)) == null) {
+				scannerPriMapInteger.remove(id);
+			}
+		}
+
+		for (String regionName : regionPriMap.keySet()) {
+			this.initRegionPri(regionName, true);
+		}
+
+		// List<HRegionInfo> infos = ((HRegionServer) this.instance)
+		// .getOnlineRegions();
+		// for (HRegionInfo info : infos) {
+		// //System.out.println(Bytes.toString(info.getEncodedName() ));
+		// Integer pri = this.tablePriMap.get(info.getTableDesc().getName());
+		// if (pri != null) {
+		// this.regionPriMap.put(info.getEncodedNameAsBytes(), pri);
+		// } else if (info.isMetaRegion()) {
+		// this.regionPriMap.put(info.getEncodedNameAsBytes(),
+		// this.highestPri);
+		// } else if (info.isRootRegion()) {
+		// this.regionPriMap.put(info.getEncodedNameAsBytes(),
+		// this.highestPri);
+		// } else {
+		// this.regionPriMap.put(info.getEncodedNameAsBytes(),
+		// this.defaultPri);
+		// }
+		// }
+	}
+
+	/**
+	 * A convenience method to bind to a given address and report better
+	 * exceptions if the address is not a valid host.
+	 * 
+	 * @param socket
+	 *            the socket to bind
+	 * @param address
+	 *            the address to bind to
+	 * @param backlog
+	 *            the number of connections allowed in the queue
+	 * @throws BindException
+	 *             if the address can't be bound
+	 * @throws UnknownHostException
+	 *             if the address isn't a valid host name
+	 * @throws IOException
+	 *             other random errors from bind
+	 */
+	public static void bind(ServerSocket socket, InetSocketAddress address,
+			int backlog) throws IOException {
+		try {
+			socket.bind(address, backlog);
+		} catch (BindException e) {
+			BindException bindException = new BindException(
+					"Problem binding to " + address + " : " + e.getMessage());
+			bindException.initCause(e);
+			throw bindException;
+		} catch (SocketException e) {
+			// If they try to bind to a different host's address, give a better
+			// error message.
+			if ("Unresolved address".equals(e.getMessage())) {
+				throw new UnknownHostException("Invalid hostname for server: "
+						+ address.getHostName());
+			}
+			throw e;
+		}
+	}
+
+	/** A call queued for handling.copied from HBaseServer */
+	static class Call {
+		protected int id; // the client's call id
+		protected Writable param; // the parameter passed
+		protected Connection connection; // connection to client
+		protected long timestamp; // the time received when response is null
+		// the time served when response is not null
+		protected ByteBuffer response; // the response for this call
+
+		public Call(int id, Writable param, Connection connection) {
+			this.id = id;
+			this.param = param;
+			this.connection = connection;
+			this.timestamp = System.currentTimeMillis();
+			this.response = null;
+		}
+
+		public String toString() {
+			return param.toString() + " from " + connection.toString();
+		}
+
+		public void setResponse(ByteBuffer response) {
+			this.response = response;
+		}
+	}
+
+	/**
+	 * Listens on the socket. Creates jobs for the handler threads copied from
+	 * HBaseServer
+	 */
+	private class Listener extends Thread {
+
+		private ServerSocketChannel acceptChannel = null; // the accept channel
+		private Selector selector = null; // the selector that we use for the
+		// server
+		private Reader[] readers = null;
+		private int currentReader = 0;
+		private InetSocketAddress address; // the address we bind at
+		private Random rand = new Random();
+		private long lastCleanupRunTime = 0; // the last time when a cleanup
+		// connec-
+		// -tion (for idle connections) ran
+		private long cleanupInterval = 10000; // the minimum interval between
+		// two cleanup runs
+		private int backlogLength = conf.getInt("ipc.server.listen.queue.size",
+				128);
+
+		private ExecutorService readPool;
+
+		public Listener() throws IOException {
+			address = new InetSocketAddress(bindAddress, port);
+			// Create a new server socket and set to non blocking mode
+			acceptChannel = ServerSocketChannel.open();
+			acceptChannel.configureBlocking(false);
+
+			// Bind the server socket to the local host and port
+			bind(acceptChannel.socket(), address, backlogLength);
+			port = acceptChannel.socket().getLocalPort(); // Could be an
+			// ephemeral port
+			// create a selector;
+			selector = Selector.open();
+
+			readers = new Reader[readThreads];
+			readPool = Executors.newFixedThreadPool(readThreads,
+					new ThreadFactoryBuilder().setNameFormat(
+							"IPC Reader %d on port " + port).build());
+			for (int i = 0; i < readThreads; ++i) {
+				Selector readSelector = Selector.open();
+				Reader reader = new Reader(readSelector);
+				readers[i] = reader;
+				readPool.execute(reader);
+			}
+
+			// Register accepts on the server socket with the selector.
+			acceptChannel.register(selector, SelectionKey.OP_ACCEPT);
+			this.setName("IPC Server listener on " + port);
+			this.setDaemon(true);
+		}
+
+		private class Reader implements Runnable {
+			private volatile boolean adding = false;
+			private Selector readSelector = null;
+
+			Reader(Selector readSelector) {
+				this.readSelector = readSelector;
+			}
+
+			public void run() {
+				synchronized (this) {
+					while (running) {
+						SelectionKey key = null;
+						try {
+							readSelector.select();
+							while (adding) {
+								this.wait(1000);
+							}
+
+							Iterator<SelectionKey> iter = readSelector
+							.selectedKeys().iterator();
+							while (iter.hasNext()) {
+								key = iter.next();
+								iter.remove();
+								if (key.isValid()) {
+									if (key.isReadable()) {
+										doRead(key);
+									}
+								}
+								key = null;
+							}
+						} catch (InterruptedException e) {
+							if (running) { // unexpected -- log it
+								LOG.info(getName() + "caught: "
+										+ StringUtils.stringifyException(e));
+							}
+						} catch (IOException ex) {
+							LOG.error("Error in Reader", ex);
+						}
+					}
+				}
+			}
+
+			/**
+			 * This gets reader into the state that waits for the new channel to
+			 * be registered with readSelector. If it was waiting in select()
+			 * the thread will be woken up, otherwise whenever select() is
+			 * called it will return even if there is nothing to read and wait
+			 * in while(adding) for finishAdd call
+			 */
+			public void startAdd() {
+				adding = true;
+				readSelector.wakeup();
+			}
+
+			public synchronized SelectionKey registerChannel(
+					SocketChannel channel) throws IOException {
+				return channel.register(readSelector, SelectionKey.OP_READ);
+			}
+
+			public synchronized void finishAdd() {
+				adding = false;
+				this.notify();
+			}
+		}
+
+		/**
+		 * cleanup connections from connectionList. Choose a random range to
+		 * scan and also have a limit on the number of the connections that will
+		 * be cleanedup per run. The criteria for cleanup is the time for which
+		 * the connection was idle. If 'force' is true then all connections will
+		 * be looked at for the cleanup.
+		 * 
+		 * @param force
+		 *            all connections will be looked at for cleanup
+		 */
+		private void cleanupConnections(boolean force) {
+			if (force || numConnections > thresholdIdleConnections) {
+				long currentTime = System.currentTimeMillis();
+				if (!force
+						&& (currentTime - lastCleanupRunTime) < cleanupInterval) {
+					return;
+				}
+				int start = 0;
+				int end = numConnections - 1;
+				if (!force) {
+					start = rand.nextInt() % numConnections;
+					end = rand.nextInt() % numConnections;
+					int temp;
+					if (end < start) {
+						temp = start;
+						start = end;
+						end = temp;
+					}
+				}
+				int i = start;
+				int numNuked = 0;
+				while (i <= end) {
+					Connection c;
+					synchronized (connectionList) {
+						try {
+							c = connectionList.get(i);
+						} catch (Exception e) {
+							return;
+						}
+					}
+					if (c.timedOut(currentTime)) {
+						if (LOG.isDebugEnabled())
+							LOG.debug(getName() + ": disconnecting client "
+									+ c.getHostAddress());
+						closeConnection(c);
+						numNuked++;
+						end--;
+						// noinspection UnusedAssignment
+						c = null;
+						if (!force && numNuked == maxConnectionsToNuke)
+							break;
+					} else
+						i++;
+				}
+				lastCleanupRunTime = System.currentTimeMillis();
+			}
+		}
+
+		public void run() {
+			LOG.info(getName() + ": starting");
+			SERVER.set(ScheduleHBaseServer.this);
+
+			while (running) {
+				SelectionKey key = null;
+				try {
+					selector.select(); // FindBugs IS2_INCONSISTENT_SYNC
+					Iterator<SelectionKey> iter = selector.selectedKeys()
+					.iterator();
+					while (iter.hasNext()) {
+						key = iter.next();
+						iter.remove();
+						try {
+							if (key.isValid()) {
+								if (key.isAcceptable())
+									doAccept(key);
+							}
+						} catch (IOException ignored) {
+						}
+						key = null;
+					}
+				} catch (OutOfMemoryError e) {
+					if (errorHandler != null) {
+						if (errorHandler.checkOOME(e)) {
+							LOG.info(getName() + ": exiting on OOME");
+							closeCurrentConnection(key);
+							cleanupConnections(true);
+							return;
+						}
+					} else {
+						// we can run out of memory if we have too many threads
+						// log the event and sleep for a minute and give
+						// some thread(s) a chance to finish
+						LOG.warn("Out of Memory in server select", e);
+						closeCurrentConnection(key);
+						cleanupConnections(true);
+						try {
+							Thread.sleep(60000);
+						} catch (Exception ignored) {
+						}
+					}
+				} catch (Exception e) {
+					closeCurrentConnection(key);
+				}
+				cleanupConnections(false);
+			}
+			LOG.info("Stopping " + this.getName());
+
+			synchronized (this) {
+				try {
+					acceptChannel.close();
+					selector.close();
+				} catch (IOException ignored) {
+				}
+
+				selector = null;
+				acceptChannel = null;
+
+				// clean up all connections
+				while (!connectionList.isEmpty()) {
+					closeConnection(connectionList.remove(0));
+				}
+			}
+		}
+
+		private void closeCurrentConnection(SelectionKey key) {
+			if (key != null) {
+				Connection c = (Connection) key.attachment();
+				if (c != null) {
+					if (LOG.isDebugEnabled())
+						LOG.debug(getName() + ": disconnecting client "
+								+ c.getHostAddress());
+					closeConnection(c);
+				}
+			}
+		}
+
+		InetSocketAddress getAddress() {
+			return (InetSocketAddress) acceptChannel.socket()
+			.getLocalSocketAddress();
+		}
+
+		void doAccept(SelectionKey key) throws IOException, OutOfMemoryError {
+			Connection c;
+			ServerSocketChannel server = (ServerSocketChannel) key.channel();
+
+			SocketChannel channel;
+			while ((channel = server.accept()) != null) {
+				channel.configureBlocking(false);
+				channel.socket().setTcpNoDelay(tcpNoDelay);
+				channel.socket().setKeepAlive(tcpKeepAlive);
+
+				Reader reader = getReader();
+				try {
+					reader.startAdd();
+					SelectionKey readKey = reader.registerChannel(channel);
+					c = new Connection(channel, System.currentTimeMillis());
+					readKey.attach(c);
+					synchronized (connectionList) {
+						connectionList.add(numConnections, c);
+						numConnections++;
+					}
+					// if (LOG.isDebugEnabled())
+					// LOG.debug("Server connection from " + c.toString()
+					// + "; # active connections: " + numConnections
+					// + "; # queued calls: " + callQueue.size());
+				} finally {
+					reader.finishAdd();
+				}
+			}
+		}
+
+		void doRead(SelectionKey key) throws InterruptedException {
+			int count = 0;
+			Connection c = (Connection) key.attachment();
+			if (c == null) {
+				return;
+			}
+			c.setLastContact(System.currentTimeMillis());
+
+			try {
+				count = c.readAndProcess();
+			} catch (InterruptedException ieo) {
+				throw ieo;
+			} catch (Exception e) {
+				LOG.warn(getName() + ": readAndProcess threw exception " + e
+						+ ". Count of bytes read: " + count, e);
+				count = -1; // so that the (count < 0) block is executed
+			}
+			if (count < 0) {
+				if (LOG.isDebugEnabled())
+					LOG.debug(getName() + ": disconnecting client "
+							+ c.getHostAddress()
+							+ ". Number of active connections: "
+							+ numConnections);
+				closeConnection(c);
+				// c = null;
+			} else {
+				c.setLastContact(System.currentTimeMillis());
+			}
+		}
+
+		synchronized void doStop() {
+			if (selector != null) {
+				selector.wakeup();
+				Thread.yield();
+			}
+			if (acceptChannel != null) {
+				try {
+					acceptChannel.socket().close();
+				} catch (IOException e) {
+					LOG.info(getName()
+							+ ":Exception in closing listener socket. " + e);
+				}
+			}
+			readPool.shutdownNow();
+		}
+
+		// The method that will return the next reader to work with
+		// Simplistic implementation of round robin for now
+		Reader getReader() {
+			currentReader = (currentReader + 1) % readers.length;
+			return readers[currentReader];
+		}
+	}
+
+	// Sends responses of RPC back to clients. copied from HBaseServer
+	private class Responder extends Thread {
+		private Selector writeSelector;
+		private int pending; // connections waiting to register
+
+		final static int PURGE_INTERVAL = 900000; // 15mins
+
+		Responder() throws IOException {
+			this.setName("IPC Server Responder");
+			this.setDaemon(true);
+			writeSelector = Selector.open(); // create a selector
+			pending = 0;
+		}
+
+		public void run() {
+			LOG.info(getName() + ": starting");
+			SERVER.set(ScheduleHBaseServer.this);
+			long lastPurgeTime = 0; // last check for old calls.
+
+			while (running) {
+				try {
+					waitPending(); // If a channel is being registered, wait.
+					writeSelector.select(PURGE_INTERVAL);
+					Iterator<SelectionKey> iter = writeSelector.selectedKeys()
+					.iterator();
+					while (iter.hasNext()) {
+						SelectionKey key = iter.next();
+						iter.remove();
+						try {
+							if (key.isValid() && key.isWritable()) {
+								doAsyncWrite(key);
+							}
+						} catch (IOException e) {
+							LOG.info(getName()
+									+ ": doAsyncWrite threw exception " + e);
+						}
+					}
+					long now = System.currentTimeMillis();
+					if (now < lastPurgeTime + PURGE_INTERVAL) {
+						continue;
+					}
+					lastPurgeTime = now;
+					//
+					// If there were some calls that have not been sent out for
+					// a
+					// long time, discard them.
+					//
+					LOG.debug("Checking for old call responses.");
+					ArrayList<Call> calls;
+
+					// get the list of channels from list of keys.
+					synchronized (writeSelector.keys()) {
+						calls = new ArrayList<Call>(writeSelector.keys().size());
+						iter = writeSelector.keys().iterator();
+						while (iter.hasNext()) {
+							SelectionKey key = iter.next();
+							Call call = (Call) key.attachment();
+							if (call != null
+									&& key.channel() == call.connection.channel) {
+								calls.add(call);
+							}
+						}
+					}
+
+					for (Call call : calls) {
+						doPurge(call, now);
+					}
+				} catch (OutOfMemoryError e) {
+					if (errorHandler != null) {
+						if (errorHandler.checkOOME(e)) {
+							LOG.info(getName() + ": exiting on OOME");
+							return;
+						}
+					} else {
+						//
+						// we can run out of memory if we have too many threads
+						// log the event and sleep for a minute and give
+						// some thread(s) a chance to finish
+						//
+						LOG.warn("Out of Memory in server select", e);
+						try {
+							Thread.sleep(60000);
+						} catch (Exception ignored) {
+						}
+					}
+				} catch (Exception e) {
+					LOG.warn("Exception in Responder "
+							+ StringUtils.stringifyException(e));
+				}
+			}
+			LOG.info("Stopping " + this.getName());
+		}
+
+		private void doAsyncWrite(SelectionKey key) throws IOException {
+			Call call = (Call) key.attachment();
+			if (call == null) {
+				return;
+			}
+			if (key.channel() != call.connection.channel) {
+				throw new IOException("doAsyncWrite: bad channel");
+			}
+
+			synchronized (call.connection.responseQueue) {
+				if (processResponse(call.connection.responseQueue, false)) {
+					try {
+						key.interestOps(0);
+					} catch (CancelledKeyException e) {
+						/*
+						 * The Listener/reader might have closed the socket. We
+						 * don't explicitly cancel the key, so not sure if this
+						 * will ever fire. This warning could be removed.
+						 */
+						LOG.warn("Exception while changing ops : " + e);
+					}
+				}
+			}
+		}
+
+		//
+		// Remove calls that have been pending in the responseQueue
+		// for a long time.
+		//
+		private void doPurge(Call call, long now) {
+			synchronized (call.connection.responseQueue) {
+				Iterator<Call> iter = call.connection.responseQueue
+				.listIterator(0);
+				while (iter.hasNext()) {
+					Call nextCall = iter.next();
+					if (now > nextCall.timestamp + PURGE_INTERVAL) {
+						closeConnection(nextCall.connection);
+						break;
+					}
+				}
+			}
+		}
+
+		// Processes one response. Returns true if there are no more pending
+		// data for this channel.
+		//
+		@SuppressWarnings( { "ConstantConditions" })
+		private boolean processResponse(final LinkedList<Call> responseQueue,
+				boolean inHandler) throws IOException {
+			boolean error = true;
+			boolean done = false; // there is more data for this channel.
+			int numElements;
+			Call call = null;
+			try {
+				// noinspection SynchronizationOnLocalVariableOrMethodParameter
+				synchronized (responseQueue) {
+					//
+					// If there are no items for this channel, then we are done
+					//
+					numElements = responseQueue.size();
+					if (numElements == 0) {
+						error = false;
+						return true; // no more data for this channel.
+					}
+					//
+					// Extract the first call
+					//
+					call = responseQueue.removeFirst();
+					SocketChannel channel = call.connection.channel;
+					if (LOG.isDebugEnabled()) {
+						LOG.debug(getName() + ": responding to #" + call.id
+								+ " from " + call.connection);
+					}
+					//
+					// Send as much data as we can in the non-blocking fashion
+					//
+					int numBytes = channelWrite(channel, call.response);
+					if (numBytes < 0) {
+						return true;
+					}
+					if (!call.response.hasRemaining()) {
+						call.connection.decRpcCount();
+						// noinspection RedundantIfStatement
+						if (numElements == 1) { // last call fully processes.
+							done = true; // no more data for this channel.
+						} else {
+							done = false; // more calls pending to be sent.
+						}
+						if (LOG.isDebugEnabled()) {
+							LOG.debug(getName() + ": responding to #" + call.id
+									+ " from " + call.connection + " Wrote "
+									+ numBytes + " bytes.");
+						}
+					} else {
+						//
+						// If we were unable to write the entire response out,
+						// then
+						// insert in Selector queue.
+						//
+						call.connection.responseQueue.addFirst(call);
+
+						if (inHandler) {
+							// set the serve time when the response has to be
+							// sent later
+							call.timestamp = System.currentTimeMillis();
+
+							incPending();
+							try {
+								// Wakeup the thread blocked on select, only
+								// then can the call
+								// to channel.register() complete.
+								writeSelector.wakeup();
+								channel.register(writeSelector,
+										SelectionKey.OP_WRITE, call);
+							} catch (ClosedChannelException e) {
+								// Its ok. channel might be closed else where.
+								done = true;
+							} finally {
+								decPending();
+							}
+						}
+						if (LOG.isDebugEnabled()) {
+							LOG.debug(getName() + ": responding to #" + call.id
+									+ " from " + call.connection
+									+ " Wrote partial " + numBytes + " bytes.");
+						}
+					}
+					error = false; // everything went off well
+				}
+			} finally {
+				if (error && call != null) {
+					LOG.warn(getName() + ", call " + call + ": output error");
+					done = true; // error. no more data for this channel.
+					closeConnection(call.connection);
+				}
+			}
+			return done;
+		}
+
+		//
+		// Enqueue a response from the application.
+		//
+		void doRespond(Call call) throws IOException {
+			synchronized (call.connection.responseQueue) {
+				call.connection.responseQueue.addLast(call);
+				if (call.connection.responseQueue.size() == 1) {
+					processResponse(call.connection.responseQueue, true);
+				}
+			}
+		}
+
+		private synchronized void incPending() { // call waiting to be enqueued.
+			pending++;
+		}
+
+		private synchronized void decPending() { // call done enqueueing.
+			pending--;
+			notify();
+		}
+
+		private synchronized void waitPending() throws InterruptedException {
+			while (pending > 0) {
+				wait();
+			}
+		}
+	}
+
+	/**
+	 * Reads calls from a connection and queues them for handling. copied from
+	 * HBaseServer but changed in getCallPri() and processData() methods.
+	 * */
+	private class Connection {
+		private boolean versionRead = false; // if initial signature and
+		// version are read
+		private boolean headerRead = false; // if the connection header that
+		// follows version is read.
+		protected SocketChannel channel;
+		private ByteBuffer data;
+		private ByteBuffer dataLengthBuffer;
+		protected final LinkedList<Call> responseQueue;
+		private volatile int rpcCount = 0; // number of outstanding rpcs
+		private long lastContact;
+		private int dataLength;
+		protected Socket socket;
+		// Cache the remote host & port info so that even if the socket is
+		// disconnected, we can say where it used to connect to.
+		private String hostAddress;
+		private int remotePort;
+		protected UserGroupInformation ticket = null;
+
+		public Connection(SocketChannel channel, long lastContact) {
+			this.channel = channel;
+			this.lastContact = lastContact;
+			this.data = null;
+			this.dataLengthBuffer = ByteBuffer.allocate(4);
+			this.socket = channel.socket();
+			InetAddress addr = socket.getInetAddress();
+			if (addr == null) {
+				this.hostAddress = "*Unknown*";
+			} else {
+				this.hostAddress = addr.getHostAddress();
+			}
+			this.remotePort = socket.getPort();
+			this.responseQueue = new LinkedList<Call>();
+			if (socketSendBufferSize != 0) {
+				try {
+					socket.setSendBufferSize(socketSendBufferSize);
+				} catch (IOException e) {
+					LOG
+					.warn("Connection: unable to set socket send buffer size to "
+							+ socketSendBufferSize);
+				}
+			}
+		}
+
+		public String toString() {
+			return getHostAddress() + ":" + remotePort;
+		}
+
+		public String getHostAddress() {
+			return hostAddress;
+		}
+
+		public void setLastContact(long lastContact) {
+			this.lastContact = lastContact;
+		}
+
+		public long getLastContact() {
+			return lastContact;
+		}
+
+		/* Return true if the connection has no outstanding rpc */
+		private boolean isIdle() {
+			return rpcCount == 0;
+		}
+
+		/* Decrement the outstanding RPC count */
+		protected void decRpcCount() {
+			rpcCount--;
+		}
+
+		/* Increment the outstanding RPC count */
+		private void incRpcCount() {
+			rpcCount++;
+		}
+
+		protected boolean timedOut(long currentTime) {
+			return isIdle() && currentTime - lastContact > maxIdleTime;
+		}
+
+		public int readAndProcess() throws IOException, InterruptedException {
+			while (true) {
+				/*
+				 * Read at most one RPC. If the header is not read completely
+				 * yet then iterate until we read first RPC or until there is no
+				 * data left.
+				 */
+				int count;
+				if (dataLengthBuffer.remaining() > 0) {
+					count = channelRead(channel, dataLengthBuffer);
+					if (count < 0 || dataLengthBuffer.remaining() > 0)
+						return count;
+				}
+
+				if (!versionRead) {
+					// Every connection is expected to send the header.
+					ByteBuffer versionBuffer = ByteBuffer.allocate(1);
+					count = channelRead(channel, versionBuffer);
+					if (count <= 0) {
+						return count;
+					}
+					int version = versionBuffer.get(0);
+
+					dataLengthBuffer.flip();
+					if (!HEADER.equals(dataLengthBuffer)
+							|| version != CURRENT_VERSION) {
+						// Warning is ok since this is not supposed to happen.
+						LOG.warn("Incorrect header or version mismatch from "
+								+ hostAddress + ":" + remotePort
+								+ " got version " + version
+								+ " expected version " + CURRENT_VERSION);
+						return -1;
+					}
+					dataLengthBuffer.clear();
+					versionRead = true;
+					continue;
+				}
+
+				if (data == null) {
+					dataLengthBuffer.flip();
+					dataLength = dataLengthBuffer.getInt();
+
+					if (dataLength == ScheduleHBaseServer.PING_CALL_ID) {
+						dataLengthBuffer.clear();
+						return 0; // ping message
+					}
+					data = ByteBuffer.allocate(dataLength);
+					incRpcCount(); // Increment the rpc count
+				}
+
+				count = channelRead(channel, data);
+
+				if (data.remaining() == 0) {
+					dataLengthBuffer.clear();
+					data.flip();
+					if (headerRead) {
+						processData();
+						data = null;
+						return count;
+					}
+					processHeader();
+					headerRead = true;
+					data = null;
+					continue;
+				}
+				return count;
+			}
+		}
+
+		// / Reads the header following version
+		private void processHeader() throws IOException {
+			/*
+			 * In the current version, it is just a ticket. Later we could
+			 * introduce a "ConnectionHeader" class.
+			 */
+			DataInputStream in = new DataInputStream(new ByteArrayInputStream(
+					data.array()));
+			ticket = (UserGroupInformation) ObjectWritable.readObject(in, conf);
+		}
+
+		int report = 0;
+
+		private void processData() throws IOException, InterruptedException {
+			DataInputStream dis = new DataInputStream(new ByteArrayInputStream(
+					data.array()));
+			int id = dis.readInt(); // try to read an id
+
+			if (LOG.isDebugEnabled())
+				LOG.debug(" got #" + id);
+
+			Writable param = ReflectionUtils.newInstance(paramClass, conf); // read
+			// param
+			param.readFields(dis);
+
+			Call call = new Call(id, param, this);
+			report++;
+			if (((report << 54) >>> 54) == 0) {
+				//System.out.println("client :" + call);
+			}
+			if (priorityCallQueue != null
+					&& getQosLevel(param) > highPriorityLevel) {
+				priorityCallQueue.put(call);
+			} else {
+
+				// add call and find the call's priority.
+				queue.add(call, getCallPri(call));
+				// callQueue.put(call); // queue the call; maybe blocked here
+			}
+		}
+
+		protected int getCallPri(Call call) {
+			Invocation invo = (Invocation) call.param;
+			if (invo.getMethodName().endsWith("next")) {
+				Long scanN = (Long) invo.getParameters()[0];
+				Integer pri = scannerPriMapInteger.get(scanN);
+				if (pri == null) {
+					String region = scannerPriMap.get(scanN);
+					if (region != null) {
+						pri = regionPriMap.get(region);
+						if (pri != null) {
+							scannerPriMapInteger.put(scanN, pri);
+							return pri;
+						} else {
+							if (scannerPriMap.get(scanN) != null) {
+								return initRegionPri(region, false);
+							}
+						}
+					}
+				}
+				if (pri == null)
+					return defaultPri;
+				return pri;
+
+			}
+
+			else if (invo.getMethodName().endsWith("multi")) {
+				MultiAction multi = (MultiAction) invo.getParameters()[0];
+				for (Map.Entry<byte[], List<Action>> e : multi.actions
+						.entrySet()) {
+					String regionName = Bytes.toString(e.getKey());
+					// byte[] regionName = e.getKey();
+					Integer pri = regionPriMap.get(regionName);
+					if (pri == null) {
+						pri = initRegionPri(regionName, false);
+					}
+					if (pri == null)
+						return defaultPri;
+					return pri;
+
+				}
+				return defaultPri;
+
+			} else if (invo.getMethodName().endsWith("get")) {
+				byte[] region = (byte[]) invo.getParameters()[0];
+				String regionN = Bytes.toString(region);
+
+				Integer pri = regionPriMap.get(regionN);
+				if (pri == null) {
+					pri = initRegionPri(regionN, false);
+				}
+				if (pri == null)
+					return defaultPri;
+				return pri;
+			} else if (invo.getMethodName().endsWith("put")) {
+				String region = Bytes
+				.toString((byte[]) invo.getParameters()[0]);
+
+				Integer pri = regionPriMap.get(region);
+				if (pri == null) {
+					pri = initRegionPri(region, false);
+				}
+				if (pri == null)
+					return defaultPri;
+				return pri;
+
+			} else if (invo.getMethodName().endsWith("delete")) {
+				// byte[] region = (byte[]) invo.getParameters()[0];
+				String region = Bytes
+				.toString((byte[]) invo.getParameters()[0]);
+				Integer pri = regionPriMap.get(region);
+				if (pri == null) {
+					pri = initRegionPri(region, false);
+				}
+				if (pri == null)
+					return defaultPri;
+				return pri;
+
+			} else {
+				return highPri;
+			}
+
+		}
+
+		protected synchronized void close() {
+			data = null;
+			dataLengthBuffer = null;
+			if (!channel.isOpen())
+				return;
+			try {
+				socket.shutdownOutput();
+			} catch (Exception ignored) {
+			} // FindBugs DE_MIGHT_IGNORE
+			if (channel.isOpen()) {
+				try {
+					channel.close();
+				} catch (Exception ignored) {
+				}
+			}
+			try {
+				socket.close();
+			} catch (Exception ignored) {
+			}
+		}
+	}
+
+	/**
+	 * Handles queued calls . copied from HBase server but get data from the
+	 * prioriryQueue,and handle has priority
+	 */
+	private class Handler extends Thread {
+		private ScheduleQueue<Call> myCallQueue = null;
+		static final int BUFFER_INITIAL_SIZE = 1024;
+		private BlockingQueue<Call> myCallQueueBlock = null;
+		private int qPriority = 5;
+
+		public int getqPriority() {
+			return qPriority;
+		}
+
+		public void setqPriority(int qPriority) {
+			this.qPriority = qPriority;
+		}
+
+		public Handler(final ScheduleQueue<Call> cq, int instanceNumber) {
+			this.myCallQueue = cq;
+			this.setDaemon(true);
+
+			String threadName = "IPC Server handler " + instanceNumber + " on "
+			+ port;
+			if (cq == priorityCallQueue) {
+				// this is just an amazing hack, but it works.
+				threadName = "PRI " + threadName;
+			}
+			this.setName(threadName);
+		}
+
+		public Handler(final BlockingQueue<Call> cq, int instanceNumber) {
+			this.myCallQueueBlock = cq;
+			this.setDaemon(true);
+
+			String threadName = "IPC Server handler " + instanceNumber + " on "
+			+ port;
+			if (cq == priorityCallQueue) {
+				// this is just an amazing hack, but it works.
+				threadName = "PRI " + threadName;
+			}
+			this.setName(threadName);
+		}
+
+		public void run() {
+			LOG.info(getName() + ": starting");
+			SERVER.set(ScheduleHBaseServer.this);
+			int flush = 3;
+			while (running) {
+				try {
+					Call call = null;
+					if (myCallQueue != null) {
+						call = myCallQueue.get(this.getqPriority());
+						if (((flush << move) >>> move) == 0) {
+							myCallQueue.refresh();
+						}
+						flush++;
+					} else {
+						call = this.myCallQueueBlock.take();
+					}
+
+					if (LOG.isDebugEnabled())
+						LOG.debug(getName() + ": has #" + call.id + " from "
+								+ call.connection);
+
+					String errorClass = null;
+					String error = null;
+					Writable value = null;
+
+					CurCall.set(call);
+					try {
+						if (!started)
+							throw new ServerNotRunningException(
+							"Server is not running yet");
+						value = call(call.param, call.timestamp); // make the
+						// call
+					} catch (Throwable e) {
+						LOG.debug(getName() + ", call " + call + ": error: "
+								+ e, e);
+						errorClass = e.getClass().getName();
+						error = StringUtils.stringifyException(e);
+					}
+					CurCall.set(null);
+
+					int size = BUFFER_INITIAL_SIZE;
+					if (value instanceof WritableWithSize) {
+						// get the size hint.
+						WritableWithSize ohint = (WritableWithSize) value;
+						long hint = ohint.getWritableSize() + Bytes.SIZEOF_BYTE
+						+ Bytes.SIZEOF_INT;
+						if (hint > 0) {
+							if ((hint) > Integer.MAX_VALUE) {
+								// oops, new problem.
+								IOException ioe = new IOException(
+										"Result buffer size too large: " + hint);
+								errorClass = ioe.getClass().getName();
+								error = StringUtils.stringifyException(ioe);
+							} else {
+								size = (int) hint;
+							}
+						}
+					}
+					ByteBufferOutputStream buf = new ByteBufferOutputStream(
+							size);
+					DataOutputStream out = new DataOutputStream(buf);
+					out.writeInt(call.id); // write call id
+					out.writeBoolean(error != null); // write error flag
+
+					if (error == null) {
+						value.write(out);
+					} else {
+						WritableUtils.writeString(out, errorClass);
+						WritableUtils.writeString(out, error);
+					}
+
+					if (buf.size() > warnResponseSize) {
+						LOG.warn(getName() + ", responseTooLarge for: " + call
+								+ ": Size: "
+								+ StringUtils.humanReadableInt(buf.size()));
+					}
+
+					call.setResponse(buf.getByteBuffer());
+					responder.doRespond(call);
+				} catch (InterruptedException e) {
+					if (running) { // unexpected -- log it
+						LOG.info(getName() + " caught: "
+								+ StringUtils.stringifyException(e));
+					}
+				} catch (OutOfMemoryError e) {
+					if (errorHandler != null) {
+						if (errorHandler.checkOOME(e)) {
+							LOG.info(getName() + ": exiting on OOME");
+							return;
+						}
+					} else {
+						// rethrow if no handler
+						throw e;
+					}
+				} catch (Exception e) {
+					LOG.warn(getName() + " caught: "
+							+ StringUtils.stringifyException(e));
+				}
+			}
+			LOG.info(getName() + ": exiting");
+		}
+
+	}
+
+	public synchronized InetSocketAddress getListenerAddress() {
+		return listener.getAddress();
+	}
+
+	/*
+	 * Constructs a server listening on the named port and address. Parameters
+	 * passed must be of the named class. The <code>handlerCount</handlerCount>
+	 * determines the number of handler threads that will be used to process
+	 * calls.
+	 */
+	protected ScheduleHBaseServer(String bindAddress, int port,
+			Class<? extends Writable> paramClass, int handlerCount,
+			int priorityHandlerCount, Configuration conf, String serverName,
+			int highPriorityLevel) throws IOException {
+		super(bindAddress, port + 1, paramClass, handlerCount,
+				priorityHandlerCount, conf, serverName, highPriorityLevel);
+
+		this.bindAddress = bindAddress;
+		this.conf = conf;
+		handleFreshInter = conf.getInt("hbase.schedule.refreshinter", 7);
+		this.move = Integer.SIZE - handleFreshInter;
+		this.port = port;
+		this.paramClass = paramClass;
+		this.handlerCount = handlerCount >= 10 ? handlerCount : 10;
+		this.handlerCount = (int) (this.handlerCount * 1.5);
+		this.priorityHandlerCount = priorityHandlerCount;
+		this.socketSendBufferSize = 0;
+		this.readThreads = conf.getInt("ipc.server.read.threadpool.size", 10);
+		this.tcpNoDelay = conf.getBoolean("ipc.server.tcpnodelay", false);
+		this.tcpKeepAlive = conf.getBoolean("ipc.server.tcpkeepalive", true);
+		this.maxQueueSize = handlerCount * MAX_QUEUE_SIZE_PER_HANDLER;
+		if (priorityHandlerCount > 0) {
+			this.priorityCallQueue = new LinkedBlockingQueue<Call>(maxQueueSize);
+		} else {
+			this.priorityCallQueue = null;
+		}
+		this.highPriorityLevel = highPriorityLevel;
+		this.maxIdleTime = 2 * conf.getInt("ipc.client.connection.maxidletime",
+				1000);
+		this.maxConnectionsToNuke = conf.getInt("ipc.client.kill.max", 10);
+		this.thresholdIdleConnections = conf.getInt("ipc.client.idlethreshold",
+				4000);
+
+		// Start the listener here and let it bind to the port
+
+		super.stop();
+		listener = new Listener();
+		responder = new Responder();
+		this.port = listener.getAddress().getPort();
+		this.rpcMetrics = new HBaseRpcMetrics(serverName, Integer
+				.toString(this.port));
+
+		this.warnResponseSize = conf.getInt(WARN_RESPONSE_SIZE,
+				DEFAULT_WARN_RESPONSE_SIZE);
+		// Create the responder here
+
+	}
+
+	protected void closeConnection(Connection connection) {
+		synchronized (connectionList) {
+			if (connectionList.remove(connection))
+				numConnections--;
+		}
+		connection.close();
+	}
+
+	/**
+	 * translate thread priority to system priority
+	 * 
+	 * @param tpri
+	 * @return
+	 */
+	private int priTrans(int tpri) {
+		switch (tpri) {
+		case 10:
+			return 1;
+		case 9:
+			return 2;
+		case 8:
+			return 3;
+		case 7:
+			return 4;
+		case 6:
+			return 5;
+		case 5:
+			return 6;
+		case 4:
+			return 7;
+		case 3:
+			return 8;
+		case 2:
+			return 9;
+		case 1:
+			return 10;
+		default:
+			return 5;
+		}
+	}
+
+	/**
+	 * start Threads and set priority of handlers
+	 */
+	@Override
+	public synchronized void startThreads() {
+		responder.start();
+		listener.start();
+		handlers = new Handler[handlerCount];
+		int pri = 10;
+		int minPri = 10;
+		for (int i = 0; i < handlerCount; i++) {
+			if (pri <= 0) {
+				pri = 10;
+			}
+			if (pri < minPri) {
+				minPri = pri;
+			}
+			handlers[i] = new Handler(queue, i);
+			handlers[i].setPriority(pri);
+			handlers[i].setqPriority(priTrans(pri));
+			pri--;
+		}
+		for (int i = 0; i < handlerCount; i++) {
+			handlers[i].start();
+		}
+
+		if (priorityHandlerCount > 0) {
+			priorityHandlers = new Handler[priorityHandlerCount];
+			for (int i = 0; i < priorityHandlerCount; i++) {
+				priorityHandlers[i] = new Handler(priorityCallQueue, i);
+				priorityHandlers[i].start();
+			}
+		}
+	}
+
+	/** Stops the service. No new calls will be handled after this is called. */
+	@Override
+	public synchronized void stop() {
+		LOG.info("Stopping server on " + port);
+		running = false;
+		if (handlers != null) {
+			for (Handler handler : handlers) {
+				if (handler != null) {
+					handler.interrupt();
+				}
+			}
+		}
+		if (priorityHandlers != null) {
+			for (Handler handler : priorityHandlers) {
+				if (handler != null) {
+					handler.interrupt();
+				}
+			}
+		}
+		listener.interrupt();
+		listener.doStop();
+		responder.interrupt();
+		notifyAll();
+		if (this.rpcMetrics != null) {
+			this.rpcMetrics.shutdown();
+		}
+		if (this.priorityIniter != null) {
+			this.priorityIniter.interrupt();
+		}
+		/**
+		 * added here to stop the priority refresher.
+		 */
+		this.queue.stop();
+	}
+
+	/**
+	 * The number of rpc calls in the queue. this method return the
+	 * {@link ScheduleQueue} size.
+	 * 
+	 * @return The number of rpc calls in the queue.
+	 */
+	public int getCallQueueLen() {
+		return this.queue.size();
+	}
+
+}
diff -uNr hbase-0.90.2/src/main/java/org/apache/hadoop/hbase/master/GroupAssignmentManager.java hbase-0.90.2-local/src/main/java/org/apache/hadoop/hbase/master/GroupAssignmentManager.java
--- src/main/java/org/apache/hadoop/hbase/master/GroupAssignmentManager.java	1970-01-01 08:00:00.000000000 +0800
+++ src/main/java/org/apache/hadoop/hbase/master/GroupAssignmentManager.java	2011-07-20 11:41:12.000000000 +0800
@@ -0,0 +1,1590 @@
+/**
+ * Copyright 2010 The Apache Software Foundation
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.hbase.master;
+
+import java.io.BufferedInputStream;
+import java.io.IOException;
+import java.lang.reflect.Field;
+import java.util.ArrayList;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Map;
+import java.util.Map.Entry;
+import java.util.Random;
+import java.util.TreeMap;
+import java.util.TreeSet;
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.fs.FSDataInputStream;
+import org.apache.hadoop.fs.Path;
+
+import org.apache.hadoop.hbase.HBaseConfiguration;
+import org.apache.hadoop.hbase.HConstants;
+import org.apache.hadoop.hbase.HRegionInfo;
+import org.apache.hadoop.hbase.HServerAddress;
+import org.apache.hadoop.hbase.HServerInfo;
+import org.apache.hadoop.hbase.HTableDescriptor;
+import org.apache.hadoop.hbase.MasterNotRunningException;
+import org.apache.hadoop.hbase.NotServingRegionException;
+import org.apache.hadoop.hbase.Server;
+import org.apache.hadoop.hbase.UnknownRegionException;
+import org.apache.hadoop.hbase.ZooKeeperConnectionException;
+import org.apache.hadoop.hbase.allocation.CheckMeta;
+import org.apache.hadoop.hbase.allocation.group.AutoBalance;
+import org.apache.hadoop.hbase.catalog.CatalogTracker;
+import org.apache.hadoop.hbase.catalog.MetaEditor;
+import org.apache.hadoop.hbase.catalog.MetaReader;
+import org.apache.hadoop.hbase.client.HBaseAdmin;
+import org.apache.hadoop.hbase.client.HTable;
+import org.apache.hadoop.hbase.client.MetaScanner;
+import org.apache.hadoop.hbase.client.Result;
+import org.apache.hadoop.hbase.client.MetaScanner.MetaScannerVisitor;
+import org.apache.hadoop.hbase.executor.ExecutorService;
+import org.apache.hadoop.hbase.executor.RegionTransitionData;
+import org.apache.hadoop.hbase.ipc.ScheduleHBaseServer;
+import org.apache.hadoop.hbase.master.AssignmentManager.RegionState;
+import org.apache.hadoop.hbase.master.LoadBalancer.RegionPlan;
+import org.apache.hadoop.hbase.master.handler.ClosedRegionHandler;
+import org.apache.hadoop.hbase.master.handler.OpenedRegionHandler;
+
+import org.apache.hadoop.hbase.util.Bytes;
+import org.apache.hadoop.hbase.util.FSUtils;
+import org.apache.hadoop.hbase.util.Pair;
+import org.apache.hadoop.hbase.util.Threads;
+import org.apache.hadoop.hbase.util.Writables;
+import org.apache.hadoop.hbase.zookeeper.ZKAssign;
+import org.apache.hadoop.hbase.zookeeper.ZKTable;
+import org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher;
+import org.apache.hadoop.io.Writable;
+import org.apache.zookeeper.AsyncCallback;
+import org.apache.zookeeper.KeeperException;
+import org.apache.zookeeper.data.Stat;
+
+/**
+ * 
+ * manager assignment of region according to the group information
+ * 
+ */
+public class GroupAssignmentManager extends AssignmentManager {
+	// contains the table group information
+	private static HashMap<String, List<String>> tableGroup = new HashMap<String, List<String>>();
+	// contains the server group infomation
+	private static HashMap<String, HashSet<HServerInfo>> groupServers = new HashMap<String, HashSet<HServerInfo>>();
+	// contains the
+	private static HashMap<String, HashSet<String>> groupServersString = new HashMap<String, HashSet<String>>();
+
+	// used only when refresh configuration
+	private static HashMap<String, Boolean> groupDifConf = new HashMap<String, Boolean>();
+
+	static HMaster master;
+	static private Configuration conf = HBaseConfiguration.create();
+
+	// the default group which servers and tables belong to
+	public static final String DEFAULT_GROUP = "0";
+
+	// group information key in table descriptor.
+	public static final byte[] GROUP_KEY = Bytes.toBytes("group");
+	public static final String GROUP_SPLITER = ",";
+	private static ServerManager serverManager;
+	private static HBaseAdmin admin;
+	private static final Log LOG = LogFactory
+	.getLog(GroupAssignmentManager.class);
+	// TimeoutMonitor timeoutMonitor;
+	static CatalogTracker catalogTracker;
+	private ZKTable zkTableIn;
+	static final int refreshInterver = 500000;
+	private ExecutorService executorServiceIn = null;
+
+	// the gap between the maximum and minimum when do the balance
+	public static final int div = 2;
+
+	/**
+	 * initiate the refresh thread which check the wrong assignment and load the
+	 * group infomation
+	 */
+	static {
+
+		try {
+			long period = conf.getLong("hbase.balancer.period", 300000);
+			AutoBalance balancer = new AutoBalance(period);
+			balancer.startBalance();
+		} catch (Exception e1) {
+			LOG.error("start balancer error" + e1.getMessage());
+			e1.printStackTrace();
+		}
+		Thread refresher = new Thread() {
+			public void run() {
+				while (true) {
+					try {
+						try {
+							sleep(refreshInterver);
+						} catch (Exception e1) {
+
+							e1.printStackTrace();
+						}
+						if (GroupAssignmentManager.master != null
+								&& GroupAssignmentManager.master.isAlive()
+								&& !master.isStopped()) {
+							synchronized(GroupAssignmentManager.class)
+							{
+								HTableDescriptor[] dess = GroupAssignmentManager
+								.initValue();
+								maintainGroup(dess);
+							}
+							LOG.debug("groupDifConf:" + groupDifConf);
+							LOG.debug("server groups:" + groupServers);
+							LOG.debug("table groups:" + tableGroup);
+
+						} else if (GroupAssignmentManager.master == null) {
+
+							try {
+								LOG.debug("server groups:" + groupServers);
+								LOG.debug("table groups:" + tableGroup);
+								sleep(refreshInterver);
+							} catch (InterruptedException e) {
+								e.printStackTrace();
+							}
+
+						} else {
+							break;
+						}
+					} catch (Exception e) {
+						e.printStackTrace();
+					}
+				}
+			}
+		};
+		refresher.start();
+	}
+
+	private static boolean haveGroup(String tableName) {
+		HTableDescriptor t = null;
+		if (admin == null) {
+			try {
+				admin = new HBaseAdmin(conf);
+			} catch (MasterNotRunningException e) {
+				e.printStackTrace();
+			} catch (ZooKeeperConnectionException e) {
+				e.printStackTrace();
+			}
+		}
+		try {
+			t = admin.getTableDescriptor(Bytes.toBytes(tableName));
+		} catch (Exception e) {
+			e.printStackTrace();
+		}
+		if (t != null) {
+			byte[] groupsb = t.getValue(GROUP_KEY);
+			if (groupsb != null) {
+				return true;
+			}
+		}
+		return false;
+	}
+
+	private static String[] getTableGroupsInner(String tableName) {
+		String[] groups = new String[] { "0" };
+		if (admin == null) {
+			try {
+				admin = new HBaseAdmin(conf);
+			} catch (MasterNotRunningException e) {
+				e.printStackTrace();
+			} catch (ZooKeeperConnectionException e) {
+				e.printStackTrace();
+			}
+		}
+		HTableDescriptor t = null;
+		try {
+			t = admin.getTableDescriptor(Bytes.toBytes(tableName));
+		} catch (IOException e) {
+			e.printStackTrace();
+		}
+		if (t != null) {
+			byte[] groupsb = t.getValue(GROUP_KEY);
+			if (groupsb != null) {
+				groups = Bytes.toString(t.getValue(GROUP_KEY)).split(
+						GROUP_SPLITER);
+			}
+		}
+		return groups;
+
+	}
+
+	@SuppressWarnings("unused")
+	private HServerAddress serveringServer(HRegionInfo info) {
+		Map<String, HServerInfo> map = serverManager.getOnlineServers();
+		for (HServerInfo server : map.values()) {
+			try {
+				if (admin.getConnection().getHRegionConnection(
+						server.getServerAddress()).getRegionInfo(
+								info.getEncodedNameAsBytes()) != null) {
+					return server.getServerAddress();
+				}
+			} catch (NotServingRegionException e) {
+				continue;
+			} catch (Exception e) {
+				e.printStackTrace();
+			}
+		}
+		return null;
+
+	}
+
+	// /**
+	// * Gets the online regions of the specified table. This method looks at
+	// the
+	// * in-memory state. It does not go to <code>.META.</code>. Only returns
+	// * <em>online</em> regions. If a region on this table has been closed
+	// during
+	// * a disable, etc., it will be included in the returned list. So, the
+	// * returned list may not necessarily be ALL regions in this table, its all
+	// * the ONLINE regions in the table.
+	// *
+	// * @param tableName
+	// * @return Online regions from <code>tableName</code>
+	// */
+	//
+	// public List<HRegionInfo> getRegionsOfTable(byte[] tableName) {
+	// if (true)
+	// return super.getRegionsOfTable(tableName);
+	// // System.out.println("In my method ............................");
+	// if (this.getZKTable().isDisablingTable(Bytes.toString(tableName))
+	// || this.getZKTable().isDisabledTable(Bytes.toString(tableName))) {
+	// System.out.println("Table disabled ............................");
+	// final List<HRegionInfo> l = super.getRegionsOfTable(tableName);
+	// System.out.println("there are  " + l.size()
+	// + " regions not disabled ............................");
+	// Thread[] threads = new Thread[l.size()];
+	// HashMap<HRegionInfo, HServerAddress> regionMaps = null;
+	// try {
+	// regionMaps = CheckMeta.getRegionAddress(Bytes
+	// .toString(tableName), CheckMeta.getAllRegionInfo());
+	// } catch (IOException e1) {
+	// // TODO Auto-generated catch block
+	// e1.printStackTrace();
+	// } catch (InterruptedException e1) {
+	// // TODO Auto-generated catch block
+	// e1.printStackTrace();
+	// }
+	// if (regionMaps == null) {
+	//
+	// } else {
+	// l.addAll(regionMaps.keySet());
+	// }
+	// boolean allOffLine = false;
+	// while (l.size() != 0) {
+	// allOffLine = true;
+	// for (HRegionInfo info2 : l) {
+	// if (info2.isSplit() || (!info2.isOffline())) {
+	// allOffLine = false;
+	// }
+	// }
+	// if (allOffLine) {
+	// break;
+	// }
+	// for (int i = 0; i < l.size(); i++) {
+	// final HRegionInfo info = l.get(i);
+	// threads[i] = new Thread() {
+	// public void run() {
+	// HServerAddress address = serveringServer(info);
+	// if (address == null) {
+	// System.out
+	// .println("disabled table have regions "
+	// + info.getRegionNameAsString());
+	// unassign(info, true);
+	// clearRegionFromTransition(info);
+	// l.remove(info);
+	// } else {
+	// System.out
+	// .println("disabled table have regions "
+	// + info.getRegionNameAsString()
+	// + "servering at " + address);
+	// unassign(info, true);
+	// }
+	// }
+	// };
+	// threads[i].start();
+	// }
+	// for (int i = 0; i < l.size(); i++) {
+	// try {
+	// threads[i].join();
+	// } catch (InterruptedException e) {
+	// // TODO Auto-generated catch block
+	// e.printStackTrace();
+	// }
+	// }
+	// }
+	//
+	// }
+	// return super.getRegionsOfTable(tableName);
+	// }
+
+	private static String getTableGroup(HTableDescriptor dess) {
+		byte[] group = dess.getValue(GROUP_KEY);
+		if (group != null) {
+			return Bytes.toString(group);
+		}
+		return DEFAULT_GROUP;
+	}
+
+	private static void maintainGroup(HTableDescriptor[] dess) {
+		try {
+			HTableDescriptor t[];
+			if (dess == null) {
+				t = listTables();
+			} else {
+				t = dess;
+			}
+			HashMap<HRegionInfo, HServerAddress> maps = null;
+			try {
+				maps = CheckMeta.getAllRegionInfo();
+			} catch (InterruptedException e1) {
+				e1.printStackTrace();
+			}
+
+			if (maps == null)
+				return;
+			for (HTableDescriptor des : t) {
+				try {
+					Map<HRegionInfo, HServerAddress> map = CheckMeta
+					.getRegionAddress(des.getNameAsString(), maps);
+
+					for (HRegionInfo hri : map.keySet()) {
+						if (hri.isOffline() || hri.isMetaRegion()
+								|| hri.isRootRegion() || hri.isSplit()
+								|| hri.isSplitParent())
+							continue;
+						if (!getTableGroup(hri.getTableDesc()).equals(
+								getTableGroup(des))) {
+							LOG.error(" error region group not right: region:"
+									+ hri.getRegionNameAsString());
+							LOG.error(" region desc:" + hri.getTableDesc());
+							LOG.error(" table desc:" + des);
+							hri.setTableDesc(des);
+							MetaEditor.updateRegionInfo(catalogTracker, hri);
+							master.getMasterFileSystem().updateRegionInfo(hri);
+						}
+					}
+					List<HServerInfo> servers = getAvailableServer(des
+							.getNameAsString());
+					if (servers.size() == 0) {
+						continue;
+					}
+					for (HRegionInfo info : map.keySet()) {
+						boolean shouldMove = true;
+						for (HServerInfo server : servers) {
+							if (server.getServerAddress().getHostname().equals(
+									map.get(info).getHostname())
+									&& (server.getServerAddress().getPort() == map
+											.get(info).getPort())) {
+								shouldMove = false;
+								break;
+							}
+						}
+
+						if (shouldMove) {
+							try {
+
+								HServerInfo s = servers.get(RANDOM
+										.nextInt(servers.size()));
+								LOG.info("table is:" + des);
+								LOG
+								.info("table group is:"
+										+ getTableGroups(des
+												.getNameAsString()));
+								LOG.info("move region:" + info.getEncodedName()
+										+ " to " + s.getServerName()
+										+ " from :"
+										+ map.get(info).getHostname() + ":"
+										+ map.get(info).getPort());
+								LOG
+								.info("the available servers are:"
+										+ servers);
+								master.move(info.getEncodedNameAsBytes(), Bytes
+										.toBytes(s.getServerName()));
+							} catch (Exception e) {
+								e.printStackTrace();
+							}
+						}
+
+					}
+				} catch (Exception e) {
+
+					LOG.info("The table can't get region info" + des);
+					e.printStackTrace();
+				}
+
+			}
+		} catch (IOException e) {
+			e.printStackTrace();
+		}
+
+	}
+
+	/**
+	 * add a new group,only refresh the memory group information,use should
+	 * change the group information file first
+	 * 
+	 * @param groupName
+	 * @param servers
+	 *            the servers belong to the group
+	 */
+	public static void newGroup(String groupName, List<HServerInfo> servers) {
+		HashSet<HServerInfo> serverSet = groupServers.get(groupName);
+		if (serverSet == null) {
+			serverSet = new HashSet<HServerInfo>();
+			groupServers.put(groupName, serverSet);
+		}
+		for (HServerInfo info : servers) {
+			serverSet.add(info);
+		}
+
+	}
+
+	private static boolean readConfig() {
+		try {
+
+			FSDataInputStream input = null;
+			try {
+				input = master.getMasterFileSystem().getFileSystem().open(
+						new Path(FSUtils.getRootDir(conf),
+						"groupinformation.conf"));
+			} catch (Exception e1) {
+				e1.printStackTrace();
+			}
+			if (input != null) {
+				BufferedInputStream binput = new BufferedInputStream(input);
+				int size = binput.available();
+				byte[] result = new byte[size];
+
+				binput.read(result);
+				String groups = Bytes.toString(result);
+				String[] grouplines = groups.split(":");
+				binput.close();
+				System.out.println("config is" + Bytes.toString(result));
+
+				for (String line : grouplines) {
+					if (line == null || line.length() <= 0)
+						continue;
+					String[] serverlines = line.split(";");
+
+					// System.out.println("Group" + serverlines[0]);
+					String groupName = serverlines[0];
+					HashSet<String> set = new HashSet<String>();
+					String groupDifConfigV = serverlines[1];
+					try {
+						groupDifConf.put(groupName, Boolean
+								.parseBoolean(groupDifConfigV));
+					} catch (Exception e) {
+						groupDifConf.put(groupName, false);
+						e.printStackTrace();
+					}
+					for (int i = 2; i < serverlines.length; i++) {
+						set.add(serverlines[i]);
+					}
+					groupServersString.put(groupName, set);
+				}
+			}
+
+		} catch (Exception e) {
+			// TODO Auto-generated catch block
+
+			e.printStackTrace();
+			if (groupServersString.get(DEFAULT_GROUP) == null) {
+				groupServersString.put(DEFAULT_GROUP, new HashSet<String>());
+				LOG.error("there is no server in group 0 ");
+				return false;
+			}
+
+		}
+		if (groupServersString.get(DEFAULT_GROUP) == null) {
+			groupServersString.put(DEFAULT_GROUP, new HashSet<String>());
+			LOG.error("there is no server in group 0 ");
+			return false;
+		}
+		return true;
+
+	}
+
+	private static void initServerInfo() {
+		List<HServerInfo> list = serverManager.getOnlineServersList();
+		HashMap<String, HServerInfo> serverMap = new HashMap<String, HServerInfo>();
+		for (HServerInfo info : list) {
+			serverMap.put(info.getServerAddress().getHostname() + ","
+					+ info.getServerAddress().getPort(), info);
+		}
+		for (String group : groupServersString.keySet()) {
+			HashSet<HServerInfo> set = new HashSet<HServerInfo>();
+			for (String address : groupServersString.get(group)) {
+				if (serverMap.get(address) != null) {
+					set.add(serverMap.get(address));
+					list.remove(serverMap.get(address));
+				}
+			}
+			groupServers.put(group, set);
+
+		}
+
+		for (String group : groupServers.keySet()) {
+			if (groupServersString.get(group) == null) {
+				groupServers.remove(group);
+			}
+		}
+		for (String group : groupDifConf.keySet()) {
+			if (groupServersString.get(group) == null) {
+				groupDifConf.remove(group);
+			}
+		}
+		for (HServerInfo server : list) {
+			groupDifConf.put(DEFAULT_GROUP, false);
+			groupServers.get(DEFAULT_GROUP).add(server);
+		}
+		for (String s : groupServers.keySet()) {
+			if (groupDifConf.get(s) == null) {
+				groupDifConf.put(DEFAULT_GROUP, false);
+			}
+		}
+
+	}  
+	private static HTableDescriptor[] listTables() throws IOException {
+		return CheckMeta.getTables();
+//		final TreeSet<HTableDescriptor> uniqueTables = new TreeSet<HTableDescriptor>();
+//		MetaScannerVisitor visitor = new MetaScannerVisitor() {
+//			public boolean processRow(Result result) throws IOException {
+//				try {
+//					byte[] value = result.getValue(HConstants.CATALOG_FAMILY,
+//							HConstants.REGIONINFO_QUALIFIER);
+//					HRegionInfo info = null;
+//					if (value != null) {
+//						info = Writables.getHRegionInfo(value);
+//					}
+//					// Only examine the rows where the startKey is zero length
+//					if (info != null && info.getStartKey().length == 0) {
+//						uniqueTables.add(info.getTableDesc());
+//					}
+//					return true;
+//				} catch (RuntimeException e) {
+//					throw e;
+//				}
+//			}
+//		};
+//		MetaScanner.metaScan(conf, visitor);
+//
+//		return uniqueTables.toArray(new HTableDescriptor[uniqueTables.size()]);
+	}
+
+	/**
+	 * set the table priority,because disable sometimes failed,so we disable one
+	 * table twice.
+	 * 
+	 * @param priority
+	 *            priority String
+	 * @param table
+	 *            table name
+	 */
+	@SuppressWarnings("static-access")
+	public static void setPriority(String priority, String table) {
+
+		try {
+			Integer.parseInt(priority);
+		} catch (NumberFormatException e) {
+			e.printStackTrace();
+			return;
+		}
+		try {
+			HBaseAdmin admin = new HBaseAdmin(conf);
+			HTableDescriptor des = admin.getTableDescriptor(Bytes
+					.toBytes(table));
+			des.setValue(Bytes.toBytes(ScheduleHBaseServer.pri_string), Bytes
+					.toBytes(priority));
+			LOG.info("disable table start .............");
+			try {
+				admin.disableTable(table);
+				Thread.currentThread().sleep(3000);
+				admin.disableTable(table);
+			} catch (Exception e1) {
+				e1.printStackTrace();
+			}
+			try {
+				Thread.currentThread().sleep(10000);
+			} catch (InterruptedException e1) {
+				e1.printStackTrace();
+			}
+			LOG.info(".....disable finished .............");
+
+			try {
+				admin.modifyTable(des.getName(), des);
+				LOG.info(".....modify priority finished .............");
+			} catch (Exception e) {
+				e.printStackTrace();
+			}
+			try {
+				admin.enableTable(table);
+				LOG.info(".....enable table finished .............");
+			} catch (Exception e) {
+				e.printStackTrace();
+			}
+		} catch (MasterNotRunningException e) {
+			e.printStackTrace();
+		} catch (ZooKeeperConnectionException e) {
+			e.printStackTrace();
+		} catch (IOException e) {
+			e.printStackTrace();
+		}
+
+	}
+
+	/**
+	 * set the table group,because disable sometimes failed,so we disable one
+	 * table twice.
+	 * 
+	 * @param groups
+	 *            groups the table belong to
+	 * @param table
+	 *            table name
+	 */
+	@SuppressWarnings("static-access")
+	public static void setGroup(String[] groups, String table) {
+
+		try {
+			HBaseAdmin admin = new HBaseAdmin(conf);
+
+			HTableDescriptor des = admin.getTableDescriptor(Bytes
+					.toBytes(table));
+			String group = "";
+			for (String s : groups) {
+				group += (s + ",");
+			}
+			LOG.info("disable table :" + table + " start");
+			des.setValue(GROUP_KEY, Bytes.toBytes(group));
+			try {
+				admin.disableTable(table);
+				Thread.currentThread().sleep(5000);
+				admin.disableTable(table);
+			} catch (Exception e1) {
+				e1.printStackTrace();
+			}
+			try {
+				Thread.currentThread().sleep(10000);
+			} catch (InterruptedException e1) {
+				e1.printStackTrace();
+			}
+			LOG.info("disable table :" + table + "finished");
+			try {
+				admin.modifyTable(des.getName(), des);
+			} catch (Exception e) {
+				e.printStackTrace();
+			}
+			try {
+				Thread.currentThread().sleep(5000);
+				admin.modifyTable(des.getName(), des);
+			} catch (InterruptedException e1) {
+				e1.printStackTrace();
+			}
+			LOG.info("modify table :" + table + " finished");
+			try {
+				GroupAssignmentManager.initValue();
+			} catch (Exception e) {
+				e.printStackTrace();
+			}
+			LOG.info("intivalue  :" + table + " finished");
+			try {
+				admin.enableTable(table);
+			} catch (Exception e) {
+				e.printStackTrace();
+			}
+			LOG.info("enable :" + table + " finished");
+		} catch (Exception e) {
+			e.printStackTrace();
+		}
+	}
+
+	private static boolean first = true;
+
+	/**
+	 * not used
+	 * 
+	 * @param first
+	 */
+	public static void initValue(boolean first) {
+		initValue();
+	}
+
+	/**
+	 * initiate the group information
+	 * 
+	 * @return the tables belong to the cluster
+	 */
+	public static HTableDescriptor[] initValue() {
+		
+
+		
+			boolean fileExist = readConfig();
+	
+			if (!first && !fileExist) {
+				return null;
+			}
+			first = false;
+			HTableDescriptor[] dess = null;
+			try {
+				dess = listTables();
+				for (HTableDescriptor des : dess) {
+					String[] groups = new String[] { "0" };
+					byte[] groupsb = des.getValue(GROUP_KEY);
+					if (groupsb != null) {
+						groups = Bytes.toString(des.getValue(GROUP_KEY)).split(
+								GROUP_SPLITER);
+					}
+					ArrayList<String> list = new ArrayList<String>();
+					for (String group : groups)
+						list.add(group);
+					tableGroup.put(des.getNameAsString(), list);
+	
+				}
+			} catch (IOException e) {
+				e.printStackTrace();
+			}
+			initServerInfo();
+			return dess;
+		
+	}
+
+	public GroupAssignmentManager(Server master, ServerManager serverManager,
+			CatalogTracker catalogTracker, ExecutorService service)
+	throws KeeperException {
+		super(master, serverManager, catalogTracker, service);
+		GroupAssignmentManager.master = (HMaster) master;
+		GroupAssignmentManager.master.getZooKeeper()
+		.registerListenerFirst(this);
+		GroupAssignmentManager.master.balanceSwitch(false);
+		GroupAssignmentManager.conf = GroupAssignmentManager.master
+		.getConfiguration();
+		GroupAssignmentManager.serverManager = serverManager;
+		GroupAssignmentManager.catalogTracker = catalogTracker;
+		try {
+			Field f = AssignmentManager.class.getDeclaredField("zkTable");
+			f.setAccessible(true);
+			this.zkTableIn = (ZKTable) f.get(this);
+		} catch (Exception e) {
+			e.printStackTrace();
+		}
+
+		try {
+			Field f = AssignmentManager.class
+			.getDeclaredField("executorService");
+			f.setAccessible(true);
+			this.executorServiceIn = (ExecutorService) f.get(this);
+		} catch (SecurityException e) {
+
+			e.printStackTrace();
+		} catch (NoSuchFieldException e) {
+			e.printStackTrace();
+		} catch (IllegalArgumentException e) {
+			e.printStackTrace();
+		} catch (IllegalAccessException e) {
+			e.printStackTrace();
+		}
+
+	}
+
+	private boolean regionAndServerIsSameGroup(HRegionInfo regionInfo,
+			HServerInfo serverInfo) {
+
+		List<String> groups = new ArrayList<String>();
+		String[] groupss = getTableGroups(regionInfo.getTableDesc()
+				.getNameAsString());
+		for (String s : groupss)
+			groups.add(s);
+
+		boolean inGroup = false;
+		for (String group : groups) {
+			if (groupServers.get(group) == null)
+				continue;
+			if (groupServers.get(group).contains(serverInfo)) {
+				inGroup = true;
+				break;
+			}
+		}
+		return inGroup;
+
+	}
+
+	@Override
+	void balance(final RegionPlan plan) {
+		if (!regionAndServerIsSameGroup(plan.getRegionInfo(), plan
+				.getDestination())) {
+			return;
+		}
+		synchronized (this.regionPlans) {
+			this.regionPlans.put(plan.getRegionName(), plan);
+		}
+		unassign(plan.getRegionInfo());
+	}
+
+	/**
+	 * balance regions belong to one table
+	 * 
+	 * @param table
+	 *            the table you want to balance
+	 */
+	public static void balanceTable(String table) {
+		String groups[] = getTableGroups(table);
+		HashSet<HServerInfo> servers = new HashSet<HServerInfo>();
+
+		for (String group : groups) {
+			System.out.println("table belong to :" + group);
+			if (groupServers.get(group) != null) {
+				servers.addAll(groupServers.get(group));
+			}
+		}
+
+		HashMap<HRegionInfo, HServerAddress> maps = CheckMeta
+		.getRegionAddress(table);
+		HashMap<HRegionInfo, HServerInfo> map = new HashMap<HRegionInfo, HServerInfo>();
+		for (Entry<HRegionInfo, HServerAddress> e : maps.entrySet()) {
+			for (HServerInfo info : servers) {
+				if (CheckMeta.isThisAddress(info, e.getValue())) {
+					map.put(e.getKey(), info);
+				}
+			}
+		}
+		doBalance(servers, map);
+
+	}
+
+	/**
+	 * do the balance job according to the region map and the available server
+	 * list;
+	 * 
+	 * @param servers
+	 * @param map
+	 */
+	private static void doBalance(HashSet<HServerInfo> servers,
+			HashMap<HRegionInfo, HServerInfo> map) {
+		HashMap<HRegionInfo, HServerInfo> moves = new HashMap<HRegionInfo, HServerInfo>();
+		HashMap<HServerInfo, List<HRegionInfo>> serverList = new HashMap<HServerInfo, List<HRegionInfo>>();
+		for (Entry<HRegionInfo, HServerInfo> e : map.entrySet()) {
+			if (serverList.get(e.getValue()) == null) {
+				serverList.put(e.getValue(), new ArrayList<HRegionInfo>());
+			}
+			serverList.get(e.getValue()).add(e.getKey());
+		}
+		for (HServerInfo s : servers) {
+			if (serverList.get(s) == null) {
+				serverList.put(s, new ArrayList<HRegionInfo>());
+			}
+		}
+
+		int div = 10;
+		while (div > GroupAssignmentManager.div) {
+			HServerInfo maxLoad = null, minLoad = null;
+			int maxLoadN = Integer.MIN_VALUE, minLoadN = Integer.MAX_VALUE;
+			for (Entry<HServerInfo, List<HRegionInfo>> e : serverList
+					.entrySet()) {
+				if (e.getValue().size() >= maxLoadN) {
+					maxLoadN = e.getValue().size();
+					maxLoad = e.getKey();
+				}
+				if (e.getValue().size() <= minLoadN) {
+					minLoadN = e.getValue().size();
+					minLoad = e.getKey();
+				}
+			}
+			if (maxLoad == null || minLoad == null)
+				break;
+			if (serverList.get(maxLoad).size() == 0)
+				break;
+			else {
+				div = Math.abs(maxLoadN - minLoadN);
+				int index = RANDOM.nextInt(serverList.get(maxLoad).size());
+				moves.put(serverList.get(maxLoad).get(index), minLoad);
+				serverList.get(minLoad).add(serverList.get(maxLoad).get(index));
+				serverList.get(maxLoad).remove(index);
+			}
+
+		}
+
+		for (Entry<HRegionInfo, HServerInfo> e : moves.entrySet()) {
+			try {
+				LOG.info("move :" + e.getKey().getEncodedName()
+						+ " regions to " + e.getValue());
+				master.move(e.getKey().getEncodedNameAsBytes(), Bytes.toBytes(e
+						.getValue().getServerName()));
+			} catch (Exception e1) {
+				// TODO Auto-generated catch block
+				e1.printStackTrace();
+			}
+		}
+	}
+
+	/**
+	 * balance regions which in the same group
+	 * 
+	 * @param group
+	 *            the group you want to balance
+	 */
+	public static void balanceGroup(String group) {
+		HashSet<HServerInfo> servers = groupServers.get(group);
+		if (servers == null || servers.size() < 2)
+			return;
+		HServerInfo[] infos = new HServerInfo[servers.size()];
+		servers.toArray(infos);
+		HashMap<HRegionInfo, HServerInfo> map = CheckMeta.getServerRegions(
+				infos, true);
+		if (map == null || map.size() < 2)
+			return;
+
+		doBalance(servers, map);
+
+	}
+
+	private static String[] getTableGroups(String tableName) {
+		String groups[] = null;
+		if (haveGroup(tableName)) {
+			groups = getTableGroupsInner(tableName);
+		} else {
+			ArrayList<String> l = new ArrayList<String>();
+			for (String s : groupDifConf.keySet()) {
+				if (groupDifConf.get(s) == false) {
+					l.add(s);
+				}
+			}
+			groups = new String[l.size()];
+			l.toArray(groups);
+		}
+		if (groups == null)
+			groups = new String[] { DEFAULT_GROUP };
+		return groups;
+	}
+	private static List<HServerInfo> filterRootServer(List<HServerInfo> servers)
+	{
+		try {
+			if(servers.size()<=1)
+			{
+				return servers;
+			}
+			HServerAddress rootAddress=catalogTracker.getRootLocation();
+			if(rootAddress!=null)
+			{
+				for(HServerInfo server:servers)
+				{
+					if(server.getServerAddress().equals(rootAddress))
+					{
+						servers.remove(server);
+						return servers;
+					}
+				}
+			}
+		} catch (Exception e) {
+			e.printStackTrace();
+		}
+		return servers;
+	}
+	/**
+	 * Get servers which this table can use according to group information
+	 * 
+	 * @param tableName
+	 * @return available server list
+	 */
+	public static List<HServerInfo> getAvailableServer(String tableName) {
+		String groups[] = null;
+
+		groups = getTableGroups(tableName);
+		List<HServerInfo> servers = serverManager.getOnlineServersList();
+
+		List<HServerInfo> ret = new ArrayList<HServerInfo>();
+		for (HServerInfo server : servers) {
+			for (String group : groups) {
+				if (groupServers.get(group) == null) {
+					continue;
+				}
+				if (groupServers.get(group).contains(server)) {
+					ret.add(server);
+					break;
+				}
+			}
+		}
+		if (ret == null || ret.size() == 0) {
+			ret = new ArrayList<HServerInfo>();
+			ret.addAll(groupServers.get(DEFAULT_GROUP));
+		}
+		
+		return filterRootServer(ret);
+
+	}
+
+	private List<HServerInfo> getDefaultServer() {
+		List<HServerInfo> ret = new ArrayList<HServerInfo>();
+		ret.addAll(groupServers.get(DEFAULT_GROUP));
+		return ret;
+	}
+
+	private List<HServerInfo> getAvailableServer(List<HServerInfo> servers,
+			String table) {
+		
+		List<String> groups =new ArrayList<String>();
+		String groupsStr[]=getTableGroups(table);
+		for(String s:groupsStr)
+		{
+			groups.add(s);
+		}
+		List<HServerInfo> ret = new ArrayList<HServerInfo>();
+		for (HServerInfo server : servers) {
+
+			for (String group : groups) {
+				if (groupServers.get(group) == null) {
+					continue;
+				}
+				if (groupServers.get(group).contains(server)) {
+					ret.add(server);
+					break;
+				}
+			}
+		}
+		if (ret.size() == 0) {
+			if (groupServers.get(DEFAULT_GROUP) == null) {
+				initValue();
+			}
+			ret.addAll(groupServers.get(DEFAULT_GROUP));
+		}
+		return filterRootServer(ret);
+	}
+
+	@Override
+	RegionPlan getRegionPlan(final RegionState state,
+			final HServerInfo serverToExclude, final boolean forceNewPlan) {
+		List<HServerInfo> servers = serverManager.getOnlineServersList();
+		boolean rootOrMeta = false;
+		// if it's root or meta regions,use super getRegionPlan
+		if (state.getRegion().isMetaRegion()
+				|| state.getRegion().isRootRegion()) {
+			rootOrMeta = true;
+			if (groupServers.get(DEFAULT_GROUP) == null) {
+				try {
+					readConfig();
+					initServerInfo();
+				} catch (Exception e) {
+					// TODO Auto-generated catch block
+					e.printStackTrace();
+				}
+			}
+			
+			HServerAddress address=null;
+			if (state.getRegion().isMetaRegion())
+			{
+				try {
+					address=catalogTracker.getRootLocation();
+				} catch (InterruptedException e) {
+					e.printStackTrace();
+				}
+				if(address!=null)
+				{
+					HServerInfo rootServer=null;
+					for(HServerInfo serverInfo:servers)
+					{
+						if(serverInfo.getServerAddress().equals(address))
+						{
+							rootServer=serverInfo;
+							break;
+						}
+					}
+					if(rootServer!=null)
+					{
+						return new RegionPlan(state.getRegion(),null,rootServer);
+					}
+				
+				}
+			}
+			return super
+			.getRegionPlan(state, serverToExclude, forceNewPlan);
+		} else {
+			if (first)
+				initValue();
+		}
+		String encodedName = state.getRegion().getEncodedName();
+		
+		// The remove below hinges on the fact that the call to
+		// serverManager.getOnlineServersList() returns a copy
+		if (serverToExclude != null)
+			servers.remove(serverToExclude);
+		if (servers.isEmpty())
+			return null;
+		if (rootOrMeta) {
+			servers = this.getDefaultServer();
+		} else {
+			servers = this.getAvailableServer(servers, state.getRegion()
+					.getTableDesc().getNameAsString());
+		}
+
+		// get available servers according to the group information
+
+		RegionPlan randomPlan = new RegionPlan(state.getRegion(), null,
+				LoadBalancer.randomAssignment(servers));
+		boolean newPlan = false;
+		RegionPlan existingPlan = null;
+		synchronized (this.regionPlans) {
+			existingPlan = this.regionPlans.get(encodedName);
+			if (forceNewPlan || existingPlan == null
+					|| existingPlan.getDestination() == null
+					|| existingPlan.getDestination().equals(serverToExclude)) {
+				newPlan = true;
+				this.regionPlans.put(encodedName, randomPlan);
+			}
+		}
+		if (newPlan) {
+			LOG
+			.debug("No previous transition plan was found (or we are ignoring "
+					+ "an existing plan) for "
+					+ state.getRegion().getRegionNameAsString()
+					+ " so generated a random one; "
+					+ randomPlan
+					+ "; "
+					+
+					// serverManager.countOfRegionServers() +
+					" (online="
+					+ serverManager.getOnlineServers().size()
+					+ ", exclude="
+					+ serverToExclude
+					+ ") available servers");
+			return randomPlan;
+		}
+		LOG.debug("Using pre-existing plan for region "
+				+ state.getRegion().getRegionNameAsString() + "; plan="
+				+ existingPlan);
+		return existingPlan;
+	}
+
+	private String getGroupString(HTableDescriptor des) {
+
+		byte[] groupsb = des.getValue(GROUP_KEY);
+		if (groupsb != null) {
+			return Bytes.toString(des.getValue(GROUP_KEY));
+		} else {
+			return "0";
+		}
+
+	}
+
+	// private String[] getGroupString(HRegionInfo info) {
+	// String groups = getGroupString(info.getTableDesc());
+	// return groups.split(GROUP_SPLITER);
+	//
+	// }
+
+	private String getGroupStringRandom(HRegionInfo info) {
+		String groups = getGroupString(info.getTableDesc());
+		String[] ret = groups.split(GROUP_SPLITER);
+		if (ret.length == 1) {
+			return ret[0];
+		} else {
+			return ret[RANDOM.nextInt(ret.length)];
+		}
+
+	}
+
+	// private HashSet<HServerInfo> getGroupServer(HRegionInfo info) {
+	//
+	// String[] groups = getGroupString(info);
+	// String group = groups[RANDOM.nextInt(groups.length)];
+	// if (groupServers.get(group) == null) {
+	// return groupServers.get("0");
+	// }
+	// return groupServers.get(group);
+	//
+	// }
+
+	// private List<HServerInfo> getGroupServerList(HRegionInfo info) {
+	//
+	// String[] groups = getGroupString(info);
+	// String group = groups[RANDOM.nextInt(groups.length)];
+	// ArrayList<HServerInfo> ret = new ArrayList<HServerInfo>();
+	//
+	// if (groupServers.get(group) == null) {
+	// ret.addAll(groupServers.get("0"));
+	// return ret;
+	// }
+	// ret.addAll(this.groupServers.get(group));
+	// return ret;
+	//
+	// }
+
+	private Map<String, List<HServerInfo>> getServerGroups(
+			List<HServerInfo> servers) {
+		{
+			Map<String, List<HServerInfo>> ret = new TreeMap<String, List<HServerInfo>>();
+			for (HServerInfo server : servers) {
+				String group = "0";
+				for (Entry<String, HashSet<HServerInfo>> entry : groupServers
+						.entrySet()) {
+					if (entry.getValue().contains(server)) {
+						group = entry.getKey();
+						break;
+					}
+				}
+				if (ret.get(group) == null) {
+					ret.put(group, new ArrayList<HServerInfo>());
+				}
+				ret.get(group).add(server);
+			}
+			return ret;
+		}
+	}
+
+	/**
+	 * assign regions to servers according to group information,and try to use
+	 * the assignment remained in meta
+	 * 
+	 * @param regions
+	 *            regions and assignments
+	 * @param servers
+	 *            available servers
+	 * @return the new assignment
+	 */
+	private Map<HServerInfo, List<HRegionInfo>> retainGroupAssignRegions(
+			Map<HRegionInfo, HServerAddress> regions, List<HServerInfo> servers) {
+
+		Map<HServerInfo, List<HRegionInfo>> assignments = new TreeMap<HServerInfo, List<HRegionInfo>>();
+
+		Map<HServerAddress, HServerInfo> serverMap = new TreeMap<HServerAddress, HServerInfo>();
+
+		Map<String, List<HServerInfo>> groupMap = getServerGroups(servers);
+
+		for (HServerInfo server : servers) {
+			serverMap.put(server.getServerAddress(), server);
+			assignments.put(server, new ArrayList<HRegionInfo>());
+		}
+		for (Map.Entry<HRegionInfo, HServerAddress> region : regions.entrySet()) {
+			HServerAddress hsa = region.getValue();
+			HServerInfo server = hsa == null ? null : serverMap.get(hsa);
+			if (server != null
+					&& this.regionAndServerIsSameGroup(region.getKey(), server)) {
+				assignments.get(server).add(region.getKey());
+			} else {
+				List <HServerInfo> avaServers=getAvailableServer(region.getKey().getTableDesc().getNameAsString());
+				assignments.get(avaServers.get(RANDOM.nextInt(avaServers.size()))).add(
+						region.getKey());
+			}
+		}
+
+		return assignments;
+	}
+
+	private boolean groupExist(String groupString) {
+
+		String[] groups = groupString.split(GROUP_SPLITER);
+		if (groups.length != 0) {
+			for (String s : groups) {
+				if (groupServers.get(s) != null) {
+					return true;
+				}
+			}
+		}
+		return false;
+
+	}
+
+	/**
+	 * assign regions according to the group information,
+	 * 
+	 * @param regions
+	 *            regions to assigne
+	 * @param servers
+	 *            available servers
+	 * @return the assignment
+	 */
+	private List<Pair<List<HRegionInfo>, List<HServerInfo>>> groupAssignRegions(
+			List<HRegionInfo> regions, List<HServerInfo> servers) {
+		List<Pair<List<HRegionInfo>, List<HServerInfo>>> ret = new ArrayList<Pair<List<HRegionInfo>, List<HServerInfo>>>();
+		HashMap<String, List<HRegionInfo>> groupToRegion = new HashMap<String, List<HRegionInfo>>();
+		servers=filterRootServer(servers);
+		for (HRegionInfo info : regions) {
+			String groups = getGroupString(info.getTableDesc());
+			if (!groupExist(groups)) {
+				groups = DEFAULT_GROUP;
+			}
+			if (groupToRegion.get(groups) == null) {
+				groupToRegion.put(groups, new ArrayList<HRegionInfo>());
+			}
+			groupToRegion.get(groups).add(info);
+		}
+
+		for (List<HRegionInfo> list : groupToRegion.values()) {
+			Pair<List<HRegionInfo>, List<HServerInfo>> p = new Pair<List<HRegionInfo>, List<HServerInfo>>();
+			p.setFirst(list);
+			p.setSecond(new ArrayList<HServerInfo>());
+			for (HServerInfo server : servers) {
+				if (this.regionAndServerIsSameGroup(list.get(0), server)) {
+					p.getSecond().add(server);
+				}
+			}
+			ret.add(p);
+		}
+		return ret;
+	}
+
+	@Override
+	public void assignUserRegions(List<HRegionInfo> regions,
+			List<HServerInfo> servers) throws IOException, InterruptedException {
+		if (regions == null)
+			return;
+		Map<HServerInfo, List<HRegionInfo>> bulkPlan = null;
+		// Generate a round-robin bulk assignment plan
+		bulkPlan = LoadBalancer.roundRobinAssignment(regions, servers);
+		LOG.info("Bulk assigning " + regions.size()
+				+ " region(s) round-robin across " + servers.size()
+				+ " server(s)");
+		// Use fixed count thread pool assigning.
+		BulkAssigner ba = new BulkStartupAssigner(master, bulkPlan, this);
+		ba.bulkAssign();
+		LOG.info("Bulk assigning done");
+	}
+
+	/**
+	 * Assigns all user regions, if any exist. Used during cluster startup.
+	 * <p>
+	 * This is a synchronous call and will return once every region has been
+	 * assigned. If anything fails, an exception is thrown and the cluster
+	 * should be shutdown.
+	 * 
+	 * @throws InterruptedException
+	 * @throws IOException
+	 */
+	@Override
+	public void assignAllUserRegions() throws IOException, InterruptedException {
+		// Get all available servers
+		initValue();
+		List<HServerInfo> servers = serverManager.getOnlineServersList();
+
+		// Scan META for all user regions, skipping any disabled tables
+		Map<HRegionInfo, HServerAddress> allRegions = MetaReader.fullScan(
+				catalogTracker, this.zkTableIn.getDisabledTables(), true);
+		if (allRegions == null || allRegions.isEmpty())
+			return;
+
+		// Determine what type of assignment to do on startup
+		boolean retainAssignment = master.getConfiguration().getBoolean(
+				"hbase.master.startup.retainassign", true);
+
+		Map<HServerInfo, List<HRegionInfo>> bulkPlan = null;
+
+		if (retainAssignment) {
+			// Reuse existing assignment info
+			bulkPlan = this.retainGroupAssignRegions(allRegions, servers);
+			// LoadBalancer.retainAssignment(allRegions, servers);
+		} else {
+			List<Pair<List<HRegionInfo>, List<HServerInfo>>> ret = this
+			.groupAssignRegions(new ArrayList<HRegionInfo>(allRegions
+					.keySet()), servers);
+			// assign regions in round-robin fashion
+			for (Pair<List<HRegionInfo>, List<HServerInfo>> p : ret)
+				assignUserRegions(p.getFirst(), p.getSecond());
+			return;
+		}
+		LOG.info("Bulk assigning " + allRegions.size() + " region(s) across "
+				+ servers.size() + " server(s), retainAssignment="
+				+ retainAssignment);
+
+		// Use fixed count thread pool assigning.
+		BulkAssigner ba = new BulkStartupAssigner(master, bulkPlan, this);
+		ba.bulkAssign();
+		LOG.info("Bulk assigning done");
+	}
+
+	/**
+	 * Handle a ZK unassigned node transition triggered by HBCK repair tool.
+	 * <p>
+	 * This is handled in a separate code path because it breaks the normal
+	 * rules. the following is copied from AssignmentMananger.java
+	 * 
+	 * @param data
+	 */
+	private void handleHBCK(RegionTransitionData data) {
+		String encodedName = HRegionInfo.encodeRegionName(data.getRegionName());
+		LOG.info("Handling HBCK triggered transition=" + data.getEventType()
+				+ ", server=" + data.getServerName() + ", region="
+				+ HRegionInfo.prettyPrint(encodedName));
+		RegionState regionState = regionsInTransition.get(encodedName);
+		switch (data.getEventType()) {
+		case M_ZK_REGION_OFFLINE:
+			HRegionInfo regionInfo = null;
+			if (regionState != null) {
+				regionInfo = regionState.getRegion();
+			} else {
+				try {
+					regionInfo = MetaReader.getRegion(catalogTracker,
+							data.getRegionName()).getFirst();
+				} catch (IOException e) {
+					LOG
+					.info(
+							"Exception reading META doing HBCK repair operation",
+							e);
+					return;
+				}
+			}
+			LOG.info("HBCK repair is triggering assignment of region="
+					+ regionInfo.getRegionNameAsString());
+			// trigger assign, node is already in OFFLINE so don't need to
+			// update ZK
+			assign(regionInfo, false);
+			break;
+
+		default:
+			LOG.warn("Received unexpected region state from HBCK ("
+					+ data.getEventType() + ")");
+			break;
+		}
+	}
+
+	/**
+	 * Handles various states an unassigned node can be in.
+	 * <p>
+	 * Method is called when a state change is suspected for an unassigned node.
+	 * <p>
+	 * This deals with skipped transitions (we got a CLOSED but didn't see
+	 * CLOSING yet). the following is copied from AssignmentMananger.java
+	 * 
+	 * @param data
+	 */
+	@SuppressWarnings("unused")
+	private void handleRegion(final RegionTransitionData data) {
+		synchronized (regionsInTransition) {
+			if (data == null || data.getServerName() == null) {
+				LOG.warn("Unexpected NULL input " + data);
+				return;
+			}
+			// Check if this is a special HBCK transition
+			if (data.getServerName().equals(HConstants.HBCK_CODE_NAME)) {
+				handleHBCK(data);
+				return;
+			}
+			// Verify this is a known server
+			if (!serverManager.isServerOnline(data.getServerName())
+					&& !master.getServerName().equals(data.getServerName())) {
+				LOG
+				.warn("Attempted to handle region transition for server but "
+						+ "server is not online: "
+						+ data.getRegionName());
+				return;
+			}
+			String encodedName = HRegionInfo.encodeRegionName(data
+					.getRegionName());
+			String prettyPrintedRegionName = HRegionInfo
+			.prettyPrint(encodedName);
+			LOG.debug("Handling transition=" + data.getEventType()
+					+ ", server=" + data.getServerName() + ", region="
+					+ prettyPrintedRegionName);
+			RegionState regionState = regionsInTransition.get(encodedName);
+			switch (data.getEventType()) {
+			case M_ZK_REGION_OFFLINE:
+				// Nothing to do.
+				break;
+
+			case RS_ZK_REGION_CLOSING:
+				// Should see CLOSING after we have asked it to CLOSE or
+				// additional
+				// times after already being in state of CLOSING
+				if (regionState == null
+						|| (!regionState.isPendingClose() && !regionState
+								.isClosing())) {
+					LOG.warn("Received CLOSING for region "
+							+ prettyPrintedRegionName + " from server "
+							+ data.getServerName() + " but region was in "
+							+ " the state " + regionState + " and not "
+							+ "in expected PENDING_CLOSE or CLOSING states");
+					return;
+				}
+				// Transition to CLOSING (or update stamp if already CLOSING)
+				regionState.update(RegionState.State.CLOSING, data.getStamp());
+				break;
+
+			case RS_ZK_REGION_CLOSED:
+				// Should see CLOSED after CLOSING but possible after
+				// PENDING_CLOSE
+				if (regionState == null
+						|| (!regionState.isPendingClose() && !regionState
+								.isClosing())) {
+					LOG.warn("Received CLOSED for region "
+							+ prettyPrintedRegionName + " from server "
+							+ data.getServerName() + " but region was in "
+							+ " the state " + regionState + " and not "
+							+ "in expected PENDING_CLOSE or CLOSING states");
+					try {
+						HRegionInfo info = this.getAssignment(
+								data.getRegionName()).getFirst();
+						this.setOffline(info);
+						this.clearRegionFromTransition(info);
+					} catch (Exception e) {
+
+						e.printStackTrace();
+					}
+					return;
+
+				}
+				regionState.update(RegionState.State.CLOSED, data.getStamp());
+				this.executorServiceIn.submit(new ClosedRegionHandler(master,
+						this, regionState.getRegion()));
+				break;
+
+			case RS_ZK_REGION_OPENING:
+				// Should see OPENING after we have asked it to OPEN or
+				// additional
+				// times after already being in state of OPENING
+				if (regionState == null
+						|| (!regionState.isPendingOpen() && !regionState
+								.isOpening())) {
+					LOG.warn("Received OPENING for region "
+							+ prettyPrintedRegionName + " from server "
+							+ data.getServerName() + " but region was in "
+							+ " the state " + regionState + " and not "
+							+ "in expected PENDING_OPEN or OPENING states");
+					return;
+				}
+				// Transition to OPENING (or update stamp if already OPENING)
+				regionState.update(RegionState.State.OPENING, data.getStamp());
+				break;
+
+			case RS_ZK_REGION_OPENED:
+				// Should see OPENED after OPENING but possible after
+				// PENDING_OPEN
+				if (regionState == null
+						|| (!regionState.isPendingOpen() && !regionState
+								.isOpening())) {
+					LOG.warn("Received OPENED for region "
+							+ prettyPrintedRegionName + " from server "
+							+ data.getServerName() + " but region was in "
+							+ " the state " + regionState + " and not "
+							+ "in expected PENDING_OPEN or OPENING states");
+					return;
+				}
+				// Handle OPENED by removing from transition and deleted zk node
+				regionState.update(RegionState.State.OPEN, data.getStamp());
+				this.executorServiceIn.submit(new OpenedRegionHandler(master,
+						this, regionState.getRegion(), serverManager
+						.getServerInfo(data.getServerName())));
+				break;
+			}
+		}
+	}
+
+	static Random RANDOM = new Random();
+
+}
diff -uNr hbase-0.90.2/src/main/java/org/apache/hadoop/hbase/master/HMaster.java hbase-0.90.2-local/src/main/java/org/apache/hadoop/hbase/master/HMaster.java
--- src/main/java/org/apache/hadoop/hbase/master/HMaster.java	2011-03-28 04:50:34.000000000 +0800
+++ src/main/java/org/apache/hadoop/hbase/master/HMaster.java	2011-07-22 17:14:19.000000000 +0800
@@ -354,7 +354,7 @@
       this, conf.getInt("hbase.master.catalog.timeout", Integer.MAX_VALUE));
     this.catalogTracker.start();
 
-    this.assignmentManager = new AssignmentManager(this, serverManager,
+    this.assignmentManager = new GroupAssignmentManager(this, serverManager,
       this.catalogTracker, this.executorService);
     this.balancer = new LoadBalancer(conf);
     zooKeeper.registerListenerFirst(assignmentManager);
diff -uNr hbase-0.90.2/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java hbase-0.90.2-local/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java
--- src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java	2011-03-28 04:50:34.000000000 +0800
+++ src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java	2011-07-22 17:14:27.000000000 +0800
@@ -106,6 +106,7 @@
 import org.apache.hadoop.hbase.ipc.HBaseServer;
 import org.apache.hadoop.hbase.ipc.HMasterRegionInterface;
 import org.apache.hadoop.hbase.ipc.HRegionInterface;
+import org.apache.hadoop.hbase.ipc.ScheduleHBaseServer;
 import org.apache.hadoop.hbase.ipc.ServerNotRunningException;
 import org.apache.hadoop.hbase.regionserver.Leases.LeaseStillHeldException;
 import org.apache.hadoop.hbase.regionserver.handler.CloseMetaHandler;
@@ -325,13 +326,20 @@
       conf.get(HConstants.REGIONSERVER_PORT,
         Integer.toString(HConstants.DEFAULT_REGIONSERVER_PORT));
     HServerAddress address = new HServerAddress(addressStr);
-    this.server = HBaseRPC.getServer(this,
-        new Class<?>[]{HRegionInterface.class, HBaseRPCErrorHandler.class,
-        OnlineRegions.class},
-        address.getBindAddress(),
-      address.getPort(), conf.getInt("hbase.regionserver.handler.count", 10),
-        conf.getInt("hbase.regionserver.metahandler.count", 10),
-        false, conf, QOS_THRESHOLD);
+    this.server = new ScheduleHBaseServer(this,
+			new Class<?>[]{HRegionInterface.class, HBaseRPCErrorHandler.class,
+	        OnlineRegions.class},conf,
+			address.getBindAddress(),
+			address.getPort(), conf.getInt("hbase.regionserver.handler.count", 10),
+			conf.getInt("hbase.regionserver.metahandler.count", 10),
+			false, QOS_THRESHOLD);
+//    this.server = HBaseRPC.getServer(this,
+//        new Class<?>[]{HRegionInterface.class, HBaseRPCErrorHandler.class,
+//        OnlineRegions.class},
+//        address.getBindAddress(),
+//      address.getPort(), conf.getInt("hbase.regionserver.handler.count", 10),
+//        conf.getInt("hbase.regionserver.metahandler.count", 10),
+//        false, conf, QOS_THRESHOLD);
     this.server.setErrorHandler(this);
     this.server.setQosFunction(new QosFunction());
 
